{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnaUyTXsaEHS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# If you use torch/gymnasium, include them here too:\n",
        "import torch\n",
        "import gymnasium as gym\n",
        "\n",
        "os.makedirs(\"runs\", exist_ok=True)\n",
        "\n",
        "def set_seed(seed: int = 0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass, field\n",
        "\n",
        "@dataclass\n",
        "class DBSBounds:\n",
        "    amp_mA_min: float = 0.1\n",
        "    amp_mA_max: float = 5.0\n",
        "    freq_Hz_min: float = 5.0\n",
        "    freq_Hz_max: float = 200.0\n",
        "    pw_ms_min: float = 0.05\n",
        "    pw_ms_max: float = 0.5\n",
        "\n",
        "@dataclass\n",
        "class PlantConfig:\n",
        "    dt_ms: float = 0.05\n",
        "    window_ms: float = 250.0\n",
        "    sigma_S_per_m: float = 0.2\n",
        "\n",
        "    onset_weight_mult: float = 50.0\n",
        "\n",
        "    # safety bounds (also used by action mapping)\n",
        "    max_amp_mA: float = 10.0\n",
        "    max_pw_ms: float = 1.0\n",
        "    max_freq_Hz: float = 250.0\n",
        "\n",
        "@dataclass\n",
        "class NetworkConfig:\n",
        "    n_cells: int = 80\n",
        "    frac_gm: float = 0.65\n",
        "\n",
        "    gm_frac_E: float = 0.75\n",
        "    gm_frac_I_fast: float = 0.15\n",
        "    # remainder is I_slow\n",
        "\n",
        "    p_conn: float = 0.08\n",
        "    w_exc: float = 0.002\n",
        "    w_inh: float = -0.004\n",
        "\n",
        "    # “spatial box” around focus center (mm)\n",
        "    spatial_extent_mm: float = 1.5\n",
        "\n",
        "    # WM axon geometry (um)\n",
        "    wm_axon_L_um: float = 800.0\n",
        "    wm_axon_diam_um: float = 2.0\n",
        "\n",
        "    # tissue mode: \"GM\", \"WM\", \"BOUNDARY\"\n",
        "    tissue_mode: str = \"BOUNDARY\"\n",
        "\n",
        "@dataclass\n",
        "class EnvConfig:\n",
        "    episode_steps: int = 40\n",
        "    obs_clip: float = 1e6\n",
        "    reward_scale: float = 1.0\n",
        "    # in EnvConfig\n",
        "    min_amp_mA: float = 0.0   # default allow OFF\n",
        "\n",
        "\n",
        "    # how much baseline to run at reset (optional)\n",
        "    baseline_windows: int = 1\n",
        "\n",
        "    # action mapping\n",
        "    dbs_bounds: DBSBounds = field(default_factory=DBSBounds)\n",
        "\n",
        "    # observation composition toggles (keep simple)\n",
        "    include_last_action_in_obs: bool = True\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E971P95IaI0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_action_to_dbs(action: np.ndarray, amp_min, amp_max, freq_min, freq_max, pw_min, pw_max):\n",
        "    \"\"\"\n",
        "    action in [-1, 1]^3 -> (amp_mA, freq_Hz, pw_ms) within bounds\n",
        "    \"\"\"\n",
        "    a = np.clip(action.astype(float), -1.0, 1.0)\n",
        "    # affine map: [-1,1] -> [0,1] -> [min,max]\n",
        "    u = 0.5 * (a + 1.0)\n",
        "    amp = amp_min + u[0] * (amp_max - amp_min)\n",
        "    freq = freq_min + u[1] * (freq_max - freq_min)\n",
        "    pw = pw_min + u[2] * (pw_max - pw_min)\n",
        "    return float(amp), float(freq), float(pw)\n",
        "\n",
        "def safe_clip(x: np.ndarray, bound: float) -> np.ndarray:\n",
        "    return np.clip(x, -bound, bound)\n"
      ],
      "metadata": {
        "id": "NrDsmjV7acwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import List\n",
        "\n",
        "def burst_fraction_from_spikes(\n",
        "    spike_times_ms: np.ndarray,\n",
        "    isi_thresh_ms: float = 10.0,\n",
        "    min_spikes_in_burst: int = 3\n",
        ") -> float:\n",
        "    \"\"\"Fraction of spikes that belong to an ISI-defined burst.\"\"\"\n",
        "    st = np.asarray(spike_times_ms, dtype=float)\n",
        "    if st.size < min_spikes_in_burst:\n",
        "        return 0.0\n",
        "    st = np.sort(st)\n",
        "    isi = np.diff(st)\n",
        "    fast = isi < float(isi_thresh_ms)\n",
        "\n",
        "    count_in_bursts = 0\n",
        "    run_len = 0\n",
        "    for f in fast:\n",
        "        if f:\n",
        "            run_len += 1\n",
        "        else:\n",
        "            if run_len >= (min_spikes_in_burst - 1):\n",
        "                count_in_bursts += (run_len + 1)\n",
        "            run_len = 0\n",
        "    if run_len >= (min_spikes_in_burst - 1):\n",
        "        count_in_bursts += (run_len + 1)\n",
        "\n",
        "    return float(count_in_bursts) / float(st.size)\n",
        "\n",
        "def sync_from_spike_trains(\n",
        "    spike_lists_ms: List[np.ndarray],\n",
        "    window_ms: float,\n",
        "    bin_ms: float = 5.0\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Synchrony proxy:\n",
        "    - Bin population spikes in bin_ms windows\n",
        "    - Compute CV = std/mean of population bin counts\n",
        "    - Return tanh(CV) to keep in [0,1)\n",
        "    \"\"\"\n",
        "    if len(spike_lists_ms) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    n_bins = int(np.ceil(float(window_ms) / float(bin_ms)))\n",
        "    if n_bins <= 1:\n",
        "        return 0.0\n",
        "\n",
        "    pop = np.zeros(n_bins, dtype=float)\n",
        "    for st in spike_lists_ms:\n",
        "        if st.size == 0:\n",
        "            continue\n",
        "        idx = np.floor(st / float(bin_ms)).astype(int)\n",
        "        idx = idx[(idx >= 0) & (idx < n_bins)]\n",
        "        if idx.size:\n",
        "            pop += np.bincount(idx, minlength=n_bins).astype(float)\n",
        "\n",
        "    mu = float(np.mean(pop))\n",
        "    if mu < 1e-9:\n",
        "        return 0.0\n",
        "\n",
        "    cv = float(np.std(pop)) / mu\n",
        "    return float(np.tanh(cv))"
      ],
      "metadata": {
        "id": "3LjOqyqyLY3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRm1bk5buO53"
      },
      "outputs": [],
      "source": [
        "# logging.py\n",
        "from __future__ import annotations\n",
        "import os, json\n",
        "import numpy as np\n",
        "\n",
        "class EpisodeLogger:\n",
        "    def __init__(self, out_dir: str):\n",
        "        self.out_dir = out_dir\n",
        "        os.makedirs(self.out_dir, exist_ok=True)\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.rows = []\n",
        "        self.ep_info = {}\n",
        "\n",
        "    def log_step(self, row: dict):\n",
        "        # row should only contain JSON-serializable scalars / strings\n",
        "        self.rows.append(row)\n",
        "\n",
        "    def end_episode(self, ep_index: int, summary: dict):\n",
        "        # Save stepwise data\n",
        "        step_path = os.path.join(self.out_dir, f\"episode_{ep_index:06d}.jsonl\")\n",
        "        with open(step_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            for r in self.rows:\n",
        "                f.write(json.dumps(r) + \"\\n\")\n",
        "\n",
        "        # Save episode summary\n",
        "        sum_path = os.path.join(self.out_dir, f\"episode_{ep_index:06d}_summary.json\")\n",
        "        with open(sum_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(summary, f, indent=2)\n",
        "\n",
        "        self.reset()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Case specification + generators for the DBS-epilepsy RL environment.\n",
        "\n",
        "This module is designed to be:\n",
        "- Complete and reproducible (seeded generation, deterministic suites)\n",
        "- Scalable (sample_n for large case batches)\n",
        "- Explicit about anatomy/tissue modes, electrode geometry/placement, onset topology,\n",
        "  severity/excitability, and per-case network/connectivity variants.\n",
        "\n",
        "Intended usage:\n",
        "- Training: CaseGenerator.sample() / sample_n()\n",
        "- Evaluation: CaseSuite.grid(...) to produce deterministic grids/sweeps\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Literal, Optional, Sequence, Tuple\n",
        "import hashlib\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "Vec3 = Tuple[float, float, float]\n",
        "TissueMode = Literal[\"GM\", \"WM\", \"BOUNDARY\"]\n",
        "ConnectivityRegime = Literal[\"none\", \"sparse\", \"dense\", \"small_world\", \"clustered\"]\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Core specs\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class ElectrodeSpec:\n",
        "    \"\"\"Electrode placement and coupling model selection.\"\"\"\n",
        "    xyz_mm: Vec3\n",
        "    orientation_unit: Vec3 = (0.0, 0.0, 1.0)\n",
        "    model: str = \"point_source\"  # e.g., point_source, monopolar_contact, directional\n",
        "    contact_radius_mm: float = 0.0\n",
        "    reference: str = \"monopolar\"  # monopolar / bipolar, etc.\n",
        "\n",
        "    @property\n",
        "    def xyz(self) -> np.ndarray:\n",
        "        return np.asarray(self.xyz_mm, dtype=float)\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BoundaryPlane:\n",
        "    \"\"\"WM–GM boundary represented by a plane: (x - p)·n = 0.\"\"\"\n",
        "    point_mm: Vec3\n",
        "    normal_unit: Vec3\n",
        "\n",
        "    def signed_distance_mm(self, xyz_mm: Vec3) -> float:\n",
        "        p = np.asarray(self.point_mm, dtype=float)\n",
        "        n = np.asarray(self.normal_unit, dtype=float)\n",
        "        n = n / (np.linalg.norm(n) + 1e-12)\n",
        "        x = np.asarray(xyz_mm, dtype=float)\n",
        "        return float(np.dot(x - p, n))\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class AnisotropySpec:\n",
        "    \"\"\"Optional future extension. Kept for forward compatibility.\"\"\"\n",
        "    enabled: bool = False\n",
        "    principal_dir_unit: Vec3 = (1.0, 0.0, 0.0)\n",
        "    ratio_parallel_over_perp: float = 1.0  # 1.0 means isotropic\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TissueSpec:\n",
        "    mode: TissueMode\n",
        "    sigma_gm_S_per_m: float = 0.2\n",
        "    sigma_wm_S_per_m: float = 0.14\n",
        "    boundary: Optional[BoundaryPlane] = None\n",
        "    anisotropy: Optional[AnisotropySpec] = None\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        if self.mode == \"BOUNDARY\" and self.boundary is None:\n",
        "            raise ValueError(\"TissueSpec.mode='BOUNDARY' requires a BoundaryPlane.\")\n",
        "        if self.mode != \"BOUNDARY\" and self.boundary is not None:\n",
        "            raise ValueError(\"BoundaryPlane provided but TissueSpec.mode is not 'BOUNDARY'.\")\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class RegionSpec:\n",
        "    \"\"\"Defines the spatial extent of the simulated region.\"\"\"\n",
        "    center_mm: Vec3\n",
        "    bounds_mm: Vec3 = (3.0, 3.0, 3.0)  # half-extent box\n",
        "    density_mode: str = \"uniform\"      # uniform / clustered / boundary_biased etc.\n",
        "\n",
        "    def sample_point_mm(self, rng: np.random.Generator) -> Vec3:\n",
        "        c = np.asarray(self.center_mm, dtype=float)\n",
        "        b = np.asarray(self.bounds_mm, dtype=float)\n",
        "        x = c + rng.uniform(-b, b)\n",
        "        return (float(x[0]), float(x[1]), float(x[2]))\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class FocusSiteSpec:\n",
        "    \"\"\"One candidate onset site (primary or secondary).\"\"\"\n",
        "    xyz_mm: Vec3\n",
        "    baseline_strength: float\n",
        "    baseline_drive_hz: float\n",
        "    baseline_weight: float\n",
        "    site_type: str = \"secondary\"  # secondary / latent / primary / control\n",
        "\n",
        "    @property\n",
        "    def xyz(self) -> np.ndarray:\n",
        "        return np.asarray(self.xyz_mm, dtype=float)\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class FocusClusterSpec:\n",
        "    \"\"\"Primary focus described by a cluster plus (optional) multiple sites within it.\"\"\"\n",
        "    center_mm: Vec3\n",
        "    radius_mm: float\n",
        "    n_sites: int = 1\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class OnsetSpec:\n",
        "    \"\"\"Primary focus cluster + explicit secondary sites.\"\"\"\n",
        "    primary_cluster: FocusClusterSpec\n",
        "    primary_sites: Tuple[FocusSiteSpec, ...]\n",
        "    secondary_sites: Tuple[FocusSiteSpec, ...]\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class NetworkVariantSpec:\n",
        "    \"\"\"Per-case overrides for neuron composition / counts.\"\"\"\n",
        "    n_total: int = 80\n",
        "    frac_gm: float = 0.7\n",
        "    frac_exc_in_gm: float = 0.75\n",
        "    frac_inh_fast_in_gm: float = 0.15\n",
        "    frac_inh_slow_in_gm: float = 0.10\n",
        "    wm_axon_params: Dict[str, float] = field(default_factory=lambda: {\"L_um\": 800.0, \"diam_um\": 1.0, \"nseg\": 9})\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        if not (0.0 <= self.frac_gm <= 1.0):\n",
        "            raise ValueError(\"frac_gm must be in [0,1].\")\n",
        "        s = self.frac_exc_in_gm + self.frac_inh_fast_in_gm + self.frac_inh_slow_in_gm\n",
        "        if abs(s - 1.0) > 1e-6:\n",
        "            raise ValueError(\"GM fractions must sum to 1.0 (exc + inh_fast + inh_slow).\")\n",
        "        if self.n_total <= 0:\n",
        "            raise ValueError(\"n_total must be > 0.\")\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class ConnectivityVariantSpec:\n",
        "    \"\"\"Per-case connectivity regime knobs (may be ignored by a minimal plant).\"\"\"\n",
        "    regime: ConnectivityRegime = \"none\"\n",
        "    p_conn: float = 0.0\n",
        "    w_exc: float = 0.01\n",
        "    w_inh: float = 0.01\n",
        "    delay_ms_range: Tuple[float, float] = (1.0, 5.0)\n",
        "    e_i_balance_mode: str = \"fixed\"\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        if not (0.0 <= self.p_conn <= 1.0):\n",
        "            raise ValueError(\"p_conn must be in [0,1].\")\n",
        "        lo, hi = self.delay_ms_range\n",
        "        if lo < 0.0 or hi < lo:\n",
        "            raise ValueError(\"delay_ms_range must satisfy 0 <= lo <= hi.\")\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class CaseSpec:\n",
        "    \"\"\"A complete scenario instance.\"\"\"\n",
        "    case_id: str\n",
        "    rng_seed: int\n",
        "\n",
        "    electrode: ElectrodeSpec\n",
        "    tissue: TissueSpec\n",
        "    region: RegionSpec\n",
        "    onset: OnsetSpec\n",
        "\n",
        "    severity: float\n",
        "    baseline_burden: float\n",
        "    excitability: Dict[str, float] = field(default_factory=dict)\n",
        "\n",
        "    network_variant: NetworkVariantSpec = field(default_factory=NetworkVariantSpec)\n",
        "    connectivity_variant: ConnectivityVariantSpec = field(default_factory=ConnectivityVariantSpec)\n",
        "\n",
        "    descriptors: Dict[str, float] = field(default_factory=dict)\n",
        "    tags: Dict[str, object] = field(default_factory=dict)\n",
        "\n",
        "    primary_onsets_xyz_mm: List[List[float]] = field(default_factory=list)\n",
        "    secondary_onsets_xyz_mm: List[List[float]] = field(default_factory=list)\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        if not (0.0 <= self.severity <= 2.0):\n",
        "            raise ValueError(\"severity expected in [0,2] (recommended [0,1]).\")\n",
        "        if self.baseline_burden < 0.0:\n",
        "            raise ValueError(\"baseline_burden must be >= 0.\")\n",
        "        self.network_variant.validate()\n",
        "        self.connectivity_variant.validate()\n",
        "\n",
        "    @property\n",
        "    def primary_center_mm(self) -> Vec3:\n",
        "        return self.onset.primary_cluster.center_mm\n",
        "\n",
        "    def dist_electrode_to_primary_mm(self) -> float:\n",
        "        e = self.electrode.xyz\n",
        "        c = np.asarray(self.primary_center_mm, dtype=float)\n",
        "        return float(np.linalg.norm(e - c))\n",
        "\n",
        "    def boundary_signed_dist_primary_mm(self) -> Optional[float]:\n",
        "        if self.tissue.mode != \"BOUNDARY\" or self.tissue.boundary is None:\n",
        "            return None\n",
        "        return self.tissue.boundary.signed_distance_mm(self.primary_center_mm)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Helper functions\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def _unit(v: np.ndarray) -> np.ndarray:\n",
        "    n = float(np.linalg.norm(v))\n",
        "    if n < 1e-12:\n",
        "        return np.array([1.0, 0.0, 0.0], dtype=float)\n",
        "    return v / n\n",
        "\n",
        "\n",
        "def _stable_hash_to_int(s: str, mod: int = 2**31 - 1) -> int:\n",
        "    h = hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n",
        "    return int(h[:16], 16) % mod\n",
        "\n",
        "\n",
        "def _case_id_from_fields(prefix: str, fields: Dict[str, object]) -> str:\n",
        "    # Deterministic and human-readable-ish\n",
        "    parts = [prefix]\n",
        "    for k in sorted(fields.keys()):\n",
        "        v = fields[k]\n",
        "        if isinstance(v, float):\n",
        "            parts.append(f\"{k}={v:.4g}\")\n",
        "        else:\n",
        "            parts.append(f\"{k}={v}\")\n",
        "    base = \"|\".join(parts)\n",
        "    short = hashlib.md5(base.encode(\"utf-8\")).hexdigest()[:10]\n",
        "    return f\"{prefix}-{short}\"\n",
        "\n",
        "\n",
        "def place_electrode_at_distance(\n",
        "    primary_center_mm: Vec3,\n",
        "    dist_mm: float,\n",
        "    rng: np.random.Generator,\n",
        "    ray_mode: Literal[\"random\", \"canonical\"] = \"random\",\n",
        "    canonical_axis: Optional[Literal[\"+x\", \"-x\", \"+y\", \"-y\", \"+z\", \"-z\"]] = None,\n",
        ") -> Tuple[Vec3, Vec3]:\n",
        "    \"\"\"\n",
        "    Place electrode exactly dist_mm from primary center along a ray direction.\n",
        "    Returns (electrode_xyz_mm, ray_dir_unit).\n",
        "    \"\"\"\n",
        "    c = np.asarray(primary_center_mm, dtype=float)\n",
        "\n",
        "    if ray_mode == \"canonical\":\n",
        "        axis = canonical_axis or \"+x\"\n",
        "        mapping = {\n",
        "            \"+x\": np.array([1.0, 0.0, 0.0]),\n",
        "            \"-x\": np.array([-1.0, 0.0, 0.0]),\n",
        "            \"+y\": np.array([0.0, 1.0, 0.0]),\n",
        "            \"-y\": np.array([0.0, -1.0, 0.0]),\n",
        "            \"+z\": np.array([0.0, 0.0, 1.0]),\n",
        "            \"-z\": np.array([0.0, 0.0, -1.0]),\n",
        "        }\n",
        "        u = mapping[axis]\n",
        "    else:\n",
        "        # Uniform on sphere using normal then normalize\n",
        "        u = _unit(rng.normal(size=3))\n",
        "\n",
        "    e = c + float(dist_mm) * u\n",
        "    return (float(e[0]), float(e[1]), float(e[2])), (float(u[0]), float(u[1]), float(u[2]))\n",
        "\n",
        "\n",
        "def sample_boundary_plane(\n",
        "    rng: np.random.Generator,\n",
        "    point_mm: Vec3,\n",
        "    normal_mode: Literal[\"random\", \"canonical\"] = \"random\",\n",
        "    canonical_axis: Optional[Literal[\"+x\", \"-x\", \"+y\", \"-y\", \"+z\", \"-z\"]] = None,\n",
        ") -> BoundaryPlane:\n",
        "    p = point_mm\n",
        "    if normal_mode == \"canonical\":\n",
        "        axis = canonical_axis or \"+z\"\n",
        "        mapping = {\n",
        "            \"+x\": (1.0, 0.0, 0.0),\n",
        "            \"-x\": (-1.0, 0.0, 0.0),\n",
        "            \"+y\": (0.0, 1.0, 0.0),\n",
        "            \"-y\": (0.0, -1.0, 0.0),\n",
        "            \"+z\": (0.0, 0.0, 1.0),\n",
        "            \"-z\": (0.0, 0.0, -1.0),\n",
        "        }\n",
        "        n = mapping[axis]\n",
        "        return BoundaryPlane(point_mm=p, normal_unit=n)\n",
        "    n = _unit(rng.normal(size=3))\n",
        "    return BoundaryPlane(point_mm=p, normal_unit=(float(n[0]), float(n[1]), float(n[2])))\n",
        "\n",
        "\n",
        "def _beta_strength(rng: np.random.Generator, a: float, b: float, lo: float = 0.0, hi: float = 1.0) -> float:\n",
        "    x = float(rng.beta(a, b))\n",
        "    return lo + (hi - lo) * x\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Generators\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "@dataclass\n",
        "class CaseGeneratorConfig:\n",
        "\n",
        "    forced_tissue_mode: Optional[str] = None\n",
        "\n",
        "    \"\"\"Ranges and options for training-time case sampling.\"\"\"\n",
        "    # Tissue mode proportions\n",
        "    p_gm: float = 0.34\n",
        "    p_wm: float = 0.33\n",
        "    p_boundary: float = 0.33\n",
        "\n",
        "    # Region geometry\n",
        "    region_bounds_mm: Vec3 = (3.0, 3.0, 3.0)\n",
        "\n",
        "    # Electrode distance sweep range\n",
        "    electrode_dist_mm_range: Tuple[float, float] = (0.5, 5.0)\n",
        "    electrode_ray_mode: Literal[\"random\", \"canonical\"] = \"random\"\n",
        "\n",
        "    # Boundary options\n",
        "    boundary_normal_mode: Literal[\"random\", \"canonical\"] = \"random\"\n",
        "\n",
        "    # Severity range\n",
        "    severity_range: Tuple[float, float] = (0.1, 0.95)\n",
        "\n",
        "    # Primary cluster\n",
        "    primary_cluster_radius_mm_range: Tuple[float, float] = (0.4, 1.0)\n",
        "    n_primary_sites_range: Tuple[int, int] = (1, 5)\n",
        "\n",
        "    # Secondary foci\n",
        "    n_secondary_range: Tuple[int, int] = (3, 12)\n",
        "    secondary_mix: Tuple[float, float, float] = (0.5, 0.35, 0.15)  # near, mid, far fractions\n",
        "\n",
        "    # Baseline drive parameters\n",
        "    # (In minimal HH+Exp2Syn plants, 0.01–0.03 is often subthreshold; widen for spiking regimes.)\n",
        "    drive_rate_hz_range: Tuple[float, float] = (20.0, 80.0)\n",
        "    drive_weight_range: Tuple[float, float] = (0.05, 0.40)\n",
        "\n",
        "\n",
        "    # Secondary site baseline strength distribution (latent-leaning)\n",
        "    secondary_strength_beta: Tuple[float, float] = (2.0, 6.0)\n",
        "\n",
        "    # Network composition variability\n",
        "    n_total_range: Tuple[int, int] = (60, 120)\n",
        "    frac_gm_range: Tuple[float, float] = (0.55, 0.85)\n",
        "    frac_exc_in_gm_range: Tuple[float, float] = (0.65, 0.85)\n",
        "    frac_inh_fast_in_gm_range: Tuple[float, float] = (0.10, 0.25)\n",
        "    # inh_slow is 1 - exc - inh_fast (clamped)\n",
        "\n",
        "    # Connectivity regime sampling\n",
        "    connectivity_regimes: Tuple[ConnectivityRegime, ...] = (\"none\", \"sparse\", \"dense\")\n",
        "    p_conn_by_regime: Dict[ConnectivityRegime, Tuple[float, float]] = field(\n",
        "        default_factory=lambda: {\n",
        "            \"none\": (0.0, 0.0),\n",
        "            \"sparse\": (0.01, 0.05),\n",
        "            \"dense\": (0.05, 0.15),\n",
        "            \"small_world\": (0.03, 0.10),\n",
        "            \"clustered\": (0.03, 0.10),\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Conductivities (defaults, can be varied externally)\n",
        "    sigma_gm_S_per_m: float = 0.2\n",
        "    sigma_wm_S_per_m: float = 0.14\n",
        "\n",
        "\n",
        "class CaseGenerator:\n",
        "    \"\"\"Stochastic training-time case sampler with reproducibility.\"\"\"\n",
        "    def __init__(self, cfg: Optional[CaseGeneratorConfig] = None, rng_seed: int = 0):\n",
        "        self.cfg = cfg or CaseGeneratorConfig()\n",
        "        self._root_seed = int(rng_seed)\n",
        "        self._rng = np.random.default_rng(self._root_seed)\n",
        "\n",
        "        # Normalize tissue probabilities\n",
        "        s = self.cfg.p_gm + self.cfg.p_wm + self.cfg.p_boundary\n",
        "        if s <= 0:\n",
        "            raise ValueError(\"Invalid tissue probabilities: sum must be > 0.\")\n",
        "        self._p = np.array([self.cfg.p_gm, self.cfg.p_wm, self.cfg.p_boundary], dtype=float) / s\n",
        "        self._modes: Tuple[TissueMode, ...] = (\"GM\", \"WM\", \"BOUNDARY\")\n",
        "\n",
        "    def _spawn_case_rng(self) -> Tuple[int, np.random.Generator]:\n",
        "        # Each case gets its own seed derived from the root RNG\n",
        "        case_seed = int(self._rng.integers(1, 2**31 - 1))\n",
        "        return case_seed, np.random.default_rng(case_seed)\n",
        "\n",
        "    def sample(self, *, tags: Optional[Dict[str, object]] = None) -> CaseSpec:\n",
        "        \"\"\"Sample one randomized case.\"\"\"\n",
        "        tags = dict(tags or {})\n",
        "\n",
        "        # 1) Decide forced tissue mode (tags override config)\n",
        "        forced_mode = None\n",
        "\n",
        "        # Config-level forcing (if provided)\n",
        "        cfg_forced = getattr(self.cfg, \"forced_tissue_mode\", None)\n",
        "        if cfg_forced is not None:\n",
        "            cfg_forced = str(cfg_forced).upper().strip()\n",
        "            if cfg_forced != \"\":\n",
        "                forced_mode = cfg_forced\n",
        "\n",
        "        # Per-sample forcing overrides config\n",
        "        tag_forced = tags.get(\"forced_tissue_mode\", None)\n",
        "        if tag_forced is not None:\n",
        "            tag_forced = str(tag_forced).upper().strip()\n",
        "            if tag_forced != \"\":\n",
        "                forced_mode = tag_forced\n",
        "\n",
        "        # 2) Validate only if forcing is requested\n",
        "        if forced_mode is not None and forced_mode not in (\"GM\", \"WM\", \"BOUNDARY\"):\n",
        "            raise ValueError(f\"Invalid forced_tissue_mode: {forced_mode}\")\n",
        "\n",
        "        # 3) Spawn RNG for this case\n",
        "        case_seed, rng = self._spawn_case_rng()\n",
        "        cfg = self.cfg\n",
        "\n",
        "        # 4) Select tissue mode\n",
        "        if forced_mode is not None:\n",
        "            tissue_mode: TissueMode = forced_mode  # type: ignore[assignment]\n",
        "            tags[\"forced_tissue_mode\"] = forced_mode  # persist into CaseSpec.tags\n",
        "        else:\n",
        "            tissue_mode: TissueMode = self._modes[int(rng.choice(len(self._modes), p=self._p))]\n",
        "\n",
        "        # Severity and baseline burden\n",
        "        severity = float(rng.uniform(*cfg.severity_range))\n",
        "        baseline_burden = float(max(0.0, severity))  # explicit; can be a nonlinear map later\n",
        "\n",
        "        # Region & primary center\n",
        "        region_center = (0.0, 0.0, 0.0)\n",
        "        region = RegionSpec(center_mm=region_center, bounds_mm=cfg.region_bounds_mm, density_mode=\"uniform\")\n",
        "        primary_center = region.sample_point_mm(rng)\n",
        "\n",
        "        # Primary cluster\n",
        "        r_primary = float(rng.uniform(*cfg.primary_cluster_radius_mm_range))\n",
        "        n_primary_sites = int(rng.integers(cfg.n_primary_sites_range[0], cfg.n_primary_sites_range[1] + 1))\n",
        "        primary_cluster = FocusClusterSpec(center_mm=primary_center, radius_mm=r_primary, n_sites=n_primary_sites)\n",
        "\n",
        "        # Electrode at a controlled distance\n",
        "        dist_mm = float(rng.uniform(*cfg.electrode_dist_mm_range))\n",
        "        electrode_xyz, ray_dir = place_electrode_at_distance(\n",
        "            primary_center_mm=primary_center,\n",
        "            dist_mm=dist_mm,\n",
        "            rng=rng,\n",
        "            ray_mode=cfg.electrode_ray_mode,\n",
        "            canonical_axis=None,\n",
        "        )\n",
        "        electrode = ElectrodeSpec(xyz_mm=electrode_xyz, orientation_unit=(0.0, 0.0, 1.0), model=\"point_source\")\n",
        "\n",
        "        # Tissue spec (+ boundary plane if needed)\n",
        "        boundary = None\n",
        "        if tissue_mode == \"BOUNDARY\":\n",
        "            # Place boundary plane through primary center for now (can shift later)\n",
        "            boundary = sample_boundary_plane(\n",
        "                rng=rng,\n",
        "                point_mm=primary_center,\n",
        "                normal_mode=cfg.boundary_normal_mode,\n",
        "            )\n",
        "        tissue = TissueSpec(\n",
        "            mode=tissue_mode,\n",
        "            sigma_gm_S_per_m=cfg.sigma_gm_S_per_m,\n",
        "            sigma_wm_S_per_m=cfg.sigma_wm_S_per_m,\n",
        "            boundary=boundary,\n",
        "            anisotropy=None,\n",
        "        )\n",
        "\n",
        "       # Baseline drive params (primary)\n",
        "        primary_drive_hz = float(rng.uniform(*cfg.drive_rate_hz_range))\n",
        "        primary_weight = float(rng.uniform(*cfg.drive_weight_range))\n",
        "\n",
        "        # Couple severity into the generated onset drive so higher severity cases are genuinely more excitable.\n",
        "        # Keep names the same; just scale the sampled values.\n",
        "        drive_scale = 0.8 + 0.6 * severity\n",
        "        syn_weight_scale = 0.9 + 0.4 * severity\n",
        "\n",
        "        primary_drive_hz *= drive_scale\n",
        "        primary_weight *= syn_weight_scale\n",
        "\n",
        "\n",
        "        # Primary sites (within cluster)\n",
        "        primary_sites: List[FocusSiteSpec] = []\n",
        "        for _ in range(n_primary_sites):\n",
        "            # Uniform in ball: sample direction * radius * u^(1/3)\n",
        "            d = _unit(rng.normal(size=3))\n",
        "            u = float(rng.uniform(0.0, 1.0)) ** (1.0 / 3.0)\n",
        "            offset = d * (u * r_primary)\n",
        "            xyz = tuple((np.asarray(primary_center) + offset).tolist())\n",
        "            primary_sites.append(\n",
        "                FocusSiteSpec(\n",
        "                    xyz_mm=(float(xyz[0]), float(xyz[1]), float(xyz[2])),\n",
        "                    baseline_strength=float(rng.uniform(0.9, 1.0)),\n",
        "                    baseline_drive_hz=primary_drive_hz,\n",
        "                    baseline_weight=primary_weight,\n",
        "                    site_type=\"primary\",\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Secondary sites mixture: near/mid/far shells around primary\n",
        "        n_secondary = int(rng.integers(cfg.n_secondary_range[0], cfg.n_secondary_range[1] + 1))\n",
        "        mix = np.asarray(cfg.secondary_mix, dtype=float)\n",
        "        mix = mix / (mix.sum() + 1e-12)\n",
        "        n_near = int(round(n_secondary * mix[0]))\n",
        "        n_mid = int(round(n_secondary * mix[1]))\n",
        "        n_far = max(0, n_secondary - n_near - n_mid)\n",
        "\n",
        "        # Define distance shells (relative to primary radius)\n",
        "        # near: [0.8r, 2r], mid: [2r, 4r], far: [4r, 7r] (clipped by region bounds implicitly)\n",
        "        shells = (\n",
        "            (0.8 * r_primary, 2.0 * r_primary, n_near),\n",
        "            (2.0 * r_primary, 4.0 * r_primary, n_mid),\n",
        "            (4.0 * r_primary, 7.0 * r_primary, n_far),\n",
        "        )\n",
        "\n",
        "        a_beta, b_beta = cfg.secondary_strength_beta\n",
        "        secondary_sites: List[FocusSiteSpec] = []\n",
        "        for r_lo, r_hi, count in shells:\n",
        "            for _ in range(count):\n",
        "                d = _unit(rng.normal(size=3))\n",
        "                rad = float(rng.uniform(r_lo, r_hi))\n",
        "                xyz = np.asarray(primary_center) + d * rad\n",
        "                strength = _beta_strength(rng, a_beta, b_beta, lo=0.0, hi=1.0)\n",
        "\n",
        "                sec_drive_hz = float(primary_drive_hz * (0.4 + 0.6 * strength) * rng.uniform(0.7, 1.1))\n",
        "                sec_weight   = float(primary_weight   * (0.4 + 0.6 * strength) * rng.uniform(0.7, 1.1))\n",
        "\n",
        "                # Floors to avoid secondaries becoming completely inert\n",
        "                sec_drive_hz = max(5.0, sec_drive_hz)\n",
        "                sec_weight   = max(0.02, sec_weight)\n",
        "\n",
        "\n",
        "                site_type = \"latent\" if strength < 0.35 else \"secondary\"\n",
        "                secondary_sites.append(\n",
        "                    FocusSiteSpec(\n",
        "                        xyz_mm=(float(xyz[0]), float(xyz[1]), float(xyz[2])),\n",
        "                        baseline_strength=float(strength),\n",
        "                        baseline_drive_hz=sec_drive_hz,\n",
        "                        baseline_weight=sec_weight,\n",
        "                        site_type=site_type,\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        onset = OnsetSpec(\n",
        "            primary_cluster=primary_cluster,\n",
        "            primary_sites=tuple(primary_sites),\n",
        "            secondary_sites=tuple(secondary_sites),\n",
        "        )\n",
        "\n",
        "        # Per-case network variant\n",
        "        n_total = int(rng.integers(cfg.n_total_range[0], cfg.n_total_range[1] + 1))\n",
        "        frac_gm = float(rng.uniform(*cfg.frac_gm_range))\n",
        "        frac_exc = float(rng.uniform(*cfg.frac_exc_in_gm_range))\n",
        "        frac_inh_fast = float(rng.uniform(*cfg.frac_inh_fast_in_gm_range))\n",
        "\n",
        "        # Ensure remaining fraction is valid\n",
        "        frac_inh_slow = max(0.0, 1.0 - frac_exc - frac_inh_fast)\n",
        "        # If we overshot, renormalize exc/inh_fast to leave at least 0.05 slow\n",
        "        if frac_inh_slow < 0.05:\n",
        "            target_slow = 0.05\n",
        "            remaining = 1.0 - target_slow\n",
        "            # scale exc and inh_fast to sum to remaining\n",
        "            s2 = frac_exc + frac_inh_fast\n",
        "            if s2 < 1e-9:\n",
        "                frac_exc, frac_inh_fast = remaining * 0.75, remaining * 0.25\n",
        "            else:\n",
        "                frac_exc = frac_exc / s2 * remaining\n",
        "                frac_inh_fast = frac_inh_fast / s2 * remaining\n",
        "            frac_inh_slow = target_slow\n",
        "\n",
        "        network_variant = NetworkVariantSpec(\n",
        "            n_total=n_total,\n",
        "            frac_gm=frac_gm,\n",
        "            frac_exc_in_gm=frac_exc,\n",
        "            frac_inh_fast_in_gm=frac_inh_fast,\n",
        "            frac_inh_slow_in_gm=frac_inh_slow,\n",
        "            wm_axon_params={\"L_um\": 800.0, \"diam_um\": 1.0, \"nseg\": 9},\n",
        "        )\n",
        "\n",
        "        # Connectivity variant\n",
        "        regime = str(rng.choice(cfg.connectivity_regimes))\n",
        "        p_lo, p_hi = cfg.p_conn_by_regime.get(regime, (0.0, 0.0))\n",
        "        p_conn = float(rng.uniform(p_lo, p_hi))\n",
        "        connectivity_variant = ConnectivityVariantSpec(\n",
        "            regime=regime,  # type: ignore[arg-type]\n",
        "            p_conn=p_conn,\n",
        "            w_exc=float(rng.uniform(0.005, 0.02)),\n",
        "            w_inh=float(rng.uniform(0.005, 0.02)),\n",
        "            delay_ms_range=(1.0, 5.0),\n",
        "            e_i_balance_mode=\"fixed\",\n",
        "        )\n",
        "\n",
        "        # Excitability mapping (minimal but explicit)\n",
        "        excitability = {\n",
        "            \"drive_scale\": 0.8 + 0.6 * severity,\n",
        "            \"noise_scale\": 0.8 + 0.8 * severity,\n",
        "            \"syn_weight_scale\": 0.9 + 0.4 * severity,\n",
        "        }\n",
        "\n",
        "        # Descriptors for optional policy conditioning\n",
        "        descriptors: Dict[str, float] = {\n",
        "            \"severity\": float(severity),\n",
        "            \"dist_electrode_to_primary_mm\": float(dist_mm),\n",
        "            \"n_secondary\": float(n_secondary),\n",
        "            \"frac_gm\": float(frac_gm),\n",
        "        }\n",
        "        if tissue_mode == \"BOUNDARY\" and boundary is not None:\n",
        "            descriptors[\"boundary_signed_dist_primary_mm\"] = float(boundary.signed_distance_mm(primary_center))\n",
        "            # also store boundary normal components for analysis if desired\n",
        "            descriptors[\"boundary_nx\"] = float(boundary.normal_unit[0])\n",
        "            descriptors[\"boundary_ny\"] = float(boundary.normal_unit[1])\n",
        "            descriptors[\"boundary_nz\"] = float(boundary.normal_unit[2])\n",
        "\n",
        "        # Stable deterministic ID for this sampled case (seed included)\n",
        "        id_fields = {\n",
        "            \"seed\": case_seed,\n",
        "            \"mode\": tissue_mode,\n",
        "            \"sev\": severity,\n",
        "            \"dist\": dist_mm,\n",
        "            \"ns\": n_secondary,\n",
        "            \"ntot\": n_total,\n",
        "            \"reg\": regime,\n",
        "        }\n",
        "        case_id = _case_id_from_fields(\"case\", id_fields)\n",
        "\n",
        "        primary_onsets_xyz_mm = [list(s.xyz_mm) for s in onset.primary_sites]\n",
        "        secondary_onsets_xyz_mm = [list(s.xyz_mm) for s in onset.secondary_sites]\n",
        "\n",
        "\n",
        "        case = CaseSpec(\n",
        "            case_id=case_id,\n",
        "            rng_seed=case_seed,\n",
        "            electrode=electrode,\n",
        "            tissue=tissue,\n",
        "            region=RegionSpec(center_mm=region_center, bounds_mm=cfg.region_bounds_mm, density_mode=\"uniform\"),\n",
        "            onset=onset,\n",
        "            severity=severity,\n",
        "            baseline_burden=baseline_burden,\n",
        "            excitability=excitability,\n",
        "            network_variant=network_variant,\n",
        "            connectivity_variant=connectivity_variant,\n",
        "            descriptors=descriptors,\n",
        "            tags=tags or {},\n",
        "            primary_onsets_xyz_mm=primary_onsets_xyz_mm,\n",
        "            secondary_onsets_xyz_mm=secondary_onsets_xyz_mm,\n",
        "        )\n",
        "        case.validate()\n",
        "        return case\n",
        "\n",
        "    def sample_n(self, n: int, *, tags: Optional[Dict[str, object]] = None) -> List[CaseSpec]:\n",
        "        if n <= 0:\n",
        "            return []\n",
        "        return [self.sample(tags=tags) for _ in range(n)]\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Deterministic case suites\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class SuiteAxis:\n",
        "    name: str\n",
        "    values: Tuple[object, ...]\n",
        "\n",
        "\n",
        "class CaseSuite:\n",
        "    \"\"\"\n",
        "    Deterministic evaluation suite builder.\n",
        "\n",
        "    Primary use: grid over tissue_mode × distance × severity, with optional\n",
        "    additional axes for boundary normals, connectivity regimes, and composition presets.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def grid(\n",
        "        *,\n",
        "        suite_seed: int,\n",
        "        tissue_modes: Sequence[TissueMode] = (\"GM\", \"WM\", \"BOUNDARY\"),\n",
        "        distances_mm: Sequence[float] = (0.5, 1.0, 2.0, 3.5, 5.0),\n",
        "        severities: Sequence[float] = (0.1, 0.3, 0.6, 0.9),\n",
        "        # Optional axes:\n",
        "        boundary_normals: Optional[Sequence[Vec3]] = None,\n",
        "        connectivity_regimes: Sequence[ConnectivityRegime] = (\"none\", \"sparse\", \"dense\"),\n",
        "        # Secondary / cluster settings (fixed or simple sweeps):\n",
        "        primary_cluster_radius_mm: float = 0.7,\n",
        "        n_primary_sites: int = 3,\n",
        "        n_secondary: int = 8,\n",
        "        # Network presets (optional; if None, use a default)\n",
        "        network_presets: Optional[Sequence[NetworkVariantSpec]] = None,\n",
        "        connectivity_presets: Optional[Sequence[ConnectivityVariantSpec]] = None,\n",
        "        # Conductivities:\n",
        "        sigma_gm_S_per_m: float = 0.2,\n",
        "        sigma_wm_S_per_m: float = 0.14,\n",
        "        # Ray mode for electrode placement:\n",
        "        ray_mode: Literal[\"canonical\", \"random\"] = \"canonical\",\n",
        "        canonical_rays: Sequence[Literal[\"+x\", \"-x\", \"+y\", \"-y\", \"+z\", \"-z\"]] = (\"+x\", \"+y\", \"+z\"),\n",
        "        # Secondary strength distribution:\n",
        "        secondary_strength_beta: Tuple[float, float] = (2.0, 6.0),\n",
        "        # Drive defaults:\n",
        "        drive_rate_hz: float = 40,\n",
        "        drive_weight: float = 0.15,\n",
        "        tag_overrides: Optional[Dict[str, object]] = None,\n",
        "    ) -> List[CaseSpec]:\n",
        "        rng = np.random.default_rng(int(suite_seed))\n",
        "\n",
        "        # Default boundary normals if boundary included and none provided\n",
        "        if boundary_normals is None:\n",
        "            boundary_normals = [(0.0, 0.0, 1.0), (1.0, 0.0, 0.0), (0.0, 1.0, 0.0)]\n",
        "\n",
        "        if network_presets is None:\n",
        "            network_presets = [\n",
        "                NetworkVariantSpec(n_total=80, frac_gm=0.7, frac_exc_in_gm=0.75, frac_inh_fast_in_gm=0.15, frac_inh_slow_in_gm=0.10),\n",
        "            ]\n",
        "\n",
        "        # If explicit connectivity presets are not provided, synthesize from regimes\n",
        "        if connectivity_presets is None:\n",
        "            presets: List[ConnectivityVariantSpec] = []\n",
        "            for reg in connectivity_regimes:\n",
        "                if reg == \"none\":\n",
        "                    presets.append(ConnectivityVariantSpec(regime=\"none\", p_conn=0.0))\n",
        "                elif reg == \"sparse\":\n",
        "                    presets.append(ConnectivityVariantSpec(regime=\"sparse\", p_conn=0.03))\n",
        "                elif reg == \"dense\":\n",
        "                    presets.append(ConnectivityVariantSpec(regime=\"dense\", p_conn=0.10))\n",
        "                else:\n",
        "                    presets.append(ConnectivityVariantSpec(regime=reg, p_conn=0.06))\n",
        "            connectivity_presets = presets\n",
        "\n",
        "        cases: List[CaseSpec] = []\n",
        "        ray_cycle = list(canonical_rays)\n",
        "        ray_idx = 0\n",
        "\n",
        "        # Fixed region for suite (keep comparable)\n",
        "        region_center = (0.0, 0.0, 0.0)\n",
        "        region_bounds = (3.0, 3.0, 3.0)\n",
        "        region = RegionSpec(center_mm=region_center, bounds_mm=region_bounds, density_mode=\"uniform\")\n",
        "\n",
        "        # Fixed primary center (can also be swept if desired)\n",
        "        primary_center = (0.0, 0.0, 0.0)\n",
        "\n",
        "        # Prepare primary sites inside cluster deterministically from suite_seed\n",
        "        def make_primary_sites(local_rng: np.random.Generator) -> Tuple[FocusSiteSpec, ...]:\n",
        "            sites: List[FocusSiteSpec] = []\n",
        "            for _ in range(n_primary_sites):\n",
        "                d = _unit(local_rng.normal(size=3))\n",
        "                u = float(local_rng.uniform(0.0, 1.0)) ** (1.0 / 3.0)\n",
        "                offset = d * (u * primary_cluster_radius_mm)\n",
        "                xyz = tuple((np.asarray(primary_center) + offset).tolist())\n",
        "                sites.append(\n",
        "                    FocusSiteSpec(\n",
        "                        xyz_mm=(float(xyz[0]), float(xyz[1]), float(xyz[2])),\n",
        "                        baseline_strength=1.0,\n",
        "                        baseline_drive_hz=float(drive_rate_hz),\n",
        "                        baseline_weight=float(drive_weight),\n",
        "                        site_type=\"primary\",\n",
        "                    )\n",
        "                )\n",
        "            return tuple(sites)\n",
        "\n",
        "        # Prepare secondary sites deterministically per case (seeded by case_id)\n",
        "        def make_secondary_sites(local_rng: np.random.Generator) -> Tuple[FocusSiteSpec, ...]:\n",
        "            a_beta, b_beta = secondary_strength_beta\n",
        "            sites: List[FocusSiteSpec] = []\n",
        "            # distribute secondary points in shells around the primary center\n",
        "            for i in range(n_secondary):\n",
        "                d = _unit(local_rng.normal(size=3))\n",
        "                # shell radius cycles from near to far\n",
        "                shell = i % 3\n",
        "                if shell == 0:\n",
        "                    rad = float(local_rng.uniform(0.8 * primary_cluster_radius_mm, 2.0 * primary_cluster_radius_mm))\n",
        "                elif shell == 1:\n",
        "                    rad = float(local_rng.uniform(2.0 * primary_cluster_radius_mm, 4.0 * primary_cluster_radius_mm))\n",
        "                else:\n",
        "                    rad = float(local_rng.uniform(4.0 * primary_cluster_radius_mm, 7.0 * primary_cluster_radius_mm))\n",
        "                xyz = np.asarray(primary_center) + d * rad\n",
        "                strength = _beta_strength(local_rng, a_beta, b_beta, lo=0.0, hi=1.0)\n",
        "                sec_drive_hz = float(drive_rate_hz * (0.4 + 0.6 * strength))\n",
        "                sec_weight = float(drive_weight * (0.4 + 0.6 * strength))\n",
        "                site_type = \"latent\" if strength < 0.35 else \"secondary\"\n",
        "                sites.append(\n",
        "                    FocusSiteSpec(\n",
        "                        xyz_mm=(float(xyz[0]), float(xyz[1]), float(xyz[2])),\n",
        "                        baseline_strength=float(strength),\n",
        "                        baseline_drive_hz=sec_drive_hz,\n",
        "                        baseline_weight=sec_weight,\n",
        "                        site_type=site_type,\n",
        "                    )\n",
        "                )\n",
        "            return tuple(sites)\n",
        "\n",
        "        for mode in tissue_modes:\n",
        "            for dist in distances_mm:\n",
        "                for sev in severities:\n",
        "                    for net in network_presets:\n",
        "                        for conn in connectivity_presets:\n",
        "                            # Deterministic ray direction selection\n",
        "                            if ray_mode == \"canonical\":\n",
        "                                axis = ray_cycle[ray_idx % len(ray_cycle)]\n",
        "                                ray_idx += 1\n",
        "                                electrode_xyz, ray_dir = place_electrode_at_distance(\n",
        "                                    primary_center_mm=primary_center,\n",
        "                                    dist_mm=float(dist),\n",
        "                                    rng=rng,  # rng not used in canonical path except fallback\n",
        "                                    ray_mode=\"canonical\",\n",
        "                                    canonical_axis=axis,\n",
        "                                )\n",
        "                            else:\n",
        "                                electrode_xyz, ray_dir = place_electrode_at_distance(\n",
        "                                    primary_center_mm=primary_center,\n",
        "                                    dist_mm=float(dist),\n",
        "                                    rng=rng,\n",
        "                                    ray_mode=\"random\",\n",
        "                                )\n",
        "\n",
        "                            electrode = ElectrodeSpec(xyz_mm=electrode_xyz, orientation_unit=(0.0, 0.0, 1.0), model=\"point_source\")\n",
        "\n",
        "                            boundary = None\n",
        "                            if mode == \"BOUNDARY\":\n",
        "                                # Choose a deterministic boundary normal cycling through provided normals\n",
        "                                n = boundary_normals[int((ray_idx + int(dist * 10) + int(sev * 100)) % len(boundary_normals))]\n",
        "                                boundary = BoundaryPlane(point_mm=primary_center, normal_unit=n)\n",
        "\n",
        "                            tissue = TissueSpec(\n",
        "                                mode=mode,\n",
        "                                sigma_gm_S_per_m=float(sigma_gm_S_per_m),\n",
        "                                sigma_wm_S_per_m=float(sigma_wm_S_per_m),\n",
        "                                boundary=boundary,\n",
        "                                anisotropy=None,\n",
        "                            )\n",
        "\n",
        "                            primary_cluster = FocusClusterSpec(center_mm=primary_center, radius_mm=float(primary_cluster_radius_mm), n_sites=int(n_primary_sites))\n",
        "\n",
        "                            # Deterministic per-case seed derived from suite_seed + grid coords\n",
        "                            id_fields = {\n",
        "                                \"suite\": int(suite_seed),\n",
        "                                \"mode\": mode,\n",
        "                                \"dist\": float(dist),\n",
        "                                \"sev\": float(sev),\n",
        "                                \"ntot\": int(net.n_total),\n",
        "                                \"reg\": conn.regime,\n",
        "                                \"p\": float(conn.p_conn),\n",
        "                            }\n",
        "                            case_id = _case_id_from_fields(\"suitecase\", id_fields)\n",
        "                            case_seed = _stable_hash_to_int(case_id, mod=2**31 - 1)\n",
        "                            local_rng = np.random.default_rng(case_seed)\n",
        "\n",
        "                            onset = OnsetSpec(\n",
        "                                primary_cluster=primary_cluster,\n",
        "                                primary_sites=make_primary_sites(local_rng),\n",
        "                                secondary_sites=make_secondary_sites(local_rng),\n",
        "                            )\n",
        "\n",
        "                            baseline_burden = float(max(0.0, float(sev)))\n",
        "\n",
        "                            descriptors: Dict[str, float] = {\n",
        "                                \"severity\": float(sev),\n",
        "                                \"dist_electrode_to_primary_mm\": float(dist),\n",
        "                                \"n_secondary\": float(n_secondary),\n",
        "                                \"frac_gm\": float(net.frac_gm),\n",
        "                            }\n",
        "                            if mode == \"BOUNDARY\" and boundary is not None:\n",
        "                                descriptors[\"boundary_signed_dist_primary_mm\"] = float(boundary.signed_distance_mm(primary_center))\n",
        "                                descriptors[\"boundary_nx\"] = float(boundary.normal_unit[0])\n",
        "                                descriptors[\"boundary_ny\"] = float(boundary.normal_unit[1])\n",
        "                                descriptors[\"boundary_nz\"] = float(boundary.normal_unit[2])\n",
        "\n",
        "                            excitability = {\n",
        "                                \"drive_scale\": 0.8 + 0.6 * float(sev),\n",
        "                                \"noise_scale\": 0.8 + 0.8 * float(sev),\n",
        "                                \"syn_weight_scale\": 0.9 + 0.4 * float(sev),\n",
        "                            }\n",
        "\n",
        "                            tags = dict(tag_overrides or {})\n",
        "                            tags.update({\"suite_seed\": int(suite_seed), \"mode\": mode})\n",
        "\n",
        "                            case = CaseSpec(\n",
        "                                case_id=case_id,\n",
        "                                rng_seed=int(case_seed),\n",
        "                                electrode=electrode,\n",
        "                                tissue=tissue,\n",
        "                                region=region,\n",
        "                                onset=onset,\n",
        "                                severity=float(sev),\n",
        "                                baseline_burden=baseline_burden,\n",
        "                                excitability=excitability,\n",
        "                                network_variant=net,\n",
        "                                connectivity_variant=conn,\n",
        "                                descriptors=descriptors,\n",
        "                                tags=tags,\n",
        "                            )\n",
        "                            case.validate()\n",
        "                            cases.append(case)\n",
        "\n",
        "        return cases\n",
        "\n",
        "\n",
        "__all__ = [\n",
        "    \"Vec3\",\n",
        "    \"TissueMode\",\n",
        "    \"ConnectivityRegime\",\n",
        "    \"ElectrodeSpec\",\n",
        "    \"BoundaryPlane\",\n",
        "    \"AnisotropySpec\",\n",
        "    \"TissueSpec\",\n",
        "    \"RegionSpec\",\n",
        "    \"FocusSiteSpec\",\n",
        "    \"FocusClusterSpec\",\n",
        "    \"OnsetSpec\",\n",
        "    \"NetworkVariantSpec\",\n",
        "    \"ConnectivityVariantSpec\",\n",
        "    \"CaseSpec\",\n",
        "    \"CaseGeneratorConfig\",\n",
        "    \"CaseGenerator\",\n",
        "    \"CaseSuite\",\n",
        "    \"SuiteAxis\",\n",
        "    \"place_electrode_at_distance\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "P_Z2JiEiau7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def burst_fraction_from_spikes(\n",
        "    spike_times_ms: np.ndarray,\n",
        "    isi_thresh_ms: float = 10.0,\n",
        "    min_spikes_in_burst: int = 3\n",
        ") -> float:\n",
        "    if spike_times_ms.size < min_spikes_in_burst:\n",
        "        return 0.0\n",
        "    st = np.sort(spike_times_ms)\n",
        "    isi = np.diff(st)\n",
        "    fast = isi < float(isi_thresh_ms)\n",
        "\n",
        "    count_in_bursts = 0\n",
        "    run_len = 0\n",
        "    for f in fast:\n",
        "        if f:\n",
        "            run_len += 1\n",
        "        else:\n",
        "            if run_len >= (min_spikes_in_burst - 1):\n",
        "                count_in_bursts += (run_len + 1)\n",
        "            run_len = 0\n",
        "    if run_len >= (min_spikes_in_burst - 1):\n",
        "        count_in_bursts += (run_len + 1)\n",
        "\n",
        "    return float(count_in_bursts) / float(st.size)\n",
        "\n",
        "def sync_from_spike_trains(\n",
        "    spike_lists_ms: List[np.ndarray],\n",
        "    window_ms: float,\n",
        "    bin_ms: float = 5.0\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Synchrony proxy:\n",
        "    - Bin population spikes in bin_ms windows\n",
        "    - Compute CV = std/mean of population bin counts\n",
        "    - Return tanh(CV) to keep in [0,1)\n",
        "    \"\"\"\n",
        "    if len(spike_lists_ms) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    n_bins = int(np.ceil(float(window_ms) / float(bin_ms)))\n",
        "    if n_bins <= 1:\n",
        "        return 0.0\n",
        "\n",
        "    pop = np.zeros(n_bins, dtype=float)\n",
        "    for st in spike_lists_ms:\n",
        "        if st.size == 0:\n",
        "            continue\n",
        "        idx = np.floor(st / float(bin_ms)).astype(int)\n",
        "        idx = idx[(idx >= 0) & (idx < n_bins)]\n",
        "        if idx.size:\n",
        "            pop += np.bincount(idx, minlength=n_bins).astype(float)\n",
        "\n",
        "    mu = float(np.mean(pop))\n",
        "    if mu < 1e-9:\n",
        "        return 0.0\n",
        "\n",
        "    cv = float(np.std(pop)) / mu\n",
        "    return float(np.tanh(cv))\n"
      ],
      "metadata": {
        "id": "WjJb-bB7a2YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Level-1 NEURON plant (biophysical layer) for DBS parameter optimization in epilepsy.\n",
        "\n",
        "Design goals (project-aligned):\n",
        "- Spatially embedded GM (HH soma) + WM (passive cable axons) populations\n",
        "- Explicit CaseSpec-driven build (electrode position, tissue mode, boundary plane, onset sites)\n",
        "- Distance-based extracellular coupling (baseline point-source 1/r), extensible to sigma differences and boundary effects\n",
        "- Waveform generation per RL step (rectangular + optional biphasic/burst/duty cycle)\n",
        "- Primary + secondary seizure-onset drive via NetStim -> Exp2Syn, dynamically adjustable each step\n",
        "- Feature extraction per window: population rate, synchrony proxy, burst proxy, crude LFP proxy\n",
        "- Clean interface:\n",
        "    build_from_case(case, net_cfg=None)\n",
        "    precompute_coupling(stim_xyz_mm)\n",
        "    update_focus_drive(feedback)\n",
        "    run_window(stim_params) -> features dict\n",
        "\n",
        "Notes:\n",
        "- This file assumes NEURON is installed (pip install neuron).\n",
        "- If your environment is Colab, ensure you install NEURON and have a working compiler runtime.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Optional, Sequence, Tuple, Union\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# NEURON import (hard requirement to run)\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "try:\n",
        "    from neuron import h  # type: ignore\n",
        "except Exception as e:  # pragma: no cover\n",
        "    h = None  # type: ignore\n",
        "    _NEURON_IMPORT_ERROR = e\n",
        "else:\n",
        "    _NEURON_IMPORT_ERROR = None\n",
        "\n",
        "h.load_file(\"stdrun.hoc\")\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Types / Params\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "Vec3 = Tuple[float, float, float]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class StimParams:\n",
        "    \"\"\"\n",
        "    Stimulation parameters for one decision window.\n",
        "\n",
        "    Minimum required:\n",
        "    - amp_mA: amplitude (mA)\n",
        "    - freq_Hz: frequency (Hz)\n",
        "    - pw_ms: pulse width (ms)\n",
        "\n",
        "    Optional:\n",
        "    - waveform: \"rect\" | \"biphasic\" | \"burst\"\n",
        "    - duty_cycle: fraction [0..1] of time ON (simple on/off gating within window)\n",
        "    - biphasic:\n",
        "        * phase2_amp_ratio: amplitude ratio for phase 2 relative to phase 1 (usually -1 for charge balance)\n",
        "        * interphase_gap_ms: gap between phases\n",
        "    - burst:\n",
        "        * burst_Hz: bursts per second\n",
        "        * pulses_per_burst: integer\n",
        "        * intra_burst_freq_Hz: pulses per second inside burst\n",
        "    \"\"\"\n",
        "    amp_mA: float\n",
        "    freq_Hz: float\n",
        "    pw_ms: float\n",
        "\n",
        "    waveform: str = \"rect\"\n",
        "    duty_cycle: float = 1.0\n",
        "\n",
        "    phase2_amp_ratio: float = -1.0\n",
        "    interphase_gap_ms: float = 0.0\n",
        "\n",
        "    burst_Hz: float = 5.0\n",
        "    pulses_per_burst: int = 5\n",
        "    intra_burst_freq_Hz: float = 100.0\n",
        "\n",
        "\n",
        "def _as_stim_params(x: Union[StimParams, Dict[str, Any], Sequence[float]]) -> StimParams:\n",
        "    if isinstance(x, StimParams):\n",
        "        return x\n",
        "    if isinstance(x, dict):\n",
        "        return StimParams(**x)  # type: ignore[arg-type]\n",
        "    if isinstance(x, (list, tuple, np.ndarray)):\n",
        "        if len(x) < 3:\n",
        "            raise ValueError(\"stim_params sequence must have at least (amp_mA, freq_Hz, pw_ms).\")\n",
        "        return StimParams(float(x[0]), float(x[1]), float(x[2]))\n",
        "    raise TypeError(\"stim_params must be StimParams, dict, or sequence.\")\n",
        "\n",
        "\n",
        "def _unit(v: np.ndarray) -> np.ndarray:\n",
        "    n = float(np.linalg.norm(v))\n",
        "    if n < 1e-12:\n",
        "        return np.array([1.0, 0.0, 0.0], dtype=float)\n",
        "    return v / n\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Base Plant\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "class NeuronPlant:\n",
        "    def __init__(self, cfg: PlantConfig, rng_seed: int = 0):\n",
        "        if _NEURON_IMPORT_ERROR is not None:\n",
        "            raise RuntimeError(\n",
        "                \"NEURON is not available. Install with `pip install neuron` and ensure a working runtime.\"\n",
        "            ) from _NEURON_IMPORT_ERROR\n",
        "\n",
        "        self.cfg = cfg\n",
        "        self.rng_seed = int(rng_seed)\n",
        "        self.rng = np.random.default_rng(self.rng_seed)\n",
        "\n",
        "    # Interface expected by env\n",
        "    def build_from_case(self, case: CaseSpec, net_cfg: Optional[Any] = None) -> None:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def precompute_coupling(self, stim_xyz_mm: Vec3) -> None:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def update_focus_drive(self, feedback: Dict[str, Any]) -> None:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def run_window(self, stim_params: Union[StimParams, Dict[str, Any], Sequence[float]]) -> Dict[str, float]:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Full NEURON plant\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "from typing import Any, Dict, List, Optional, Sequence, Tuple, Union\n",
        "import math\n",
        "import numpy as np\n",
        "from neuron import h\n",
        "\n",
        "Vec3 = Tuple[float, float, float]\n",
        "\n",
        "\n",
        "class FullNeuronPlant(NeuronPlant):\n",
        "    \"\"\"\n",
        "    Level-1 NEURON plant for DBS parameter optimization.\n",
        "\n",
        "    Implements:\n",
        "    - build_from_case(case, net_cfg=None)\n",
        "    - precompute_coupling(stim_xyz_mm)\n",
        "    - update_focus_drive(feedback)\n",
        "    - run_window(stim_params) -> Dict[str,float]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg: PlantConfig, rng_seed: int = 0):\n",
        "        super().__init__(cfg, rng_seed=rng_seed)\n",
        "\n",
        "        # NEURON global settings\n",
        "        h.load_file(\"stdrun.hoc\")\n",
        "        h.dt = float(self.cfg.dt_ms)\n",
        "\n",
        "        # State\n",
        "        self.case: Optional[CaseSpec] = None\n",
        "        self.net_cfg: Optional[Any] = None\n",
        "        self.rng = np.random.default_rng(int(rng_seed))\n",
        "\n",
        "        # Populations\n",
        "        self.gm_secs: List[Any] = []\n",
        "        self.wm_secs: List[Any] = []\n",
        "        self.gm_xyz_mm: np.ndarray = np.zeros((0, 3), dtype=float)\n",
        "        self.wm_xyz_mm: np.ndarray = np.zeros((0, 3), dtype=float)\n",
        "        self._gm_types: List[str] = []\n",
        "\n",
        "        # Stimulation targets\n",
        "        self._stim_segs: List[Any] = []\n",
        "        self._stim_seg_xyz_mm: np.ndarray = np.zeros((0, 3), dtype=float)\n",
        "        self._stim_coupling_mV_per_mA: np.ndarray = np.zeros((0,), dtype=float)\n",
        "        self._stim_seg_types: List[str] = []\n",
        "        self._stim_play_vecs: List[Any] = []  # keep (vvec, tvec) alive\n",
        "\n",
        "        # Onset drives\n",
        "        self._primary_syns: List[Any] = []\n",
        "        self._primary_netstims: List[Any] = []\n",
        "        self._primary_netcons: List[Any] = []\n",
        "        self._primary_base_hz: List[float] = []\n",
        "        self._primary_base_w: List[float] = []\n",
        "\n",
        "        self._secondary_syns: List[Any] = []\n",
        "        self._secondary_netstims: List[Any] = []\n",
        "        self._secondary_netcons: List[Any] = []\n",
        "        self._secondary_base_hz: List[float] = []\n",
        "        self._secondary_base_w: List[float] = []\n",
        "\n",
        "        # Feedback scales (stored so they apply at build time too)\n",
        "        self._drive_rate_scale: float = 1.0\n",
        "        self._primary_rate_scale: float = 1.0\n",
        "        self._secondary_rate_scale: float = 1.0\n",
        "        self._primary_weight_scale: float = 1.0\n",
        "        self._secondary_weight_scale: float = 1.0\n",
        "        self._primary_site_scales = None\n",
        "        self._secondary_site_scales = None\n",
        "\n",
        "        # Recording\n",
        "        self._record_t: Any = None\n",
        "        self._record_vs: List[Any] = []\n",
        "        self._spike_vecs: List[Any] = []\n",
        "        self._spike_netcons: List[Any] = []\n",
        "        self._spike_cell_types: List[str] = []\n",
        "\n",
        "        # Last step\n",
        "        self._last_stim: Optional[StimParams] = None\n",
        "        self._last_features: Dict[str, float] = {}\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Build / reset\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def build_from_case(self, case: CaseSpec, net_cfg: Optional[Any] = None) -> None:\n",
        "        \"\"\"\n",
        "        Rebuild the NEURON model from scratch for a new CaseSpec.\n",
        "        \"\"\"\n",
        "        self.case = case\n",
        "        self.net_cfg = net_cfg\n",
        "\n",
        "        # Hard reset all NEURON sections\n",
        "        h(\"forall delete_section()\")\n",
        "\n",
        "        # Clear python-side containers\n",
        "        self.gm_secs.clear()\n",
        "        self.wm_secs.clear()\n",
        "        self._stim_segs.clear()\n",
        "        self._stim_play_vecs.clear()\n",
        "        self._stim_seg_types.clear()\n",
        "        self._stim_seg_xyz_mm = np.zeros((0, 3), dtype=float)\n",
        "        self._stim_coupling_mV_per_mA = np.zeros((0,), dtype=float)\n",
        "\n",
        "        self._primary_syns.clear()\n",
        "        self._primary_netstims.clear()\n",
        "        self._primary_netcons.clear()\n",
        "        self._primary_base_hz.clear()\n",
        "        self._primary_base_w.clear()\n",
        "\n",
        "        self._secondary_syns.clear()\n",
        "        self._secondary_netstims.clear()\n",
        "        self._secondary_netcons.clear()\n",
        "        self._secondary_base_hz.clear()\n",
        "        self._secondary_base_w.clear()\n",
        "\n",
        "        self._record_vs.clear()\n",
        "        self._spike_vecs.clear()\n",
        "        self._spike_netcons.clear()\n",
        "        self._spike_cell_types.clear()\n",
        "        self._record_t = None\n",
        "\n",
        "        # Resolve network parameters\n",
        "        n_total, frac_gm, frac_exc, frac_inh_fast, frac_inh_slow, ax_L_um, ax_diam_um, ax_nseg = \\\n",
        "            self._resolve_network_params(case, net_cfg)\n",
        "\n",
        "        n_gm = max(1, int(round(n_total * frac_gm)))\n",
        "        n_wm = max(1, n_total - n_gm)\n",
        "\n",
        "        # Sample positions in region\n",
        "        region_center = np.array(case.region.center_mm, dtype=float)\n",
        "        bounds = np.array(case.region.bounds_mm, dtype=float)\n",
        "\n",
        "        self.gm_xyz_mm = region_center + self.rng.uniform(-bounds, bounds, size=(n_gm, 3))\n",
        "        self.wm_xyz_mm = region_center + self.rng.uniform(-bounds, bounds, size=(n_wm, 3))\n",
        "\n",
        "        # Assign GM types\n",
        "        self._gm_types = self._assign_gm_types(n_gm, frac_exc, frac_inh_fast, frac_inh_slow)\n",
        "\n",
        "        # Build GM: HH soma + extracellular\n",
        "        for i in range(n_gm):\n",
        "            sec = h.Section(name=f\"gm_soma_{i}\")\n",
        "            sec.L = 20.0\n",
        "            sec.diam = 20.0\n",
        "            sec.nseg = 1\n",
        "            sec.insert(\"hh\")\n",
        "            sec.insert(\"extracellular\")\n",
        "            self._apply_excitability_to_hh(sec, getattr(case, \"excitability\", {}) or {}, self._gm_types[i])\n",
        "            self.gm_secs.append(sec)\n",
        "\n",
        "        # Build WM: passive axon + extracellular\n",
        "        for i in range(n_wm):\n",
        "            sec = h.Section(name=f\"wm_axon_{i}\")\n",
        "            sec.L = float(ax_L_um)\n",
        "            sec.diam = float(ax_diam_um)\n",
        "            sec.nseg = int(max(1, ax_nseg))\n",
        "            sec.insert(\"pas\")\n",
        "            sec.g_pas = 1e-4\n",
        "            sec.e_pas = -65.0\n",
        "            sec.insert(\"extracellular\")\n",
        "            self.wm_secs.append(sec)\n",
        "\n",
        "        # Collect segments to stimulate\n",
        "        self._stim_segs, self._stim_seg_xyz_mm = self._collect_stim_segments()\n",
        "\n",
        "        # Build onset drives (uses case.primary_onsets_xyz_mm / secondary_onsets_xyz_mm)\n",
        "        self._build_onset_drives(case)\n",
        "\n",
        "        # Setup recording (GM somas only)\n",
        "        self._setup_recording()\n",
        "\n",
        "        # Init\n",
        "        h.finitialize(-65.0)\n",
        "        h.t = 0.0\n",
        "\n",
        "    def _resolve_network_params(self, case: CaseSpec, net_cfg: Optional[Any]):\n",
        "        cfg = NetworkConfig() if net_cfg is None else net_cfg\n",
        "\n",
        "        nv = getattr(case, \"network_variant\", None)\n",
        "        if nv is not None:\n",
        "            n_total = int(getattr(nv, \"n_total\", getattr(cfg, \"n_total\", 80)))\n",
        "            frac_gm = float(getattr(nv, \"frac_gm\", getattr(cfg, \"frac_gm\", 0.7)))\n",
        "            frac_exc = float(getattr(nv, \"frac_exc_in_gm\", getattr(cfg, \"frac_exc_in_gm\", 0.75)))\n",
        "            frac_inh_fast = float(getattr(nv, \"frac_inh_fast_in_gm\", getattr(cfg, \"frac_inh_fast_in_gm\", 0.15)))\n",
        "            frac_inh_slow = float(getattr(nv, \"frac_inh_slow_in_gm\", getattr(cfg, \"frac_inh_slow_in_gm\", 0.10)))\n",
        "            wm_params = getattr(nv, \"wm_axon_params\", None) or {}\n",
        "            ax_L_um = float(wm_params.get(\"L_um\", getattr(cfg, \"axon_L_um\", 800.0)))\n",
        "            ax_diam_um = float(wm_params.get(\"diam_um\", getattr(cfg, \"axon_diam_um\", 1.0)))\n",
        "            ax_nseg = int(wm_params.get(\"nseg\", getattr(cfg, \"axon_nseg\", 9)))\n",
        "        else:\n",
        "            n_total = int(getattr(cfg, \"n_total\", 80))\n",
        "            frac_gm = float(getattr(cfg, \"frac_gm\", 0.7))\n",
        "            frac_exc = float(getattr(cfg, \"frac_exc_in_gm\", 0.75))\n",
        "            frac_inh_fast = float(getattr(cfg, \"frac_inh_fast_in_gm\", 0.15))\n",
        "            frac_inh_slow = float(getattr(cfg, \"frac_inh_slow_in_gm\", 0.10))\n",
        "            ax_L_um = float(getattr(cfg, \"axon_L_um\", 800.0))\n",
        "            ax_diam_um = float(getattr(cfg, \"axon_diam_um\", 1.0))\n",
        "            ax_nseg = int(getattr(cfg, \"axon_nseg\", 9))\n",
        "\n",
        "        frac_gm = float(np.clip(frac_gm, 0.05, 0.95))\n",
        "        s = frac_exc + frac_inh_fast + frac_inh_slow\n",
        "        if abs(s - 1.0) > 1e-6:\n",
        "            frac_exc, frac_inh_fast, frac_inh_slow = [x / s for x in (frac_exc, frac_inh_fast, frac_inh_slow)]\n",
        "        n_total = max(2, n_total)\n",
        "        ax_nseg = max(1, ax_nseg)\n",
        "\n",
        "        return n_total, frac_gm, frac_exc, frac_inh_fast, frac_inh_slow, ax_L_um, ax_diam_um, ax_nseg\n",
        "\n",
        "    def _assign_gm_types(self, n_gm: int, frac_exc: float, frac_inh_fast: float, frac_inh_slow: float) -> List[str]:\n",
        "        types = [\"E\"] * n_gm\n",
        "        n_exc = int(round(n_gm * frac_exc))\n",
        "        n_inh_fast = int(round(n_gm * frac_inh_fast))\n",
        "        idx = np.arange(n_gm)\n",
        "        self.rng.shuffle(idx)\n",
        "        for k in idx[n_exc:n_exc + n_inh_fast]:\n",
        "            types[int(k)] = \"I_fast\"\n",
        "        for k in idx[n_exc + n_inh_fast:]:\n",
        "            types[int(k)] = \"I_slow\"\n",
        "        return types\n",
        "\n",
        "    def _apply_excitability_to_hh(self, sec: Any, excitability: Dict[str, float], cell_type: str) -> None:\n",
        "        if not excitability:\n",
        "            return\n",
        "        drive_scale = float(excitability.get(\"drive_scale\", 1.0))\n",
        "        syn_scale = float(excitability.get(\"syn_weight_scale\", 1.0))\n",
        "        scale = float(np.clip(0.5 * drive_scale + 0.5 * syn_scale, 0.7, 1.5))\n",
        "        if str(cell_type).startswith(\"I\"):\n",
        "            scale *= 0.95\n",
        "        for seg in sec:\n",
        "            try:\n",
        "                seg.hh.gnabar *= scale\n",
        "                seg.hh.gkbar *= (0.9 + 0.1 * scale)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Segment collection + coupling\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _collect_stim_segments(self):\n",
        "        segs: List[Any] = []\n",
        "        xyz: List[List[float]] = []\n",
        "        types: List[str] = []\n",
        "\n",
        "        # GM soma centers\n",
        "        for i, sec in enumerate(self.gm_secs):\n",
        "            segs.append(sec(0.5))\n",
        "            xyz.append(self.gm_xyz_mm[i].tolist())\n",
        "            types.append(self._gm_types[i] if i < len(self._gm_types) else \"GM\")\n",
        "\n",
        "        # WM all segments (use same xyz per axon for simplicity)\n",
        "        for i, sec in enumerate(self.wm_secs):\n",
        "            for seg in sec:\n",
        "                segs.append(seg)\n",
        "                xyz.append(self.wm_xyz_mm[i].tolist())\n",
        "                types.append(\"WM\")\n",
        "\n",
        "        self._stim_seg_types = types\n",
        "        return segs, np.asarray(xyz, dtype=float)\n",
        "\n",
        "    def precompute_coupling(self, stim_xyz_mm: Vec3) -> None:\n",
        "        \"\"\"\n",
        "        Compute coupling (mV per mA) for each stimulated segment based on 1/(4*pi*sigma*r).\n",
        "        \"\"\"\n",
        "        if self.case is None:\n",
        "            raise RuntimeError(\"Call build_from_case() before precompute_coupling().\")\n",
        "\n",
        "        stim_xyz = np.asarray(stim_xyz_mm, dtype=float).reshape(1, 3)\n",
        "        seg_xyz = self._stim_seg_xyz_mm\n",
        "        if seg_xyz.size == 0:\n",
        "            self._stim_coupling_mV_per_mA = np.zeros((0,), dtype=float)\n",
        "            return\n",
        "\n",
        "        r_mm = np.linalg.norm(seg_xyz - stim_xyz, axis=1)\n",
        "        r_mm = np.maximum(r_mm, float(getattr(self.cfg, \"coupling_min_r_mm\", 0.15)))\n",
        "        r_m = r_mm * 1e-3\n",
        "\n",
        "        sigma = self._sigma_for_segments(self.case.tissue, seg_xyz)\n",
        "        sigma = np.maximum(sigma, 1e-6)\n",
        "\n",
        "        coeff_V_per_A = 1.0 / (4.0 * math.pi * sigma * r_m)\n",
        "\n",
        "        # In this convention, V/A * (mA) = mV (exact scaling), so store V/A as \"mV per mA\".\n",
        "        self._stim_coupling_mV_per_mA = coeff_V_per_A.astype(float)\n",
        "\n",
        "        # 8.2 Option A: type-dependent selectivity (optional)\n",
        "        kE = float(getattr(self.cfg, \"stim_selectivity_kE\", 1.0))\n",
        "        kI = float(getattr(self.cfg, \"stim_selectivity_kI\", 1.0))\n",
        "        if len(self._stim_seg_types) == len(self._stim_coupling_mV_per_mA):\n",
        "            mult = np.ones_like(self._stim_coupling_mV_per_mA, dtype=float)\n",
        "            for i, tp in enumerate(self._stim_seg_types):\n",
        "                if tp == \"E\":\n",
        "                    mult[i] = kE\n",
        "                elif str(tp).startswith(\"I\"):\n",
        "                    mult[i] = kI\n",
        "            self._stim_coupling_mV_per_mA *= mult\n",
        "\n",
        "    def _sigma_for_segments(self, tissue: Any, seg_xyz_mm: np.ndarray) -> np.ndarray:\n",
        "        mode = getattr(tissue, \"mode\", \"GM\")\n",
        "        sigma_gm = float(getattr(tissue, \"sigma_gm_S_per_m\", getattr(self.cfg, \"sigma_S_per_m\", 0.2)))\n",
        "        sigma_wm = float(getattr(tissue, \"sigma_wm_S_per_m\", getattr(self.cfg, \"sigma_S_per_m\", 0.14)))\n",
        "\n",
        "        if mode == \"GM\":\n",
        "            return np.full((seg_xyz_mm.shape[0],), sigma_gm, dtype=float)\n",
        "        if mode == \"WM\":\n",
        "            return np.full((seg_xyz_mm.shape[0],), sigma_wm, dtype=float)\n",
        "\n",
        "        boundary = getattr(tissue, \"boundary\", None)\n",
        "        if boundary is None:\n",
        "            return np.full((seg_xyz_mm.shape[0],), 0.5 * (sigma_gm + sigma_wm), dtype=float)\n",
        "\n",
        "        p = np.asarray(boundary.point_mm, dtype=float)\n",
        "        n = np.asarray(boundary.normal_unit, dtype=float)\n",
        "        n = _unit(n)\n",
        "        sd = (seg_xyz_mm - p.reshape(1, 3)) @ n.reshape(3, 1)\n",
        "        sd = sd.reshape(-1)\n",
        "        return np.where(sd >= 0.0, sigma_gm, sigma_wm).astype(float)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Onset drives (NetStim -> Exp2Syn)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _build_onset_drives(self, case: CaseSpec) -> None:\n",
        "        if len(self.gm_secs) == 0:\n",
        "            return\n",
        "\n",
        "        # Clear existing (avoid doubling)\n",
        "        self._primary_syns.clear()\n",
        "        self._primary_netstims.clear()\n",
        "        self._primary_netcons.clear()\n",
        "        self._primary_base_hz.clear()\n",
        "        self._primary_base_w.clear()\n",
        "\n",
        "        self._secondary_syns.clear()\n",
        "        self._secondary_netstims.clear()\n",
        "        self._secondary_netcons.clear()\n",
        "        self._secondary_base_hz.clear()\n",
        "        self._secondary_base_w.clear()\n",
        "\n",
        "        gm_xyz = np.asarray(self.gm_xyz_mm, dtype=float)\n",
        "\n",
        "        def nearest_gm_index(site_xyz_mm: np.ndarray) -> int:\n",
        "            d2 = np.sum((gm_xyz - site_xyz_mm[None, :]) ** 2, axis=1)\n",
        "            return int(np.argmin(d2))\n",
        "\n",
        "        # Build-time scales (use stored feedback values if env already stepped)\n",
        "        drive_rate_scale = float(np.clip(getattr(self, \"_drive_rate_scale\", 1.0), 0.05, 5.0))\n",
        "        primary_rate_scale = float(np.clip(getattr(self, \"_primary_rate_scale\", 1.0), 0.05, 5.0))\n",
        "        secondary_rate_scale = float(np.clip(getattr(self, \"_secondary_rate_scale\", 1.0), 0.05, 5.0))\n",
        "        primary_weight_scale = float(np.clip(getattr(self, \"_primary_weight_scale\", 1.0), 0.0, 10.0))\n",
        "        secondary_weight_scale = float(np.clip(getattr(self, \"_secondary_weight_scale\", 1.0), 0.0, 10.0))\n",
        "\n",
        "        p_site_scales = getattr(self, \"_primary_site_scales\", None)\n",
        "        s_site_scales = getattr(self, \"_secondary_site_scales\", None)\n",
        "\n",
        "        # Synapse params\n",
        "        tau1 = float(getattr(self.cfg, \"onset_syn_tau1_ms\", 0.5))\n",
        "        tau2 = float(getattr(self.cfg, \"onset_syn_tau2_ms\", 3.0))\n",
        "        e_rev = float(getattr(self.cfg, \"onset_syn_e_rev_mV\", 0.0))\n",
        "\n",
        "        rng = np.random.default_rng(int(getattr(case, \"seed\", 0)))\n",
        "\n",
        "        def sample_primary_base():\n",
        "            base_hz = float(getattr(case, \"primary_base_hz\", 25.0))\n",
        "            base_w = float(getattr(case, \"primary_base_w\", 5.0))\n",
        "            hz_jit = float(getattr(case, \"primary_hz_jitter\", 0.25))\n",
        "            w_jit = float(getattr(case, \"primary_w_jitter\", 0.25))\n",
        "            base_hz = max(0.1, base_hz * (1.0 + hz_jit * rng.normal()))\n",
        "            base_w = max(0.0, base_w * (1.0 + w_jit * rng.normal()))\n",
        "            return base_hz, base_w\n",
        "\n",
        "        def sample_secondary_base():\n",
        "            base_hz = float(getattr(case, \"secondary_base_hz\", 10.0))\n",
        "            base_w = float(getattr(case, \"secondary_base_w\", 0.25))\n",
        "            hz_jit = float(getattr(case, \"secondary_hz_jitter\", 0.30))\n",
        "            w_jit = float(getattr(case, \"secondary_w_jitter\", 0.30))\n",
        "            base_hz = max(0.1, base_hz * (1.0 + hz_jit * rng.normal()))\n",
        "            base_w = max(0.0, base_w * (1.0 + w_jit * rng.normal()))\n",
        "            return base_hz, base_w\n",
        "\n",
        "        # Robust onset list read\n",
        "        raw_primary = getattr(case, \"primary_onsets_xyz_mm\", []) or []\n",
        "        raw_secondary = getattr(case, \"secondary_onsets_xyz_mm\", []) or []\n",
        "\n",
        "        primary_sites = np.asarray(raw_primary, dtype=float).reshape(-1, 3) if len(raw_primary) else np.zeros((0, 3))\n",
        "        secondary_sites = np.asarray(raw_secondary, dtype=float).reshape(-1, 3) if len(raw_secondary) else np.zeros((0, 3))\n",
        "\n",
        "        print(\"[onset] primary_sites:\", primary_sites.shape, \"secondary_sites:\", secondary_sites.shape)\n",
        "\n",
        "        # Primary\n",
        "        for i_site, site in enumerate(primary_sites):\n",
        "            gi = nearest_gm_index(site)\n",
        "            sec = self.gm_secs[gi]\n",
        "\n",
        "            base_hz, base_w = sample_primary_base()\n",
        "            hz = base_hz * drive_rate_scale * primary_rate_scale\n",
        "            interval = 1000.0 / max(1e-6, hz)\n",
        "\n",
        "            w_scale = primary_weight_scale\n",
        "            if p_site_scales is not None and i_site < len(p_site_scales):\n",
        "                w_scale *= float(np.clip(p_site_scales[i_site], 0.0, 10.0))\n",
        "            w_eff = base_w * w_scale\n",
        "\n",
        "            syn = h.Exp2Syn(sec(0.5))\n",
        "            syn.tau1 = tau1\n",
        "            syn.tau2 = tau2\n",
        "            syn.e = e_rev\n",
        "\n",
        "            ns = h.NetStim()\n",
        "            ns.number = 1e9\n",
        "            ns.start = float(h.t)\n",
        "            ns.noise = float(getattr(self.cfg, \"onset_noise\", 1.0))\n",
        "            ns.interval = float(interval)\n",
        "\n",
        "            nc = h.NetCon(ns, syn)\n",
        "            nc.delay = 0.0\n",
        "            nc.weight[0] = float(w_eff)\n",
        "\n",
        "            self._primary_syns.append(syn)\n",
        "            self._primary_netstims.append(ns)\n",
        "            self._primary_netcons.append(nc)\n",
        "            self._primary_base_hz.append(float(base_hz))\n",
        "            self._primary_base_w.append(float(base_w))\n",
        "\n",
        "        # Secondary\n",
        "        for i_site, site in enumerate(secondary_sites):\n",
        "            gi = nearest_gm_index(site)\n",
        "            sec = self.gm_secs[gi]\n",
        "\n",
        "            base_hz, base_w = sample_secondary_base()\n",
        "            hz = base_hz * drive_rate_scale * secondary_rate_scale\n",
        "            interval = 1000.0 / max(1e-6, hz)\n",
        "\n",
        "            w_scale = secondary_weight_scale\n",
        "            if s_site_scales is not None and i_site < len(s_site_scales):\n",
        "                w_scale *= float(np.clip(s_site_scales[i_site], 0.0, 10.0))\n",
        "            w_eff = base_w * w_scale\n",
        "\n",
        "            syn = h.Exp2Syn(sec(0.5))\n",
        "            syn.tau1 = tau1\n",
        "            syn.tau2 = tau2\n",
        "            syn.e = e_rev\n",
        "\n",
        "            ns = h.NetStim()\n",
        "            ns.number = 1e9\n",
        "            ns.start = float(h.t)\n",
        "            ns.noise = float(getattr(self.cfg, \"onset_noise\", 1.0))\n",
        "            ns.interval = float(interval)\n",
        "\n",
        "            nc = h.NetCon(ns, syn)\n",
        "            nc.delay = 0.0\n",
        "            nc.weight[0] = float(w_eff)\n",
        "\n",
        "            self._secondary_syns.append(syn)\n",
        "            self._secondary_netstims.append(ns)\n",
        "            self._secondary_netcons.append(nc)\n",
        "            self._secondary_base_hz.append(float(base_hz))\n",
        "            self._secondary_base_w.append(float(base_w))\n",
        "\n",
        "        print(\"[onset] primary drives:\", len(self._primary_netstims), \"secondary drives:\", len(self._secondary_netstims))\n",
        "\n",
        "    def update_focus_drive(self, feedback: Dict[str, Any]) -> None:\n",
        "        \"\"\"\n",
        "        Live update onset drives using baselines; store for build-time too.\n",
        "        \"\"\"\n",
        "        drive_rate_scale = float(feedback.get(\"drive_rate_scale\", 1.0))\n",
        "        primary_rate_scale = float(feedback.get(\"primary_rate_scale\", 1.0))\n",
        "        secondary_rate_scale = float(feedback.get(\"secondary_rate_scale\", 1.0))\n",
        "        primary_weight_scale = float(feedback.get(\"primary_weight_scale\", 1.0))\n",
        "        secondary_weight_scale = float(feedback.get(\"secondary_weight_scale\", 1.0))\n",
        "        p_site = feedback.get(\"primary_site_scales\", None)\n",
        "        s_site = feedback.get(\"secondary_site_scales\", None)\n",
        "\n",
        "        self._drive_rate_scale = float(np.clip(drive_rate_scale, 0.05, 5.0))\n",
        "        self._primary_rate_scale = float(np.clip(primary_rate_scale, 0.05, 5.0))\n",
        "        self._secondary_rate_scale = float(np.clip(secondary_rate_scale, 0.05, 5.0))\n",
        "        self._primary_weight_scale = float(np.clip(primary_weight_scale, 0.0, 10.0))\n",
        "        self._secondary_weight_scale = float(np.clip(secondary_weight_scale, 0.0, 10.0))\n",
        "        self._primary_site_scales = p_site\n",
        "        self._secondary_site_scales = s_site\n",
        "\n",
        "        # Primary updates\n",
        "        for i, (ns, nc) in enumerate(zip(self._primary_netstims, self._primary_netcons)):\n",
        "            base_hz = float(self._primary_base_hz[i])\n",
        "            hz = base_hz * self._drive_rate_scale * self._primary_rate_scale\n",
        "            ns.interval = 1000.0 / max(1e-6, hz)\n",
        "\n",
        "            w = self._primary_weight_scale\n",
        "            if p_site is not None and i < len(p_site):\n",
        "                w *= float(np.clip(p_site[i], 0.0, 10.0))\n",
        "            nc.weight[0] = float(self._primary_base_w[i]) * float(w)\n",
        "\n",
        "        # Secondary updates\n",
        "        for i, (ns, nc) in enumerate(zip(self._secondary_netstims, self._secondary_netcons)):\n",
        "            base_hz = float(self._secondary_base_hz[i])\n",
        "            hz = base_hz * self._drive_rate_scale * self._secondary_rate_scale\n",
        "            ns.interval = 1000.0 / max(1e-6, hz)\n",
        "\n",
        "            w = self._secondary_weight_scale\n",
        "            if s_site is not None and i < len(s_site):\n",
        "                w *= float(np.clip(s_site[i], 0.0, 10.0))\n",
        "            nc.weight[0] = float(self._secondary_base_w[i]) * float(w)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Recording + spike feature helpers\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _setup_recording(self) -> None:\n",
        "        self._record_t = h.Vector()\n",
        "        self._record_t.record(h._ref_t)\n",
        "\n",
        "        self._record_vs = []\n",
        "        self._spike_vecs = []\n",
        "        self._spike_netcons = []\n",
        "        self._spike_cell_types = []\n",
        "\n",
        "        thr_mV = float(getattr(self.cfg, \"spike_threshold_mV\", -20.0))\n",
        "        max_record = int(getattr(self.cfg, \"n_record_cells\", 8))\n",
        "\n",
        "        # --- robust labels ---\n",
        "        gm_types = getattr(self, \"_gm_types\", [\"E\"] * len(self.gm_secs))\n",
        "        E_idx = [i for i, t in enumerate(gm_types) if str(t) == \"E\"]\n",
        "        I_idx = [i for i, t in enumerate(gm_types) if str(t).startswith(\"I\")]\n",
        "\n",
        "        # --- balanced selection ---\n",
        "        # target half inhibitory if possible\n",
        "        nI = min(len(I_idx), max_record // 2)\n",
        "        nE = min(len(E_idx), max_record - nI)\n",
        "\n",
        "        # if still under-filled (e.g., not enough E or I), fill from remaining GM cells\n",
        "        pick = []\n",
        "        if nE > 0:\n",
        "            pick += self.rng.choice(E_idx, size=nE, replace=False).tolist()\n",
        "        if nI > 0:\n",
        "            pick += self.rng.choice(I_idx, size=nI, replace=False).tolist()\n",
        "\n",
        "        if len(pick) < min(max_record, len(self.gm_secs)):\n",
        "            remaining = [i for i in range(len(self.gm_secs)) if i not in set(pick)]\n",
        "            n_fill = min(len(remaining), min(max_record, len(self.gm_secs)) - len(pick))\n",
        "            if n_fill > 0:\n",
        "                pick += self.rng.choice(remaining, size=n_fill, replace=False).tolist()\n",
        "\n",
        "        self.rng.shuffle(pick)\n",
        "\n",
        "        # convenience for your external tests\n",
        "        self._record_gm_indices = pick\n",
        "        self._record_secs = [self.gm_secs[i] for i in pick]\n",
        "\n",
        "        print(\n",
        "            f\"[record] n={len(pick)} thr={thr_mV} \"\n",
        "            f\"E={sum(str(gm_types[i])=='E' for i in pick)} \"\n",
        "            f\"I={sum(str(gm_types[i]).startswith('I') for i in pick)}\"\n",
        "        )\n",
        "\n",
        "        # --- create recording objects ---\n",
        "        for i in pick:\n",
        "            sec = self.gm_secs[i]\n",
        "\n",
        "            vvec = h.Vector()\n",
        "            vvec.record(sec(0.5)._ref_v)\n",
        "            self._record_vs.append(vvec)\n",
        "\n",
        "            spk = h.Vector()\n",
        "            nc = h.NetCon(sec(0.5)._ref_v, None, sec=sec)\n",
        "            nc.threshold = thr_mV\n",
        "            nc.record(spk)\n",
        "\n",
        "            self._spike_vecs.append(spk)\n",
        "            self._spike_netcons.append(nc)\n",
        "\n",
        "            # label aligned to the spike vector\n",
        "            self._spike_cell_types.append(str(gm_types[i]))\n",
        "\n",
        "    def _split_spikes_by_type(self, t0: float, t1: float):\n",
        "        E_lists, I_lists, all_lists = [], [], []\n",
        "        for i, sp in enumerate(self._spike_vecs):\n",
        "            st_all = np.asarray(list(sp), dtype=float)\n",
        "            st_win = st_all[(st_all >= t0) & (st_all < t1)] - float(t0)\n",
        "            all_lists.append(st_win)\n",
        "\n",
        "            ctype = self._spike_cell_types[i]\n",
        "            if ctype == \"E\":\n",
        "                E_lists.append(st_win)\n",
        "            elif str(ctype).startswith(\"I\"):\n",
        "                I_lists.append(st_win)\n",
        "            else:\n",
        "                E_lists.append(st_win)\n",
        "        return E_lists, I_lists, all_lists\n",
        "\n",
        "    @staticmethod\n",
        "    def _rate_from_lists(spike_lists, window_ms: float) -> float:\n",
        "        n = int(sum(len(x) for x in spike_lists))\n",
        "        return float(n) / max(1e-9, float(window_ms) / 1000.0)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Waveform + stimulation application\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _make_waveform_mA(self, stim: StimParams, t0_ms: float, t1_ms: float) -> np.ndarray:\n",
        "        dt = float(self.cfg.dt_ms)\n",
        "        n = int(np.round((t1_ms - t0_ms) / dt))\n",
        "        n = max(1, n)\n",
        "\n",
        "        t = np.arange(n, dtype=float) * dt\n",
        "        I = np.zeros(n, dtype=float)\n",
        "\n",
        "        amp = float(stim.amp_mA)\n",
        "        freq = float(stim.freq_Hz)\n",
        "        pw = float(stim.pw_ms)\n",
        "        duty = float(np.clip(getattr(stim, \"duty_cycle\", 1.0), 0.0, 1.0))\n",
        "\n",
        "        if duty <= 0.0 or amp == 0.0 or freq <= 0.0 or pw <= 0.0:\n",
        "            return I\n",
        "\n",
        "        gate = 1.0\n",
        "        if duty < 1.0:\n",
        "            on_ms = duty * float(self.cfg.window_ms)\n",
        "            gate = (t < on_ms).astype(float)\n",
        "\n",
        "        waveform = (getattr(stim, \"waveform\", \"rect\") or \"rect\").lower()\n",
        "\n",
        "        if waveform == \"rect\":\n",
        "            period_ms = 1000.0 / freq\n",
        "            phase = np.mod(t, period_ms)\n",
        "            I = np.where(phase < pw, amp, 0.0) * gate\n",
        "\n",
        "        elif waveform == \"biphasic\":\n",
        "            period_ms = 1000.0 / freq\n",
        "            phase = np.mod(t, period_ms)\n",
        "            p1 = (phase < pw)\n",
        "            gap = float(max(0.0, getattr(stim, \"interphase_gap_ms\", 0.0)))\n",
        "            p2_start = pw + gap\n",
        "            p2 = (phase >= p2_start) & (phase < p2_start + pw)\n",
        "            ratio = float(getattr(stim, \"phase2_amp_ratio\", -1.0))\n",
        "            I = (amp * p1 + amp * ratio * p2) * gate\n",
        "\n",
        "        elif waveform == \"burst\":\n",
        "            burst_Hz = float(max(1e-6, getattr(stim, \"burst_Hz\", 5.0)))\n",
        "            pulses_per_burst = int(max(1, getattr(stim, \"pulses_per_burst\", 5)))\n",
        "            intra_Hz = float(max(1e-6, getattr(stim, \"intra_burst_freq_Hz\", 100.0)))\n",
        "\n",
        "            burst_period_ms = 1000.0 / burst_Hz\n",
        "            intra_period_ms = 1000.0 / intra_Hz\n",
        "\n",
        "            t_in_burst = np.mod(t, burst_period_ms)\n",
        "            pulse_idx = np.floor(t_in_burst / intra_period_ms).astype(int)\n",
        "            in_train = pulse_idx < pulses_per_burst\n",
        "            phase_in_pulse = t_in_burst - pulse_idx * intra_period_ms\n",
        "            in_pw = phase_in_pulse < pw\n",
        "            I = np.where(in_train & in_pw, amp, 0.0) * gate\n",
        "\n",
        "        return I\n",
        "\n",
        "    def _apply_extracellular_waveform(self, I_mA: np.ndarray, t0_ms: float) -> None:\n",
        "        self._stim_play_vecs.clear()\n",
        "\n",
        "        if len(self._stim_segs) == 0:\n",
        "            return\n",
        "        if self._stim_coupling_mV_per_mA.size != len(self._stim_segs):\n",
        "            raise RuntimeError(\"Call precompute_coupling() before applying stimulation (coupling mismatch).\")\n",
        "\n",
        "        dt = float(self.cfg.dt_ms)\n",
        "        times = (t0_ms + np.arange(len(I_mA)) * dt).astype(float)\n",
        "        tvec = h.Vector(times.tolist())\n",
        "\n",
        "        for seg, k in zip(self._stim_segs, self._stim_coupling_mV_per_mA):\n",
        "            vext = (float(k) * I_mA).astype(float)\n",
        "            vvec = h.Vector(vext.tolist())\n",
        "            vvec.play(seg._ref_e_extracellular, tvec, 1)\n",
        "            self._stim_play_vecs.append((vvec, tvec))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Main simulation step\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_window(self, stim_params: Union[StimParams, Dict[str, Any], Sequence[float]]) -> Dict[str, float]:\n",
        "        if self.case is None:\n",
        "            raise RuntimeError(\"Call build_from_case() before run_window().\")\n",
        "\n",
        "        stim = _as_stim_params(stim_params)\n",
        "        self._last_stim = stim\n",
        "\n",
        "        t0 = float(h.t)\n",
        "        t1 = t0 + float(self.cfg.window_ms)\n",
        "\n",
        "        I_mA = self._make_waveform_mA(stim, t0_ms=t0, t1_ms=t1)\n",
        "        self._apply_extracellular_waveform(I_mA, t0_ms=t0)\n",
        "\n",
        "        h.continuerun(t1)\n",
        "\n",
        "        E_lists, I_lists, all_lists = ([], [], [])\n",
        "        if hasattr(self, \"_spike_vecs\") and len(self._spike_vecs) > 0:\n",
        "            E_lists, I_lists, all_lists = self._split_spikes_by_type(t0, t1)\n",
        "\n",
        "        n_spikes = int(sum(len(x) for x in all_lists))\n",
        "        rate_hz = float(n_spikes) / max(1e-9, float(self.cfg.window_ms) / 1000.0)\n",
        "\n",
        "        E_rate = self._rate_from_lists(E_lists, self.cfg.window_ms)\n",
        "        I_rate = self._rate_from_lists(I_lists, self.cfg.window_ms)\n",
        "        eps = 1e-3\n",
        "        logEI = float(np.log((E_rate + eps) / (I_rate + eps)))   # ~0 when E≈I, >0 when E>I\n",
        "        logEI = float(np.clip(logEI, -3.0, 3.0))\n",
        "\n",
        "        E_all = np.concatenate(E_lists) if len(E_lists) else np.array([], dtype=float)\n",
        "        burst_E = burst_fraction_from_spikes(E_all, isi_thresh_ms=10.0, min_spikes_in_burst=3)\n",
        "        sync_E = sync_from_spike_trains(E_lists, window_ms=float(self.cfg.window_ms), bin_ms=5.0)\n",
        "\n",
        "        feats = {\n",
        "            \"n_spikes\": float(n_spikes),\n",
        "            \"rate_hz\": float(rate_hz),\n",
        "            \"E_rate_hz\": float(E_rate),\n",
        "            \"I_rate_hz\": float(I_rate),\n",
        "            \"logEI\": float(logEI),\n",
        "            \"burst_E\": float(burst_E),\n",
        "            \"sync_E\": float(sync_E),\n",
        "        }\n",
        "        self._last_features = feats\n",
        "        return feats\n",
        "\n",
        "\n",
        "\n",
        "__all__ = [\n",
        "    \"StimParams\",\n",
        "    \"NeuronPlant\",\n",
        "    \"FullNeuronPlant\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "nCvoR5nwaklq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "print(inspect.signature(sync_from_spike_trains))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVPCOMKOc1Z3",
        "outputId": "a506cb75-72db-488c-a9fd-f11bb884eb85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(spike_lists_ms: 'List[np.ndarray]', window_ms: 'float', bin_ms: 'float' = 5.0) -> 'float'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Has FullNeuronPlant.run_window?\", \"run_window\" in FullNeuronPlant.__dict__)\n",
        "print(\"FullNeuronPlant.run_window:\", FullNeuronPlant.run_window.__qualname__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBnT5mxtbbCv",
        "outputId": "a9b0c6b7-2032-4c06-f6b2-7e38d81753e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Has FullNeuronPlant.run_window? True\n",
            "FullNeuronPlant.run_window: FullNeuronPlant.run_window\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FullNeuronPlant.run_window defined on:\", FullNeuronPlant.run_window.__qualname__)\n"
      ],
      "metadata": {
        "id": "XVxKQ3x7bteD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afad651-6650-4f29-9e87-a02340f948c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FullNeuronPlant.run_window defined on: FullNeuronPlant.run_window\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_l2.py\n",
        "\"\"\"\n",
        "Level-2 epilepsy state + plasticity model (lower-dimensional state layer).\n",
        "\n",
        "Project-aligned objectives:\n",
        "- Maintain a stable, differentiable-ish (but hand-coded) state update capturing:\n",
        "    * seizure burden / propensity (scalar)\n",
        "    * onset strengths (primary + secondary) with option for per-site vectors\n",
        "    * long-term plasticity / drift term\n",
        "- Consume Level-1 features + stimulation parameters each RL step\n",
        "- Emit feedback that modulates Level-1 onset drive:\n",
        "    * drive_rate_scale (global)\n",
        "    * primary_weight_scale / secondary_weight_scale\n",
        "    * optional per-site scales (primary_site_scales, secondary_site_scales)\n",
        "\n",
        "This file is intentionally self-contained and conservative (bounded updates, smooth dynamics),\n",
        "so training remains numerically stable.\n",
        "\n",
        "Expected feature inputs (from Level-1 plant):\n",
        "- rate_hz: float\n",
        "- sync: float\n",
        "- burst: float\n",
        "- lfp: float\n",
        "\n",
        "Expected stim inputs:\n",
        "- amp_mA, freq_Hz, pw_ms\n",
        "Optionally additional waveform descriptors (ignored safely if present).\n",
        "\n",
        "Integration keys returned in feedback dict:\n",
        "- drive_rate_scale\n",
        "- primary_rate_scale\n",
        "- secondary_rate_scale\n",
        "- primary_weight_scale\n",
        "- secondary_weight_scale\n",
        "- primary_site_scales (optional vector)\n",
        "- secondary_site_scales (optional vector)\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, Optional, Sequence, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Config + State\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class L2Config:\n",
        "    # -------- time step (discrete-time L2) --------\n",
        "    # Your EpilepsyStateModel uses cfg.dt as a multiplier on burden updates.\n",
        "    # For “one update per env step”, dt=1.0 is the correct default.\n",
        "    dt: float = 1.0\n",
        "\n",
        "    # -------- state clamps --------\n",
        "    burden_min: float = 0.0\n",
        "    burden_max: float = 10.0\n",
        "\n",
        "    strength_min: float = 0.0\n",
        "    strength_max: float = 5.0\n",
        "\n",
        "    plasticity_min: float = -2.0\n",
        "    plasticity_max: float = 2.0\n",
        "\n",
        "    # -------- feature references (normalization) --------\n",
        "    ref_rate_hz: float = 20.0\n",
        "    ref_sync: float = 0.5\n",
        "    ref_burst: float = 0.2\n",
        "    ref_lfp: float = 1.0\n",
        "\n",
        "    # Keep BOTH spellings because your notebook currently uses cfg.ref_EI_ratio\n",
        "    ref_ei_ratio: float = 1.0\n",
        "    ref_EI_ratio: float = 1.0\n",
        "\n",
        "    # Your notebook uses cfg.ref_I_rate (capital I)\n",
        "    ref_I_rate: float = 10.0\n",
        "\n",
        "    baseline_gain: float = 0.02      # start small; tune\n",
        "    burden_decay: float = 0.10       # in \"per second\" units if dt is seconds; adjust if dt differs\n",
        "\n",
        "    rebound_gain: float = 0.05\n",
        "    rebound_threshold: float = 0.2\n",
        "\n",
        "\n",
        "    # -------- weights (burden pathology mixture) --------\n",
        "    w_rate: float = 0.60\n",
        "    w_sync: float = 0.25\n",
        "    w_burst: float = 0.15\n",
        "    w_ei: float = 0.10\n",
        "\n",
        "    w_lfp: float = 0.10\n",
        "    w_plasticity: float = 0.10\n",
        "\n",
        "    # stimulation suppression weight\n",
        "    w_stim: float = 0.25\n",
        "\n",
        "    # -------- burden dynamics --------\n",
        "    # Your model uses cfg.burden_decay * burden\n",
        "    burden_decay: float = 0.02\n",
        "\n",
        "    # plasticity contributes to burden_dot via cfg.plasticity_burden_gain * plasticity\n",
        "    plasticity_burden_gain: float = 0.05\n",
        "\n",
        "    # -------- strength dynamics --------\n",
        "    # Your code uses these in both scalar and per-site updates\n",
        "    primary_strength_rate: float = 0.02\n",
        "    secondary_strength_rate: float = 0.02\n",
        "\n",
        "    strength_burden_gain: float = 0.10\n",
        "    strength_stim_gain: float = 0.10\n",
        "\n",
        "    # -------- plasticity dynamics --------\n",
        "    plasticity_rate: float = 0.05\n",
        "    plasticity_decay: float = 0.01\n",
        "\n",
        "    # -------- acute suppression controls --------\n",
        "    acute_stim_suppress_k: float = 1.0\n",
        "    acute_min_scale: float = 0.2\n",
        "\n",
        "    # -------- per-site modelling --------\n",
        "    use_per_site_secondary: bool = True\n",
        "    per_site_noise_std: float = 0.02\n",
        "\n",
        "    # -------- feedback gains (L2 -> L1) --------\n",
        "    # Your EpilepsyStateModel reads feedback_drive_gain/feedback_weight_gain.\n",
        "    feedback_drive_gain: float = 0.50\n",
        "    feedback_weight_gain: float = 0.30\n",
        "\n",
        "    # Backward-compatible aliases (your older config used fb_drive_gain/fb_weight_gain)\n",
        "    fb_drive_gain: float = 0.50\n",
        "    fb_weight_gain: float = 0.30\n",
        "\n",
        "    ref_logEI: float = 1.0\n",
        "    w_ei: float = 0.0  # or small, e.g. 0.05–0.2\n",
        "\n",
        "@dataclass\n",
        "class L2State:\n",
        "    \"\"\"Level-2 internal state.\"\"\"\n",
        "    burden: float = 0.0\n",
        "    plasticity: float = 0.0\n",
        "\n",
        "    primary_strength: float = 1.0\n",
        "    secondary_strength: float = 0.5\n",
        "\n",
        "    # Optional per-site vectors (secondary and primary)\n",
        "    primary_site_strengths: np.ndarray = field(default_factory=lambda: np.zeros((0,), dtype=float))\n",
        "    secondary_site_strengths: np.ndarray = field(default_factory=lambda: np.zeros((0,), dtype=float))\n",
        "\n",
        "    # History summaries (for trend effects)\n",
        "    stim_ema: float = 0.0\n",
        "    stim_ema_alpha: float = 0.05  # fixed smoothing for simplicity\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Utilities\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def _clip(x: float, lo: float, hi: float) -> float:\n",
        "    return float(min(max(float(x), float(lo)), float(hi)))\n",
        "\n",
        "\n",
        "def _safe_float(d: Dict[str, Any], key: str, default: float = 0.0) -> float:\n",
        "    try:\n",
        "        return float(d.get(key, default))\n",
        "    except Exception:\n",
        "        return float(default)\n",
        "\n",
        "\n",
        "def _normalize_feature(x: float, ref: float) -> float:\n",
        "    # Simple bounded normalization. Keeps magnitudes manageable.\n",
        "    ref = max(1e-6, float(ref))\n",
        "    return float(np.tanh(x / ref))\n",
        "\n",
        "def _stim_intensity(cfg, amp_mA: float, freq_Hz: float, pw_ms: float) -> float:\n",
        "    \"\"\"\n",
        "    Scalar stimulation 'dose' proxy for cost / adaptation dynamics.\n",
        "\n",
        "    Uses charge-per-second (mA * ms * Hz) as the base, then normalizes by\n",
        "    configurable reference values.\n",
        "\n",
        "    Returns a non-negative float, typically O(0..a few).\n",
        "    \"\"\"\n",
        "    amp = float(max(0.0, amp_mA))\n",
        "    freq = float(max(0.0, freq_Hz))\n",
        "    pw = float(max(0.0, pw_ms))\n",
        "\n",
        "    # charge proxy (mA * ms per pulse * pulses/s) = mA*ms/s\n",
        "    q = amp * pw * freq\n",
        "\n",
        "    # normalization refs (safe fallbacks)\n",
        "    ref_amp = float(getattr(cfg, \"ref_amp_mA\", 1.0))\n",
        "    ref_freq = float(getattr(cfg, \"ref_freq_Hz\", 100.0))\n",
        "    ref_pw = float(getattr(cfg, \"ref_pw_ms\", 0.2))\n",
        "\n",
        "    q_ref = max(1e-9, ref_amp * ref_pw * ref_freq)\n",
        "    return float(q / q_ref)\n",
        "\n",
        "\n",
        "def _normalize_stim(amp_mA: float, freq_Hz: float, pw_ms: float, cfg: L2Config) -> float:\n",
        "    \"\"\"\n",
        "    Normalize stimulation intensity into ~[0,1] range using a conservative product-like metric:\n",
        "      stim_intensity ~ (amp/amax) * (freq/fmax) * (pw/pwmax)\n",
        "    This roughly correlates with charge-per-second-like effects.\n",
        "    \"\"\"\n",
        "    a = float(np.clip(amp_mA / max(1e-6, cfg.amp_max_mA), 0.0, 2.0))\n",
        "    f = float(np.clip(freq_Hz / max(1e-6, cfg.freq_max_Hz), 0.0, 2.0))\n",
        "    p = float(np.clip(pw_ms / max(1e-6, cfg.pw_max_ms), 0.0, 2.0))\n",
        "    # Keep it smooth and bounded\n",
        "    return float(np.clip(a * f * p, 0.0, 2.0))\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Model\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "class EpilepsyStateModel:\n",
        "    \"\"\"\n",
        "    Level-2 state + plasticity model with optional per-secondary-site vector dynamics.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg: Optional[L2Config] = None, rng_seed: int = 0):\n",
        "        self.cfg = cfg or L2Config()\n",
        "        self.rng_seed = int(rng_seed)\n",
        "        self.rng = np.random.default_rng(self.rng_seed)\n",
        "        self.state = L2State()\n",
        "        # Latent seizure drive (0..1 recommended)\n",
        "        self.z = float(getattr(self.cfg, \"z0\", 0.6))\n",
        "\n",
        "        # Cache last drive dict (optional but convenient)\n",
        "        self.last_drive = None\n",
        "\n",
        "\n",
        "    # -------------------------\n",
        "    # Reset / init\n",
        "    # -------------------------\n",
        "\n",
        "    def reset(self, case: Optional[CaseSpec] = None, *, severity: Optional[float] = None) -> L2State:\n",
        "        \"\"\"\n",
        "        Reset Level-2 state.\n",
        "\n",
        "        Initialization rules:\n",
        "        - burden initialized from case.baseline_burden if present, else from severity, else 0.\n",
        "        - onset strengths initialized from case.onset site baseline_strengths if present.\n",
        "        \"\"\"\n",
        "        cfg = self.cfg\n",
        "        s = L2State()\n",
        "\n",
        "        sev = None\n",
        "        if severity is not None:\n",
        "            sev = float(severity)\n",
        "        elif case is not None and hasattr(case, \"severity\"):\n",
        "            sev = float(getattr(case, \"severity\"))\n",
        "        else:\n",
        "            sev = 0.0\n",
        "\n",
        "        # Baseline burden: prefer explicit case.baseline_burden; fallback to severity\n",
        "        if case is not None and hasattr(case, \"baseline_burden\"):\n",
        "            s.burden = float(getattr(case, \"baseline_burden\"))\n",
        "        else:\n",
        "            s.burden = float(max(0.0, sev))\n",
        "\n",
        "        s.burden = _clip(s.burden, cfg.burden_min, cfg.burden_max)\n",
        "\n",
        "        # Initialize strengths from case if possible\n",
        "        primary_strength_init = 1.0\n",
        "        secondary_strength_init = 0.5\n",
        "\n",
        "        primary_site_strengths = np.zeros((0,), dtype=float)\n",
        "        secondary_site_strengths = np.zeros((0,), dtype=float)\n",
        "\n",
        "        if case is not None and hasattr(case, \"onset\"):\n",
        "            onset = getattr(case, \"onset\")\n",
        "            primary_sites = list(getattr(onset, \"primary_sites\", ()))\n",
        "            secondary_sites = list(getattr(onset, \"secondary_sites\", ()))\n",
        "\n",
        "            if len(primary_sites) > 0:\n",
        "                primary_site_strengths = np.array(\n",
        "                    [float(getattr(ps, \"baseline_strength\", 1.0)) for ps in primary_sites],\n",
        "                    dtype=float,\n",
        "                )\n",
        "                primary_strength_init = float(np.mean(primary_site_strengths))\n",
        "\n",
        "            if len(secondary_sites) > 0:\n",
        "                secondary_site_strengths = np.array(\n",
        "                    [float(getattr(ss, \"baseline_strength\", 0.3)) for ss in secondary_sites],\n",
        "                    dtype=float,\n",
        "                )\n",
        "                secondary_strength_init = float(np.mean(secondary_site_strengths))\n",
        "\n",
        "        # If no sites provided, fallback conservative init\n",
        "        s.primary_strength = _clip(primary_strength_init, cfg.strength_min, cfg.strength_max)\n",
        "        s.secondary_strength = _clip(secondary_strength_init, cfg.strength_min, cfg.strength_max)\n",
        "\n",
        "        if cfg.use_per_site_secondary:\n",
        "            s.primary_site_strengths = primary_site_strengths.copy()\n",
        "            s.secondary_site_strengths = secondary_site_strengths.copy()\n",
        "        else:\n",
        "            s.primary_site_strengths = np.zeros((0,), dtype=float)\n",
        "            s.secondary_site_strengths = np.zeros((0,), dtype=float)\n",
        "\n",
        "        # Plasticity starts near 0, slightly biased by severity\n",
        "        s.plasticity = _clip(0.2 * (sev - 0.5), cfg.plasticity_min, cfg.plasticity_max)\n",
        "\n",
        "        # History\n",
        "        s.stim_ema = 0.0\n",
        "\n",
        "        self.state = s\n",
        "        return self.state\n",
        "\n",
        "\n",
        "    def get_drive(self) -> Dict[str, Any]:\n",
        "        st = self.state\n",
        "        cfg = self.cfg\n",
        "\n",
        "        burden_level = st.burden / max(1e-6, cfg.burden_max)\n",
        "        strength_level = (0.5 * st.primary_strength + 0.5 * st.secondary_strength) / max(1e-6, cfg.strength_max)\n",
        "\n",
        "        drive_rate_scale = 1.0 + cfg.feedback_drive_gain * (2.0 * burden_level - 1.0) + 0.05 * st.plasticity\n",
        "        drive_rate_scale = float(np.clip(drive_rate_scale, 0.25, 3.0))\n",
        "\n",
        "        primary_rate_scale = float(np.clip(1.0 + 0.10 * (2.0 * burden_level - 1.0), 0.5, 2.0))\n",
        "        secondary_rate_scale = float(np.clip(1.0 + 0.15 * (2.0 * burden_level - 1.0), 0.5, 2.5))\n",
        "\n",
        "        primary_weight_scale = 1.0 + cfg.feedback_weight_gain * (2.0 * strength_level - 1.0)\n",
        "        secondary_weight_scale = 1.0 + cfg.feedback_weight_gain * (2.0 * strength_level - 1.0)\n",
        "\n",
        "        primary_weight_scale += 0.05 * (2.0 * burden_level - 1.0)\n",
        "        secondary_weight_scale += 0.08 * (2.0 * burden_level - 1.0)\n",
        "\n",
        "        primary_weight_scale = float(np.clip(primary_weight_scale, 0.25, 3.0))\n",
        "        secondary_weight_scale = float(np.clip(secondary_weight_scale, 0.25, 3.0))\n",
        "\n",
        "        # --- ACUTE DBS SUPPRESSION (key addition) ---\n",
        "        # st.stim_ema is already in ~[0,2] given your normalize\n",
        "        acute = 1.0 / (1.0 + cfg.acute_stim_suppress_k * float(st.stim_ema))\n",
        "        acute = float(np.clip(acute, cfg.acute_min_scale, 1.0))\n",
        "\n",
        "        drive_rate_scale *= acute\n",
        "        primary_rate_scale *= acute\n",
        "        secondary_rate_scale *= acute\n",
        "        primary_weight_scale *= acute\n",
        "        secondary_weight_scale *= acute\n",
        "\n",
        "        feedback: Dict[str, Any] = {\n",
        "            \"drive_rate_scale\": float(np.clip(drive_rate_scale, 0.25, 3.0)),\n",
        "            \"primary_rate_scale\": float(np.clip(primary_rate_scale, 0.5, 2.0)),\n",
        "            \"secondary_rate_scale\": float(np.clip(secondary_rate_scale, 0.5, 2.5)),\n",
        "            \"primary_weight_scale\": float(np.clip(primary_weight_scale, 0.25, 3.0)),\n",
        "            \"secondary_weight_scale\": float(np.clip(secondary_weight_scale, 0.25, 3.0)),\n",
        "        }\n",
        "\n",
        "        # Per-site scales as before...\n",
        "        if cfg.use_per_site_secondary:\n",
        "            if st.primary_site_strengths is not None and st.primary_site_strengths.size > 0:\n",
        "                p = st.primary_site_strengths\n",
        "                feedback[\"primary_site_scales\"] = np.clip(\n",
        "                    0.5 + 1.5 * (p / max(1e-6, cfg.strength_max)), 0.25, 3.0\n",
        "                ).astype(float)\n",
        "            if st.secondary_site_strengths is not None and st.secondary_site_strengths.size > 0:\n",
        "                s = st.secondary_site_strengths\n",
        "                feedback[\"secondary_site_scales\"] = np.clip(\n",
        "                    0.5 + 1.5 * (s / max(1e-6, cfg.strength_max)), 0.25, 3.0\n",
        "                ).astype(float)\n",
        "\n",
        "        return feedback\n",
        "\n",
        "    def _stim_intensity_norm(stim: dict, amp_max=3.0, freq_max=150.0, pw_max=0.4) -> float:\n",
        "        amp = float(stim.get(\"amp_mA\", 0.0))\n",
        "        freq = float(stim.get(\"freq_Hz\", 0.0))\n",
        "        pw = float(stim.get(\"pw_ms\", 0.0))\n",
        "        duty = float(stim.get(\"duty_cycle\", 1.0))\n",
        "\n",
        "        x = (amp / max(1e-9, amp_max)) * (freq / max(1e-9, freq_max)) * (pw / max(1e-9, pw_max)) * duty\n",
        "        return float(np.clip(x, 0.0, 2.0))\n",
        "\n",
        "\n",
        "    # -------------------------\n",
        "    # Update step\n",
        "    # -------------------------\n",
        "\n",
        "    def step(\n",
        "        self,\n",
        "        features: Dict[str, float],\n",
        "        stim: Union[Dict[str, Any], Sequence[float], Tuple[float, float, float]],\n",
        "        case: Optional[CaseSpec] = None,\n",
        "    ) -> Tuple[L2State, Dict[str, Any], Dict[str, float]]:\n",
        "\n",
        "        cfg = self.cfg\n",
        "        st = self.state\n",
        "\n",
        "        # Parse stim\n",
        "        if isinstance(stim, dict):\n",
        "            amp = _safe_float(stim, \"amp_mA\", 0.0)\n",
        "            freq = _safe_float(stim, \"freq_Hz\", 0.0)\n",
        "            pw = _safe_float(stim, \"pw_ms\", 0.0)\n",
        "        else:\n",
        "            amp, freq, pw = float(stim[0]), float(stim[1]), float(stim[2])\n",
        "\n",
        "        stim_int = _stim_intensity(cfg, amp_mA=amp, freq_Hz=freq, pw_ms=pw)\n",
        "        st.stim_ema = (1.0 - st.stim_ema_alpha) * st.stim_ema + st.stim_ema_alpha * stim_int\n",
        "\n",
        "        # 8.3: use excitatory features preferentially\n",
        "        rate_raw = _safe_float(features, \"E_rate_hz\", _safe_float(features, \"rate_hz\", 0.0))\n",
        "        sync_raw = _safe_float(features, \"sync_E\", _safe_float(features, \"sync\", 0.0))\n",
        "        burst_raw = _safe_float(features, \"burst_E\", _safe_float(features, \"burst\", 0.0))\n",
        "        lfp_raw = _safe_float(features, \"lfp\", 0.0)\n",
        "        ei_raw = _safe_float(features, \"EI_ratio\", 1.0)\n",
        "\n",
        "        rate_n = _normalize_feature(rate_raw, cfg.ref_rate_hz)\n",
        "        sync_n = _normalize_feature(sync_raw, cfg.ref_sync)\n",
        "        burst_n = _normalize_feature(burst_raw, cfg.ref_burst)\n",
        "        lfp_n = _normalize_feature(lfp_raw, cfg.ref_lfp)\n",
        "\n",
        "        # Optional EI penalty (only if you add cfg.ref_ei_ratio and cfg.w_ei)\n",
        "        w_ei = float(getattr(cfg, \"w_ei\", 0.0))\n",
        "        ref_logei = float(getattr(cfg, \"ref_logEI\", 1.0))  # new cfg parameter; see below\n",
        "\n",
        "        rate_raw  = float(_safe_float(features, \"E_rate_hz\", 0.0))\n",
        "        sync_raw  = float(_safe_float(features, \"sync_E\", 0.0))\n",
        "        burst_raw = float(_safe_float(features, \"burst_E\", 0.0))\n",
        "        lfp_raw   = float(_safe_float(features, \"lfp_power\", 0.0))\n",
        "        logEI_raw = float(_safe_float(features, \"logEI\", 0.0))\n",
        "\n",
        "\n",
        "        # Only penalize excitatory dominance: logEI > 0\n",
        "        ei_drive = max(0.0, logEI_raw)\n",
        "\n",
        "        # Normalize relative to a reference (e.g. 1.0 ~ \"meaningfully E-dominant\")\n",
        "        ei_n = _normalize_feature(ei_drive, ref_logei) if w_ei > 0 else 0.0\n",
        "\n",
        "        pathology = float(\n",
        "            cfg.w_rate * rate_n\n",
        "            + cfg.w_sync * sync_n\n",
        "            + cfg.w_burst * burst_n\n",
        "            + cfg.w_lfp * lfp_n\n",
        "            + w_ei * ei_n\n",
        "        )\n",
        "\n",
        "        # Suppression increases with stim intensity but drops as foci strengthen\n",
        "        efficacy = float(np.clip(1.0 / (0.7 + 0.6 * st.primary_strength + 0.4 * st.secondary_strength), 0.2, 1.2))\n",
        "        w_stim = float(getattr(cfg, \"w_stim\", 0.25))\n",
        "        suppress = float(w_stim * stim_int * efficacy)\n",
        "\n",
        "        # --- Baseline pathology (C1) ---\n",
        "        sev = float(getattr(self.case, \"severity\", 1.0)) if getattr(self, \"case\", None) is not None else 1.0\n",
        "        baseline = float(getattr(cfg, \"baseline_gain\", 0.0)) * sev\n",
        "\n",
        "        # --- Optional rebound (C2) ---\n",
        "        rebound_gain   = float(getattr(cfg, \"rebound_gain\", 0.0))\n",
        "        rebound_thresh = float(getattr(cfg, \"rebound_threshold\", 0.2))\n",
        "        rebound = rebound_gain * max(0.0, rebound_thresh - st.burden)\n",
        "\n",
        "        # --- Decay ---\n",
        "        burden_decay = float(getattr(cfg, \"burden_decay\", 0.0))\n",
        "\n",
        "        # --- Final burden dynamics (ONE assignment only) ---\n",
        "        burden_dot = (\n",
        "            baseline\n",
        "            + pathology\n",
        "            - suppress\n",
        "            + rebound                    # safe even if rebound_gain = 0\n",
        "            + float(cfg.w_plasticity * st.plasticity)\n",
        "            - burden_decay * st.burden\n",
        "        )\n",
        "\n",
        "        st.burden = _clip(\n",
        "            st.burden + float(cfg.dt) * burden_dot,\n",
        "            cfg.burden_min,\n",
        "            cfg.burden_max\n",
        "        )\n",
        "\n",
        "\n",
        "        strength_drive = (\n",
        "            cfg.strength_burden_gain * (st.burden - 1.0)   # burden above baseline worsens\n",
        "            - cfg.strength_stim_gain * st.stim_ema         # sustained stim improves (anti-kindling)\n",
        "        )\n",
        "\n",
        "        # Strength updates (slow)\n",
        "        st.primary_strength = _clip(\n",
        "            st.primary_strength + cfg.primary_strength_rate * strength_drive,\n",
        "            cfg.strength_min, cfg.strength_max\n",
        "        )\n",
        "        st.secondary_strength = _clip(\n",
        "            st.secondary_strength + cfg.secondary_strength_rate * strength_drive,\n",
        "            cfg.strength_min, cfg.strength_max\n",
        "        )\n",
        "\n",
        "        # Plasticity (slow drift with burden)\n",
        "        st.plasticity = _clip(\n",
        "            st.plasticity + cfg.plasticity_rate * (st.burden - 0.5),\n",
        "            cfg.plasticity_min, cfg.plasticity_max\n",
        "        )\n",
        "\n",
        "        # Feedback mapping (8.4 output)\n",
        "        drive_scale = float(np.clip(1.0 + cfg.feedback_drive_gain * (st.burden - 0.5), 0.2, 2.0))\n",
        "        weight_scale = float(np.clip(1.0 - cfg.feedback_weight_gain * (st.burden - 0.5), 0.2, 2.0))\n",
        "\n",
        "        feedback = self.get_drive()\n",
        "        feedback[\"burden\"] = float(st.burden)\n",
        "\n",
        "\n",
        "        info = {\n",
        "            \"pathology\": pathology,\n",
        "            \"suppress\": suppress,\n",
        "            \"stim_intensity\": stim_int,\n",
        "            \"rate_raw\": rate_raw,\n",
        "            \"sync_raw\": sync_raw,\n",
        "            \"burst_raw\": burst_raw,\n",
        "            \"logEI_raw\": logEI_raw,\n",
        "        }\n",
        "\n",
        "        info[\"burden\"] = float(st.burden)\n",
        "        print(info[\"feedback\"])\n",
        "\n",
        "\n",
        "\n",
        "        return st, feedback, info\n",
        "\n",
        "    # -------------------------\n",
        "    # Observation helper\n",
        "    # -------------------------\n",
        "\n",
        "    def observation_vector(\n",
        "        self,\n",
        "        features: Optional[Dict[str, float]] = None,\n",
        "        *,\n",
        "        include_site_strengths: bool = False,\n",
        "        max_sites: int = 16,\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Produce a numeric observation vector from current state and optional recent features.\n",
        "\n",
        "        Base vector (always):\n",
        "          [burden, plasticity, primary_strength, secondary_strength]\n",
        "\n",
        "        If features provided, append:\n",
        "          [rate_hz, sync, burst, lfp]\n",
        "\n",
        "        If include_site_strengths:\n",
        "          append primary_site_strengths (padded/truncated)\n",
        "          append secondary_site_strengths (padded/truncated)\n",
        "        \"\"\"\n",
        "        st = self.state\n",
        "        x = [float(st.burden), float(st.plasticity), float(st.primary_strength), float(st.secondary_strength)]\n",
        "\n",
        "        if features is not None:\n",
        "            x.extend([\n",
        "                float(features.get(\"rate_hz\", 0.0)),\n",
        "                float(features.get(\"sync\", 0.0)),\n",
        "                float(features.get(\"burst\", 0.0)),\n",
        "                float(features.get(\"lfp\", 0.0)),\n",
        "            ])\n",
        "\n",
        "        if include_site_strengths:\n",
        "            p = st.primary_site_strengths if st.primary_site_strengths.size else np.zeros((0,), dtype=float)\n",
        "            s = st.secondary_site_strengths if st.secondary_site_strengths.size else np.zeros((0,), dtype=float)\n",
        "\n",
        "            def pad(v: np.ndarray) -> np.ndarray:\n",
        "                v = v.astype(float).reshape(-1)\n",
        "                if v.size >= max_sites:\n",
        "                    return v[:max_sites]\n",
        "                out = np.zeros((max_sites,), dtype=float)\n",
        "                out[:v.size] = v\n",
        "                return out\n",
        "\n",
        "            x.extend(pad(p).tolist())\n",
        "            x.extend(pad(s).tolist())\n",
        "\n",
        "        return np.asarray(x, dtype=np.float32)\n",
        "\n",
        "\n",
        "__all__ = [\n",
        "    \"L2Config\",\n",
        "    \"L2State\",\n",
        "    \"EpilepsyStateModel\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "ITX2KzTMmBq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, Optional, Sequence, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "\n",
        "def _lin_map(x: float, lo: float, hi: float) -> float:\n",
        "    x = float(np.clip(x, -1.0, 1.0))\n",
        "    return lo + (x + 1.0) * 0.5 * (hi - lo)\n",
        "\n",
        "\n",
        "def _waveform_from_code(x: float) -> str:\n",
        "    x = float(x)\n",
        "    if x < -0.333:\n",
        "        return \"rect\"\n",
        "    if x < 0.333:\n",
        "        return \"biphasic\"\n",
        "    return \"burst\"\n",
        "\n",
        "\n",
        "def _int_from_code(x: float, lo: int, hi: int) -> int:\n",
        "    v = _lin_map(float(x), lo - 0.49, hi + 0.49)\n",
        "    return int(np.clip(int(round(v)), lo, hi))\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class RewardConfig:\n",
        "    # Reward = delta_weight*(prev_burden - burden) - burden_weight*burden - stim_weight*stim_cost\n",
        "    burden_weight: float = 1.0\n",
        "    delta_weight: float = 1.0\n",
        "    stim_weight: float = 0.02\n",
        "\n",
        "\n",
        "class DBSGymEnv(gym.Env):\n",
        "    metadata = {\"render_modes\": []}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        case_gen,\n",
        "        plant,\n",
        "        l2_model,\n",
        "        env_cfg: Optional[Any] = None,\n",
        "        seed: int = 0,\n",
        "        reward_cfg: Optional[RewardConfig] = None,\n",
        "        forced_tissue_mode: Optional[str] = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.case_gen = case_gen\n",
        "        self.plant = plant\n",
        "        self.l2 = l2_model\n",
        "        self.cfg = env_cfg,  # alias for step() and other helpers\n",
        "\n",
        "        self.episode_len = int(getattr(env_cfg, \"episode_len\", getattr(env_cfg, \"episode_steps\", 40))) if env_cfg is not None else 40\n",
        "        self.horizon_steps = self.episode_len\n",
        "\n",
        "        self.seed_value = int(seed)\n",
        "        self.rng = np.random.default_rng(self.seed_value)\n",
        "\n",
        "        self.env_cfg = env_cfg\n",
        "        self.reward_cfg = reward_cfg or RewardConfig()\n",
        "        self.forced_tissue_mode = forced_tissue_mode\n",
        "\n",
        "        # ---- episode length (single source of truth) ----\n",
        "        self.episode_len = int(getattr(env_cfg, \"episode_len\", getattr(env_cfg, \"episode_steps\", 40))) if env_cfg is not None else 40\n",
        "        # keep horizon_steps as an alias if other code uses it\n",
        "        self.horizon_steps = self.episode_len\n",
        "\n",
        "        self.baseline_windows = int(getattr(env_cfg, \"baseline_windows\", 1)) if env_cfg is not None else 1\n",
        "\n",
        "        # Action bounds from configs.EnvConfig.dbs_bounds if available\n",
        "        if env_cfg is not None and hasattr(env_cfg, \"dbs_bounds\"):\n",
        "            b = env_cfg.dbs_bounds\n",
        "            self.amp_min_mA = float(getattr(b, \"amp_mA_min\", 0.0))\n",
        "            self.amp_max_mA = float(getattr(b, \"amp_mA_max\", 5.0))\n",
        "            self.freq_min_Hz = float(getattr(b, \"freq_Hz_min\", 5.0))\n",
        "            self.freq_max_Hz = float(getattr(b, \"freq_Hz_max\", 200.0))\n",
        "            self.pw_min_ms = float(getattr(b, \"pw_ms_min\", 0.05))\n",
        "            self.pw_max_ms = float(getattr(b, \"pw_ms_max\", 0.5))\n",
        "        else:\n",
        "            self.amp_min_mA, self.amp_max_mA = 0.0, 5.0\n",
        "            self.freq_min_Hz, self.freq_max_Hz = 5.0, 200.0\n",
        "            self.pw_min_ms, self.pw_max_ms = 0.05, 0.5\n",
        "\n",
        "        # 8D continuous action (your existing design)\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(8,), dtype=np.float32)\n",
        "\n",
        "        # Observation vector length 17 (your existing design)\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(17,), dtype=np.float32)\n",
        "\n",
        "        self._step_i = 0\n",
        "        self._case = None\n",
        "        self._last_stim: Dict[str, Any] = {\"amp_mA\": 0.0, \"freq_Hz\": 0.0, \"pw_ms\": 0.0, \"waveform\": \"rect\"}\n",
        "        self._last_features: Dict[str, float] = {\"rate_hz\": 0.0, \"sync\": 0.0, \"burst\": 0.0, \"lfp\": 0.0}\n",
        "        self._prev_burden: float = 0.0\n",
        "\n",
        "        # Optional: env.net_cfg set externally (as you already do)\n",
        "        self.net_cfg = None\n",
        "\n",
        "\n",
        "    # ----------------------------\n",
        "    # Action/obs helpers (yours)\n",
        "    # ----------------------------\n",
        "\n",
        "    def _stim_to_wave_onehot(self, stim: Dict[str, Any]) -> np.ndarray:\n",
        "        w = str(stim.get(\"waveform\", \"rect\"))\n",
        "        if w == \"rect\":\n",
        "            return np.array([1.0, 0.0, 0.0], dtype=np.float32)\n",
        "        if w == \"biphasic\":\n",
        "            return np.array([0.0, 1.0, 0.0], dtype=np.float32)\n",
        "        return np.array([0.0, 0.0, 1.0], dtype=np.float32)\n",
        "\n",
        "    def _action_to_stim(self, action: np.ndarray) -> Dict[str, Any]:\n",
        "        a = np.asarray(action, dtype=float).reshape(-1)\n",
        "        a = np.clip(a, -1.0, 1.0)\n",
        "\n",
        "        stim: Dict[str, Any] = {\n",
        "            \"amp_mA\": float(_lin_map(a[0], self.amp_min_mA, self.amp_max_mA)),\n",
        "            \"freq_Hz\": float(_lin_map(a[1], self.freq_min_Hz, self.freq_max_Hz)),\n",
        "            \"pw_ms\": float(_lin_map(a[2], self.pw_min_ms, self.pw_max_ms)),\n",
        "            \"waveform\": _waveform_from_code(a[3]),\n",
        "            \"duty_cycle\": float(_lin_map(a[4], 0.2, 1.0)),\n",
        "        }\n",
        "\n",
        "        # waveform-specific fields\n",
        "        if stim[\"waveform\"] == \"biphasic\":\n",
        "            stim[\"phase2_amp_ratio\"] = float(_lin_map(a[5], -1.2, -0.8))\n",
        "            stim[\"interphase_gap_ms\"] = float(_lin_map(a[6], 0.0, 0.2))\n",
        "        elif stim[\"waveform\"] == \"burst\":\n",
        "            stim[\"pulses_per_burst\"] = int(_int_from_code(a[7], 2, 10))\n",
        "            stim[\"intra_burst_freq_Hz\"] = float(_lin_map(a[7], 50.0, 250.0))\n",
        "            stim[\"burst_Hz\"] = float(_lin_map(a[5], 2.0, 20.0))\n",
        "\n",
        "        # hard safety clamps\n",
        "        stim[\"amp_mA\"] = float(np.clip(stim[\"amp_mA\"], self.amp_min_mA, self.amp_max_mA))\n",
        "        stim[\"freq_Hz\"] = float(np.clip(stim[\"freq_Hz\"], self.freq_min_Hz, self.freq_max_Hz))\n",
        "        stim[\"pw_ms\"]   = float(np.clip(stim[\"pw_ms\"],   self.pw_min_ms,  self.pw_max_ms))\n",
        "\n",
        "        # enforce min amp if desired\n",
        "        min_amp = float(getattr(self.env_cfg, \"min_amp_mA\", 0.0)) if self.env_cfg is not None else 0.0\n",
        "        stim[\"amp_mA\"] = max(float(stim[\"amp_mA\"]), min_amp)\n",
        "\n",
        "        return stim\n",
        "\n",
        "    def _case_desc(self, case) -> np.ndarray:\n",
        "        sev = float(getattr(case, \"severity\", 0.0))\n",
        "        base = float(getattr(case, \"baseline_burden\", 0.0))\n",
        "        dist = 0.0\n",
        "        try:\n",
        "            dist = float(case.descriptors.get(\"primary_dist_mm\", 0.0))\n",
        "        except Exception:\n",
        "            dist = 0.0\n",
        "        return np.array([sev, base, dist], dtype=np.float32)\n",
        "\n",
        "    def _obs(self) -> np.ndarray:\n",
        "        # l2.observation_vector(features) must return length 8\n",
        "        l2v = self.l2.observation_vector(self._last_features, include_site_strengths=False).astype(np.float32)\n",
        "\n",
        "        last = np.array(\n",
        "            [\n",
        "                float(self._last_stim.get(\"amp_mA\", 0.0)),\n",
        "                float(self._last_stim.get(\"freq_Hz\", 0.0)),\n",
        "                float(self._last_stim.get(\"pw_ms\", 0.0)),\n",
        "            ],\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "        w = self._stim_to_wave_onehot(self._last_stim)\n",
        "        cdesc = self._case_desc(self._case) if self._case is not None else np.zeros((3,), dtype=np.float32)\n",
        "\n",
        "        obs = np.concatenate([l2v, last, w, cdesc], dtype=np.float32)\n",
        "        return obs\n",
        "\n",
        "    # ----------------------------\n",
        "    # Gymnasium API\n",
        "    # ----------------------------\n",
        "\n",
        "    def reset(self, *, seed: Optional[int] = None, options: Optional[Dict[str, Any]] = None):\n",
        "        super().reset(seed=seed)\n",
        "        if seed is not None:\n",
        "            self.seed_value = int(seed)\n",
        "            self.rng = np.random.default_rng(self.seed_value)\n",
        "\n",
        "        self._step_i = 0\n",
        "\n",
        "        # Sample (or reuse) case\n",
        "        reuse = bool(getattr(self, \"freeze_case\", False)) and (getattr(self, \"_case\", None) is not None)\n",
        "\n",
        "        if reuse:\n",
        "            case = self._case\n",
        "        else:\n",
        "            if self.forced_tissue_mode:\n",
        "                case = self.case_gen.sample(tags={\"forced_tissue_mode\": self.forced_tissue_mode})\n",
        "            else:\n",
        "                case = self.case_gen.sample()\n",
        "            self._case = case\n",
        "\n",
        "        # Rebuild plant\n",
        "        self.plant.build_from_case(case, net_cfg=getattr(self, \"net_cfg\", None))\n",
        "\n",
        "        # Coupling: pass Vec3 (shape (3,)), not (1,3)\n",
        "        stim_xyz_mm = np.asarray(case.electrode.xyz_mm, dtype=float).reshape(3,)\n",
        "        self.plant.precompute_coupling(tuple(stim_xyz_mm.tolist()))\n",
        "\n",
        "        # Reset L2\n",
        "        self.l2.reset(case=case)\n",
        "\n",
        "        # Default zero stimulation for baselining\n",
        "        self._last_stim = {\"amp_mA\": 0.0, \"freq_Hz\": 0.0, \"pw_ms\": 0.0, \"waveform\": \"rect\", \"duty_cycle\": 1.0}\n",
        "\n",
        "        # Initialize features with the keys your plant/L2 actually use (safe defaults)\n",
        "        self._last_features = {\n",
        "            \"n_spikes\": 0.0,\n",
        "            \"rate_hz\": 0.0,\n",
        "            \"E_rate_hz\": 0.0,\n",
        "            \"I_rate_hz\": 0.0,\n",
        "            \"EI_ratio\": 1.0,\n",
        "            \"burst_E\": 0.0,\n",
        "            \"sync_E\": 0.0,\n",
        "            \"lfp\": 0.0,\n",
        "        }\n",
        "\n",
        "        # Baseline windows: run plant, update L2, apply feedback to plant\n",
        "        for _ in range(max(0, int(self.baseline_windows))):\n",
        "            feats = self.plant.run_window(self._last_stim)\n",
        "            self._last_features = feats\n",
        "\n",
        "            st, feedback, _info = self.l2.step(features=feats, stim=self._last_stim, case=case)\n",
        "            if isinstance(feedback, dict):\n",
        "                self.plant.update_focus_drive(feedback)\n",
        "            else:\n",
        "                self.plant.update_focus_drive({})\n",
        "\n",
        "        # Set prev burden defensively\n",
        "        burden = 0.0\n",
        "        if hasattr(self.l2, \"state\") and self.l2.state is not None:\n",
        "            burden = float(getattr(self.l2.state, \"burden\", 0.0))\n",
        "        self._prev_burden = burden\n",
        "\n",
        "        return self._obs(), {\"case_id\": getattr(case, \"case_id\", None)}\n",
        "\n",
        "\n",
        "    def step(self, action: np.ndarray):\n",
        "        self._step_i += 1\n",
        "\n",
        "        # 1) action -> stim (ensure dict with required keys)\n",
        "        stim = self._action_to_stim(action)\n",
        "        if not isinstance(stim, dict):\n",
        "            # fallback: convert to dict if user returned StimParams or array\n",
        "            try:\n",
        "                stim = dict(stim)  # type: ignore[arg-type]\n",
        "            except Exception:\n",
        "                stim = {\n",
        "                    \"amp_mA\": float(stim[0]),\n",
        "                    \"freq_Hz\": float(stim[1]),\n",
        "                    \"pw_ms\": float(stim[2]),\n",
        "                }\n",
        "        stim.setdefault(\"waveform\", \"rect\")\n",
        "        stim.setdefault(\"duty_cycle\", 1.0)\n",
        "\n",
        "        self._last_stim = stim\n",
        "\n",
        "        # 2) run Level-1 plant\n",
        "        feats = self.plant.run_window(stim)\n",
        "        self._last_features = feats\n",
        "\n",
        "        # 3) Level-2 update\n",
        "        st, feedback, l2_info = self.l2.step(features=feats, stim=stim, case=self._case)\n",
        "\n",
        "        # 4) 8.4: apply feedback back into plant every step\n",
        "        if isinstance(feedback, dict):\n",
        "            self.plant.update_focus_drive(feedback)\n",
        "        else:\n",
        "            # be defensive\n",
        "            self.plant.update_focus_drive({})\n",
        "\n",
        "        # 5) reward: improvement-based + stimulation cost\n",
        "        bur = float(getattr(st, \"burden\", 0.0))\n",
        "\n",
        "        stim_cost = float(getattr(self.reward_cfg, \"stim_cost\", 0.05)) if self.reward_cfg is not None else 0.05\n",
        "        stim_int = 0.0\n",
        "        if isinstance(l2_info, dict):\n",
        "            stim_int = float(l2_info.get(\"stim_intensity\", 0.0))\n",
        "\n",
        "        reward = (self._prev_burden - bur) - stim_cost * stim_int\n",
        "        self._prev_burden = bur\n",
        "\n",
        "        # 6) termination / truncation\n",
        "        terminated = False\n",
        "        truncated = bool(self._step_i >= int(self.episode_len))\n",
        "\n",
        "        # 7) info\n",
        "        info: Dict[str, Any] = {\n",
        "            \"case_id\": getattr(self._case, \"case_id\", None),\n",
        "            \"stim\": stim,\n",
        "            \"features\": feats,\n",
        "            \"l2_state\": st,\n",
        "            \"feedback\": feedback,\n",
        "        }\n",
        "        if isinstance(l2_info, dict):\n",
        "            info.update(l2_info)\n",
        "\n",
        "        return self._obs(), float(reward), terminated, truncated, info\n",
        "\n"
      ],
      "metadata": {
        "id": "tr3p1Uc4bAck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_env(\n",
        "    seed: int = 0,\n",
        "    episode_len: int = 50,\n",
        "    forced_tissue_mode: str | None = None,\n",
        "    freeze_case: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Top-level factory function for creating DBSGymEnv.\n",
        "    Put this in a notebook cell BELOW DBSGymEnv and all config classes.\n",
        "    \"\"\"\n",
        "    mode = forced_tissue_mode or \"BOUNDARY\"\n",
        "\n",
        "    # ---- Env config ----\n",
        "    env_cfg = EnvConfig(\n",
        "        episode_steps=int(episode_len),\n",
        "        baseline_windows=3,\n",
        "        dbs_bounds=DBSBounds(\n",
        "            amp_mA_min=0.1, amp_mA_max=3.0,\n",
        "            freq_Hz_min=5.0, freq_Hz_max=150.0,\n",
        "            pw_ms_min=0.05, pw_ms_max=0.4,\n",
        "        ),\n",
        "        include_last_action_in_obs=True,\n",
        "    )\n",
        "\n",
        "    # ---- Plant config ----\n",
        "    plant_cfg = PlantConfig(dt_ms=0.05, window_ms=250.0, sigma_S_per_m=0.2)\n",
        "\n",
        "    # ---- Network config (passed into plant via env.net_cfg -> reset -> build_from_case) ----\n",
        "    net_cfg = NetworkConfig(n_cells=60, frac_gm=0.7, tissue_mode=mode)\n",
        "\n",
        "    # ---- Components ----\n",
        "    case_gen = CaseGenerator(cfg=CaseGeneratorConfig(), rng_seed=seed)\n",
        "    plant = FullNeuronPlant(plant_cfg, rng_seed=seed)   # FIX: use plant_cfg, not cfg.plant\n",
        "    l2_model = EpilepsyStateModel(rng_seed=seed)\n",
        "\n",
        "    # ---- Sanity checks ----\n",
        "    assert type(plant).__name__ == \"FullNeuronPlant\", f\"Using {type(plant)} not FullNeuronPlant\"\n",
        "    assert callable(getattr(plant, \"run_window\", None)), \"plant.run_window missing\"\n",
        "\n",
        "    # ---- Env ----\n",
        "    env = DBSGymEnv(\n",
        "        case_gen=case_gen,\n",
        "        plant=plant,\n",
        "        l2_model=l2_model,\n",
        "        env_cfg=env_cfg,\n",
        "        seed=seed,\n",
        "        forced_tissue_mode=mode,\n",
        "    )\n",
        "\n",
        "    # Your reset() already does: build_from_case(case, net_cfg=getattr(self, \"net_cfg\", None))\n",
        "    env.net_cfg = net_cfg\n",
        "\n",
        "    # If you want a single authoritative episode length in env:\n",
        "    env.episode_len = int(episode_len)\n",
        "\n",
        "    env.freeze_case = bool(freeze_case)\n",
        "\n",
        "\n",
        "    return env\n",
        "\n"
      ],
      "metadata": {
        "id": "HTfzjAUcRrD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ss3MZv6BmulF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c08adf1-001e-4216-d19a-8071165f5503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "# sac_agent.py\n",
        "\"\"\"\n",
        "SAC agent wrapper for the DBS-epilepsy project.\n",
        "\n",
        "This module prioritizes Stable-Baselines3 (SB3) SAC for correctness and speed of iteration.\n",
        "If SB3 is not installed, it raises a clear error with installation instructions.\n",
        "\n",
        "Assumptions:\n",
        "- Your Gymnasium environment is implemented in env.py as DBSGymEnv (or similar).\n",
        "- Action space is continuous Box, observation space is Box.\n",
        "\n",
        "Install (recommended):\n",
        "  pip install \"stable-baselines3[extra]\" gymnasium torch\n",
        "\n",
        "Notes:\n",
        "- SAC-MAML/meta-learning is NOT implemented here; this is a clean SAC baseline.\n",
        "- This wrapper standardizes configuration, seeding, saving, evaluation rollouts, etc.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, Optional, Tuple\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    from stable_baselines3 import SAC\n",
        "    from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "    from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
        "    from stable_baselines3.common.monitor import Monitor\n",
        "except Exception as e:  # pragma: no cover\n",
        "    SAC = None  # type: ignore\n",
        "    CheckpointCallback = None  # type: ignore\n",
        "    DummyVecEnv = None  # type: ignore\n",
        "    VecMonitor = None  # type: ignore\n",
        "    Monitor = None  # type: ignore\n",
        "    _SB3_IMPORT_ERROR = e\n",
        "else:\n",
        "    _SB3_IMPORT_ERROR = None\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class SACConfig:\n",
        "    # Training\n",
        "    total_timesteps: int = 200_000\n",
        "    learning_rate: float = 3e-4\n",
        "    buffer_size: int = 200_000\n",
        "    batch_size: int = 256\n",
        "    gamma: float = 0.99\n",
        "    tau: float = 0.005\n",
        "    train_freq: int = 1\n",
        "    gradient_steps: int = 1\n",
        "    learning_starts: int = 5_000\n",
        "\n",
        "    # Exploration / entropy\n",
        "    ent_coef: str = \"auto\"  # or float\n",
        "\n",
        "    # Network architecture\n",
        "    net_arch: Tuple[int, int] = (256, 256)\n",
        "\n",
        "    # Evaluation / logging\n",
        "    seed: int = 0\n",
        "    log_dir: str = \"runs/sac\"\n",
        "    save_every_steps: int = 50_000\n",
        "\n",
        "    # Device\n",
        "    device: str = \"auto\"\n",
        "\n",
        "\n",
        "class SACAgent:\n",
        "    def __init__(self, env, cfg: Optional[SACConfig] = None):\n",
        "        if _SB3_IMPORT_ERROR is not None:\n",
        "            raise RuntimeError(\n",
        "                \"Stable-Baselines3 is not installed or failed to import.\\n\\n\"\n",
        "                \"Install with:\\n\"\n",
        "                \"  pip install \\\"stable-baselines3[extra]\\\" gymnasium torch\\n\\n\"\n",
        "                f\"Import error: {_SB3_IMPORT_ERROR}\"\n",
        "            )\n",
        "\n",
        "        self.env = env\n",
        "        self.cfg = cfg or SACConfig()\n",
        "\n",
        "        os.makedirs(self.cfg.log_dir, exist_ok=True)\n",
        "\n",
        "        # Wrap env for logging\n",
        "        # Use Monitor for episode returns/lengths; VecMonitor for vec env stats\n",
        "        def _make():\n",
        "            return Monitor(self.env)\n",
        "\n",
        "        venv = DummyVecEnv([_make])\n",
        "        venv = VecMonitor(venv, filename=os.path.join(self.cfg.log_dir, \"monitor.csv\"))\n",
        "        self.venv = venv\n",
        "\n",
        "        policy_kwargs = dict(net_arch=list(self.cfg.net_arch))\n",
        "\n",
        "        self.model = SAC(\n",
        "            policy=\"MlpPolicy\",\n",
        "            env=self.venv,\n",
        "            learning_rate=self.cfg.learning_rate,\n",
        "            buffer_size=self.cfg.buffer_size,\n",
        "            batch_size=self.cfg.batch_size,\n",
        "            tau=self.cfg.tau,\n",
        "            gamma=self.cfg.gamma,\n",
        "            train_freq=self.cfg.train_freq,\n",
        "            gradient_steps=self.cfg.gradient_steps,\n",
        "            learning_starts=self.cfg.learning_starts,\n",
        "            ent_coef=self.cfg.ent_coef,\n",
        "            policy_kwargs=policy_kwargs,\n",
        "            verbose=1,\n",
        "            device=self.cfg.device,\n",
        "            seed=self.cfg.seed,\n",
        "        )\n",
        "\n",
        "    def train(self) -> str:\n",
        "        \"\"\"Train SAC and return the final model path.\"\"\"\n",
        "        ts = int(time.time())\n",
        "        run_name = f\"sac_{ts}\"\n",
        "        run_dir = os.path.join(self.cfg.log_dir, run_name)\n",
        "        os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "        cb = CheckpointCallback(\n",
        "            save_freq=self.cfg.save_every_steps,\n",
        "            save_path=run_dir,\n",
        "            name_prefix=\"checkpoint\",\n",
        "            save_replay_buffer=True,\n",
        "            save_vecnormalize=False,\n",
        "        )\n",
        "\n",
        "        self.model.learn(total_timesteps=self.cfg.total_timesteps, callback=cb)\n",
        "\n",
        "        final_path = os.path.join(run_dir, \"final_model.zip\")\n",
        "        self.model.save(final_path)\n",
        "        return final_path\n",
        "\n",
        "    def save(self, path: str) -> None:\n",
        "        self.model.save(path)\n",
        "\n",
        "    @staticmethod\n",
        "    def load(path: str, env) -> \"SACAgent\":\n",
        "        \"\"\"Load a trained SAC model and attach to env.\"\"\"\n",
        "        if _SB3_IMPORT_ERROR is not None:\n",
        "            raise RuntimeError(\"SB3 not available.\") from _SB3_IMPORT_ERROR\n",
        "\n",
        "        agent = SACAgent.__new__(SACAgent)\n",
        "        agent.env = env\n",
        "        agent.cfg = SACConfig()\n",
        "        agent.model = SAC.load(path, env=env)\n",
        "        agent.venv = None\n",
        "        return agent\n",
        "\n",
        "    def act(self, obs: np.ndarray, deterministic: bool = True) -> np.ndarray:\n",
        "        \"\"\"Single-step action for a raw (non-vec) observation.\"\"\"\n",
        "        action, _ = self.model.predict(obs, deterministic=deterministic)\n",
        "        return action\n",
        "\n",
        "    def rollout(self, n_episodes: int = 5, deterministic: bool = True) -> Dict[str, float]:\n",
        "        \"\"\"Evaluate on the underlying raw env (not vectorized).\"\"\"\n",
        "        returns = []\n",
        "        lengths = []\n",
        "        for _ in range(n_episodes):\n",
        "            obs, _ = self.env.reset()\n",
        "            done = False\n",
        "            ep_ret = 0.0\n",
        "            ep_len = 0\n",
        "            while not done:\n",
        "                action = self.act(obs, deterministic=deterministic)\n",
        "                obs, reward, terminated, truncated, _info = self.env.step(action)\n",
        "                done = bool(terminated or truncated)\n",
        "                ep_ret += float(reward)\n",
        "                ep_len += 1\n",
        "            returns.append(ep_ret)\n",
        "            lengths.append(ep_len)\n",
        "        return {\n",
        "            \"return_mean\": float(np.mean(returns)) if returns else 0.0,\n",
        "            \"return_std\": float(np.std(returns)) if returns else 0.0,\n",
        "            \"len_mean\": float(np.mean(lengths)) if lengths else 0.0,\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBPyXQfzUVSZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "f878148e-f94a-4988-c63b-2bf71e411c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(self, cfg: 'Optional[L2Config]' = None, rng_seed: 'int' = 0)\n",
            "[onset] primary_sites: (5, 3) secondary_sites: (8, 3)\n",
            "[onset] primary drives: 5 secondary drives: 8\n",
            "[record] n=8 thr=-20.0 E=4 I=4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'feedback'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-247177482.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-247177482.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# ---- smoke test ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reset obs shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3639197885.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeedback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_stim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeedback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_focus_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-893639104.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, features, stim, case)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"burden\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mburden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feedback\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'feedback'"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # ---- configs ----\n",
        "    plant_cfg = PlantConfig(dt_ms=0.05, window_ms=250.0, sigma_S_per_m=0.2)\n",
        "    net_cfg = NetworkConfig(n_cells=60, frac_gm=0.7, tissue_mode=\"BOUNDARY\")\n",
        "\n",
        "    env_cfg = EnvConfig(\n",
        "        episode_steps=20,\n",
        "        baseline_windows=1,\n",
        "        dbs_bounds=DBSBounds(\n",
        "            amp_mA_min=0.0, amp_mA_max=3.0,\n",
        "            freq_Hz_min=5.0, freq_Hz_max=150.0,\n",
        "            pw_ms_min=0.05, pw_ms_max=0.4,\n",
        "        ),\n",
        "        include_last_action_in_obs=True,\n",
        "    )\n",
        "\n",
        "    # ---- runtime objects ----\n",
        "    case_gen = CaseGenerator(\n",
        "        cfg=CaseGeneratorConfig(),\n",
        "        rng_seed=0,\n",
        "    )\n",
        "\n",
        "    plant = FullNeuronPlant(\n",
        "        cfg=plant_cfg,\n",
        "        rng_seed=0,\n",
        "    )\n",
        "\n",
        "    l2_model = EpilepsyStateModel(rng_seed=0)\n",
        "\n",
        "    # ---- environment ----\n",
        "    env = DBSGymEnv(\n",
        "        case_gen=case_gen,\n",
        "        plant=plant,\n",
        "        l2_model=l2_model,\n",
        "        env_cfg=env_cfg,\n",
        "        seed=0,\n",
        "        forced_tissue_mode=\"BOUNDARY\",\n",
        "    )\n",
        "\n",
        "    # Make net_cfg available to env / plant\n",
        "    env.net_cfg = net_cfg\n",
        "\n",
        "    # ---- smoke test ----\n",
        "    obs, info = env.reset()\n",
        "    print(\"Reset obs shape:\", obs.shape)\n",
        "\n",
        "    for t in range(env_cfg.episode_steps):\n",
        "        a = env.action_space.sample()\n",
        "        obs, r, term, trunc, info = env.step(a)\n",
        "        print(\n",
        "            f\"t={t:02d} r={r:.3f} \"\n",
        "            f\"burden={info['l2_state'].burden:.3f} \"\n",
        "            f\"stim={info['stim']} \"\n",
        "            f\"feats={info['features']}\"\n",
        "        )\n",
        "        if term or trunc:\n",
        "            break\n",
        "\n",
        "\n",
        "import inspect\n",
        "print(inspect.signature(EpilepsyStateModel.__init__))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "def _deepcopy_l2_state(l2):\n",
        "    \"\"\"\n",
        "    Robust snapshot/restore for your L2 model state.\n",
        "    L2State contains numpy arrays; copy.deepcopy is fine here.\n",
        "    \"\"\"\n",
        "    return copy.deepcopy(l2.state)\n",
        "\n",
        "def _restore_l2_state(l2, state_snapshot):\n",
        "    l2.state = copy.deepcopy(state_snapshot)\n",
        "\n",
        "def rollout_fixed_stim(env, stim_dict, steps=40, *, reset_case=False, seed=0):\n",
        "    \"\"\"\n",
        "    Rollout for a fixed stimulation dictionary.\n",
        "    If reset_case=True, env.reset(seed=seed) will resample a new case.\n",
        "    For Fix A, you generally want reset_case=False to keep the same case.\n",
        "    Returns arrays of burden, E_rate, I_rate, sync_E, n_spikes.\n",
        "    \"\"\"\n",
        "    if reset_case:\n",
        "        env.reset(seed=seed)\n",
        "\n",
        "    burdens = []\n",
        "    E_rates = []\n",
        "    I_rates = []\n",
        "    syncEs  = []\n",
        "    spikes  = []\n",
        "\n",
        "    for _ in range(steps):\n",
        "        feats = env.plant.run_window(stim_dict)\n",
        "        env._last_features = feats\n",
        "        env._last_stim = stim_dict\n",
        "\n",
        "        st, feedback, l2_info = env.l2.step(features=feats, stim=stim_dict, case=env._case)\n",
        "\n",
        "        # Keep the intended L2->L1 coupling consistent with your env.step()\n",
        "        env.plant.update_focus_drive(feedback)\n",
        "\n",
        "        burdens.append(float(getattr(st, \"burden\", np.nan)))\n",
        "        E_rates.append(float(feats.get(\"E_rate_hz\", feats.get(\"rate_hz\", 0.0))))\n",
        "        I_rates.append(float(feats.get(\"I_rate_hz\", 0.0)))\n",
        "        syncEs.append(float(feats.get(\"sync_E\", feats.get(\"sync\", 0.0))))\n",
        "        spikes.append(float(feats.get(\"n_spikes\", 0.0)))\n",
        "\n",
        "    return {\n",
        "        \"burden\": np.asarray(burdens, dtype=float),\n",
        "        \"E_rate_hz\": np.asarray(E_rates, dtype=float),\n",
        "        \"I_rate_hz\": np.asarray(I_rates, dtype=float),\n",
        "        \"sync_E\": np.asarray(syncEs, dtype=float),\n",
        "        \"n_spikes\": np.asarray(spikes, dtype=float),\n",
        "    }\n",
        "\n",
        "def compare_off_on_same_case(\n",
        "    seed=0,\n",
        "    episode_len=50,\n",
        "    forced_tissue_mode=\"BOUNDARY\",\n",
        "    steps=40,\n",
        "    stim_on=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Fix A: OFF vs ON comparison with the SAME case.\n",
        "    - Builds env\n",
        "    - Resets once (samples one case)\n",
        "    - Snapshots L2 state\n",
        "    - Runs OFF rollout (amp=0) from snapshot\n",
        "    - Restores snapshot\n",
        "    - Runs ON rollout from snapshot\n",
        "    - Prints summary deltas\n",
        "    \"\"\"\n",
        "    env = build_env(seed=seed, episode_len=episode_len, forced_tissue_mode=forced_tissue_mode)\n",
        "    obs, info = env.reset(seed=seed)\n",
        "\n",
        "    # Default ON stimulation (reasonable DBS-like starting point)\n",
        "    if stim_on is None:\n",
        "        stim_on = {\n",
        "            \"amp_mA\": 1.5,\n",
        "            \"freq_Hz\": 130.0,\n",
        "            \"pw_ms\": 0.15,\n",
        "            \"waveform\": \"rect\",\n",
        "            \"duty_cycle\": 1.0,\n",
        "        }\n",
        "\n",
        "    stim_off = {\n",
        "        \"amp_mA\": 0.0,\n",
        "        \"freq_Hz\": float(stim_on.get(\"freq_Hz\", 130.0)),\n",
        "        \"pw_ms\": float(stim_on.get(\"pw_ms\", 0.15)),\n",
        "        \"waveform\": str(stim_on.get(\"waveform\", \"rect\")),\n",
        "        \"duty_cycle\": float(stim_on.get(\"duty_cycle\", 1.0)),\n",
        "    }\n",
        "\n",
        "    # Snapshot L2 state after reset (and after baseline windows your env.reset() ran)\n",
        "    snap = _deepcopy_l2_state(env.l2)\n",
        "\n",
        "    # OFF rollout\n",
        "    _restore_l2_state(env.l2, snap)\n",
        "    off = rollout_fixed_stim(env, stim_off, steps=steps, reset_case=False, seed=seed)\n",
        "\n",
        "    # ON rollout (restore same initial L2 state)\n",
        "    _restore_l2_state(env.l2, snap)\n",
        "    on = rollout_fixed_stim(env, stim_on, steps=steps, reset_case=False, seed=seed)\n",
        "\n",
        "    # Summaries\n",
        "    def summarize(tag, d):\n",
        "        return {\n",
        "            \"tag\": tag,\n",
        "            \"burden_end\": float(d[\"burden\"][-1]),\n",
        "            \"burden_mean\": float(np.mean(d[\"burden\"])),\n",
        "            \"E_rate_mean\": float(np.mean(d[\"E_rate_hz\"])),\n",
        "            \"I_rate_mean\": float(np.mean(d[\"I_rate_hz\"])),\n",
        "            \"syncE_mean\": float(np.mean(d[\"sync_E\"])),\n",
        "            \"spikes_mean\": float(np.mean(d[\"n_spikes\"])),\n",
        "        }\n",
        "\n",
        "    s_off = summarize(\"OFF\", off)\n",
        "    s_on  = summarize(\"ON\", on)\n",
        "\n",
        "    print(\"Case:\", getattr(env._case, \"case_id\", None), \"mode:\", forced_tissue_mode)\n",
        "    print(\"OFF summary:\", s_off)\n",
        "    print(\"ON  summary:\", s_on)\n",
        "\n",
        "    # Deltas (ON - OFF): negative is suppressive for burden/E_rate/sync/spikes\n",
        "    print(\"\\nDeltas (ON - OFF):\")\n",
        "    print(\"  burden_end:\", s_on[\"burden_end\"] - s_off[\"burden_end\"])\n",
        "    print(\"  burden_mean:\", s_on[\"burden_mean\"] - s_off[\"burden_mean\"])\n",
        "    print(\"  E_rate_mean:\", s_on[\"E_rate_mean\"] - s_off[\"E_rate_mean\"])\n",
        "    print(\"  I_rate_mean:\", s_on[\"I_rate_mean\"] - s_off[\"I_rate_mean\"])\n",
        "    print(\"  syncE_mean:\", s_on[\"syncE_mean\"] - s_off[\"syncE_mean\"])\n",
        "    print(\"  spikes_mean:\", s_on[\"spikes_mean\"] - s_off[\"spikes_mean\"])\n",
        "\n",
        "    return env, off, on\n"
      ],
      "metadata": {
        "id": "QAs6ag_Z1Xil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env, off, on = compare_off_on_same_case(\n",
        "    seed=0,\n",
        "    forced_tissue_mode=\"BOUNDARY\",\n",
        "    steps=40,\n",
        "    stim_on={\"amp_mA\": 1.5, \"freq_Hz\": 130.0, \"pw_ms\": 0.15, \"waveform\": \"rect\", \"duty_cycle\": 1.0},\n",
        ")\n"
      ],
      "metadata": {
        "id": "COJfF6mk1adP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Has FullNeuronPlant.run_window?\", \"run_window\" in FullNeuronPlant.__dict__)\n",
        "print(\"FullNeuronPlant.run_window is:\", FullNeuronPlant.__dict__.get(\"run_window\", None))\n",
        "print(\"MRO:\", [c.__name__ for c in FullNeuronPlant.mro()])\n"
      ],
      "metadata": {
        "id": "Mjl46EZ1ZAFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Has FullNeuronPlant.run_window?\", \"run_window\" in FullNeuronPlant.__dict__)\n",
        "print(\"Bound method comes from:\", FullNeuronPlant.run_window.__qualname__)\n"
      ],
      "metadata": {
        "id": "aT7voz6vZqpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-flight: confirm build_env exists (and if not, tell us why)\n",
        "print(\"build_env defined?\", \"build_env\" in globals())\n",
        "\n",
        "# If not defined, run all cells above this one, or re-run the big definitions cell.\n",
        "# Optional: list near-matches that may exist\n",
        "print([k for k in globals().keys() if \"build\" in k.lower() or \"env\" in k.lower()])\n",
        "\n",
        "print(\"build_env defined?\", \"build_env\" in globals())\n",
        "\n"
      ],
      "metadata": {
        "id": "pgL2i5rEQRXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def rollout_burden(env, steps=50, seed=0):\n",
        "    obs, info = env.reset(seed=seed)\n",
        "    burdens, spike_counts = [], []\n",
        "\n",
        "    # infer window length in seconds (fallback: 250 ms)\n",
        "    window_ms = 400.0\n",
        "    for obj in [env, getattr(env, \"unwrapped\", None)]:\n",
        "        if obj is None:\n",
        "            continue\n",
        "        plant = getattr(obj, \"plant\", None)\n",
        "        if plant is not None and hasattr(plant, \"cfg\"):\n",
        "            window_ms = float(getattr(plant.cfg, \"window_ms\", window_ms))\n",
        "            break\n",
        "    window_s = window_ms / 1000.0\n",
        "\n",
        "\n",
        "    for t in range(steps):\n",
        "        action = env.action_space.sample()\n",
        "        obs, r, term, trunc, info = env.step(action)\n",
        "\n",
        "        b_val = None\n",
        "\n",
        "        # 1) Preferred: L2 state if your env exposes it\n",
        "        if hasattr(env, \"l2\") and hasattr(env.l2, \"state\") and hasattr(env.l2.state, \"burden\"):\n",
        "            b_val = float(env.l2.state.burden)\n",
        "\n",
        "        # 2) If you store it on env directly\n",
        "        elif hasattr(env, \"l2_state\") and hasattr(env.l2_state, \"burden\"):\n",
        "            b_val = float(env.l2_state.burden)\n",
        "\n",
        "        # 3) Info dict (works if you set info[\"burden\"] = st.burden in L2)\n",
        "        elif isinstance(info, dict) and (\"burden\" in info):\n",
        "            try:\n",
        "                b_val = float(info[\"burden\"])\n",
        "            except Exception:\n",
        "                b_val = None\n",
        "\n",
        "        if b_val is None or not np.isfinite(b_val):\n",
        "            raise RuntimeError(f\"Burden missing/invalid at step {t}. info keys={list(info.keys())}\")\n",
        "\n",
        "        burdens.append(b_val)\n",
        "\n",
        "        feats = info.get(\"features\", {}) or {}\n",
        "        if \"n_spikes\" in feats:\n",
        "            spike_counts.append(float(feats[\"n_spikes\"]))\n",
        "        else:\n",
        "            rate_hz = float(feats.get(\"rate_hz\", 0.0))\n",
        "            spike_counts.append(rate_hz * window_s)\n",
        "\n",
        "\n",
        "        if term or trunc:\n",
        "            break\n",
        "\n",
        "    return np.array(burdens), np.array(spike_counts)\n",
        "\n",
        "env = build_env(seed=0, episode_len=50, forced_tissue_mode=\"BOUNDARY\")\n",
        "b, s = rollout_burden(env, steps=50, seed=0)\n",
        "\n",
        "print(\"Burden min/max:\", np.nanmin(b), np.nanmax(b))\n",
        "print(\"SpikeCount(win) min/max:\", np.nanmin(s), np.nanmax(s))\n",
        "\n"
      ],
      "metadata": {
        "id": "ckv_Z5MDcaRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rollout_fixed_stim(env_builder, steps=100, seed=0, mode=\"BOUNDARY\", case_id=None, stim_on=None):\n",
        "    \"\"\"\n",
        "    Builds two envs with identical case/seed and runs OFF vs ON.\n",
        "    env_builder: a callable like build_env(...) that returns a fresh env.\n",
        "    stim_on: dict of stim params for ON. OFF uses amp_mA=0 with same rest.\n",
        "    \"\"\"\n",
        "\n",
        "    # Build OFF env and freeze its case after reset\n",
        "    env_off = env_builder(seed=seed, episode_len=steps, forced_tissue_mode=mode)\n",
        "    obs_off, info_off = env_off.reset(seed=seed)\n",
        "\n",
        "    # If your env exposes case_id after reset, capture it\n",
        "    # Otherwise provide case_id explicitly to your builder if supported.\n",
        "    if case_id is None:\n",
        "        case_id = getattr(getattr(env_off, \"case\", None), \"case_id\", None) or info_off.get(\"case_id\", None)\n",
        "\n",
        "    # Build ON env with the SAME case_id if your builder supports it.\n",
        "    # If it doesn't, you must modify build_env/build_case to accept a fixed case_id.\n",
        "    env_on = env_builder(seed=seed, episode_len=steps, forced_tissue_mode=mode, forced_case_id=case_id) \\\n",
        "             if \"forced_case_id\" in env_builder.__code__.co_varnames else env_builder(seed=seed, episode_len=steps, forced_tissue_mode=mode)\n",
        "    obs_on, info_on = env_on.reset(seed=seed)\n",
        "\n",
        "    if stim_on is None:\n",
        "        stim_on = {\"amp_mA\": 1.0, \"freq_Hz\": 130.0, \"pw_ms\": 0.1, \"waveform\": \"rect\", \"duty_cycle\": 1.0}\n",
        "\n",
        "    stim_off = dict(stim_on)\n",
        "    stim_off[\"amp_mA\"] = 0.0\n",
        "\n",
        "    def run(env, stim):\n",
        "        burdens, spikes = [], []\n",
        "        for t in range(steps):\n",
        "            obs, r, term, trunc, info = env.step(stim)\n",
        "            # prefer info burden; ensure L2 sets it\n",
        "            burdens.append(float(info[\"burden\"]))\n",
        "            feats = info.get(\"features\", {}) or {}\n",
        "            spikes.append(float(feats.get(\"n_spikes\", 0.0)))\n",
        "            if term or trunc:\n",
        "                break\n",
        "        return np.asarray(burdens), np.asarray(spikes)\n",
        "\n",
        "    b_off, s_off = run(env_off, stim_off)\n",
        "    b_on,  s_on  = run(env_on,  stim_on)\n",
        "\n",
        "    return {\n",
        "        \"case_id\": case_id,\n",
        "        \"OFF\": {\"burden_end\": float(b_off[-1]), \"burden_mean\": float(np.mean(b_off)), \"spikes_mean\": float(np.mean(s_off))},\n",
        "        \"ON\":  {\"burden_end\": float(b_on[-1]),  \"burden_mean\": float(np.mean(b_on)),  \"spikes_mean\": float(np.mean(s_on))},\n",
        "        \"b_off\": b_off, \"b_on\": b_on, \"s_off\": s_off, \"s_on\": s_on\n",
        "    }\n"
      ],
      "metadata": {
        "id": "l5yQ7SZfkiuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from neuron import h\n",
        "\n",
        "def quick_spike_test(\n",
        "    sec,\n",
        "    amp_nA=0.2,\n",
        "    delay_ms=5.0,\n",
        "    dur_ms=5.0,\n",
        "    tstop_ms=30.0,\n",
        "    v_init=-65.0,\n",
        "    spike_threshold_mV=0.0,\n",
        "):\n",
        "    \"\"\"\n",
        "    Inject a brief current pulse into a NEURON Section and report Vm excursion.\n",
        "    Also reports whether a spike-like crossing occurred (simple threshold crossing).\n",
        "    \"\"\"\n",
        "    # Ensure active excitability (HH); ignore if already present or not allowed\n",
        "    try:\n",
        "        sec.insert(\"hh\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    stim = h.IClamp(sec(0.5))\n",
        "    stim.delay = float(delay_ms)\n",
        "    stim.dur   = float(dur_ms)\n",
        "    stim.amp   = float(amp_nA)   # nA\n",
        "\n",
        "    v = h.Vector(); v.record(sec(0.5)._ref_v)\n",
        "    t = h.Vector(); t.record(h._ref_t)\n",
        "\n",
        "    h.finitialize(float(v_init))\n",
        "    h.continuerun(float(tstop_ms))\n",
        "\n",
        "    t_np = np.asarray(t, dtype=float)\n",
        "    v_np = np.asarray(v, dtype=float)\n",
        "\n",
        "    vmax = float(np.max(v_np)) if v_np.size else float(\"nan\")\n",
        "    vmin = float(np.min(v_np)) if v_np.size else float(\"nan\")\n",
        "    spiked = bool(np.any(v_np >= float(spike_threshold_mV)))\n",
        "\n",
        "    print(\n",
        "        f\"Vm min/max: {vmin:.3f} / {vmax:.3f} mV \"\n",
        "        f\"(IClamp amp={amp_nA} nA) | spike>= {spike_threshold_mV} mV: {spiked}\"\n",
        "    )\n",
        "    return t_np, v_np\n",
        "\n",
        "\n",
        "def pick_test_section(env):\n",
        "    \"\"\"\n",
        "    Robustly find a reasonable GM soma section to test, across your evolving plant code.\n",
        "    Priority:\n",
        "      1) A recorded GM section (if the plant exposes one)\n",
        "      2) First GM soma in env.plant.gm_secs\n",
        "      3) Any section whose name starts with 'gm_soma_'\n",
        "      4) Fallback: first NEURON section in the model\n",
        "    \"\"\"\n",
        "    p = env.plant\n",
        "\n",
        "    # 1) If you store recorded sections explicitly (optional)\n",
        "    for attr in (\"_record_secs\", \"record_secs\", \"_recorded_secs\"):\n",
        "        if hasattr(p, attr):\n",
        "            secs = getattr(p, attr)\n",
        "            if isinstance(secs, (list, tuple)) and len(secs) > 0:\n",
        "                return secs[0], f\"env.plant.{attr}[0]\"\n",
        "\n",
        "    # 2) Your current plant uses gm_secs (list of Sections)\n",
        "    if hasattr(p, \"gm_secs\") and isinstance(p.gm_secs, (list, tuple)) and len(p.gm_secs) > 0:\n",
        "        return p.gm_secs[0], \"env.plant.gm_secs[0]\"\n",
        "\n",
        "    # 3) Try to find a gm_soma_* section among all sections\n",
        "    all_secs = list(h.allsec())\n",
        "    for sec in all_secs:\n",
        "        try:\n",
        "            if str(sec.name()).startswith(\"gm_soma_\"):\n",
        "                return sec, \"first h.allsec() with name gm_soma_*\"\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # 4) Final fallback: first section in the model\n",
        "    if len(all_secs) == 0:\n",
        "        raise RuntimeError(\"No NEURON sections exist. Build the plant first (call env.reset()).\")\n",
        "    return all_secs[0], \"h.allsec()[0]\"\n",
        "\n",
        "\n",
        "# --------- usage ----------\n",
        "# Ensure the model is built first\n",
        "# obs, info = env.reset()\n",
        "\n",
        "sec0, how = pick_test_section(env)\n",
        "print(f\"Testing section: {sec0.name()} (picked via {how})\")\n",
        "\n",
        "t_ms, v_mV = quick_spike_test(sec0, amp_nA=0.2, spike_threshold_mV=0.0)\n",
        "\n"
      ],
      "metadata": {
        "id": "dxZ_PhY2WZTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs, info = env.reset(seed=0)\n",
        "obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n"
      ],
      "metadata": {
        "id": "myNEFVwCKxik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert np.isfinite(reward)\n"
      ],
      "metadata": {
        "id": "zHhHqcuUK1CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "obs, info = env.reset(seed=0)\n",
        "\n",
        "t0 = time.time()\n",
        "for _ in range(20):\n",
        "    obs, r, terminated, truncated, info = env.step(env.action_space.sample())\n",
        "t1 = time.time()\n",
        "\n",
        "step_time = (t1 - t0) / 20\n",
        "print(f\"env.step() ≈ {step_time*1000:.1f} ms\")\n",
        "\n",
        "print(\"Estimated time for 100k steps:\",\n",
        "      f\"{step_time * 5_000 / 60:.1f} minutes\")\n"
      ],
      "metadata": {
        "id": "-it0oO9XSeh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SAC training cell with:\n",
        "# 1) TensorBoard logging (reward + SAC losses)\n",
        "# 2) Custom logging of burden/spikes/E_rate/sync_E via SB3 logger\n",
        "# 3) monitor.csv episode reward logging (already handled by Monitor/VecMonitor)\n",
        "# 4) Optional: quick post-train evaluation rollout\n",
        "\n",
        "# DO NOT import sac_agent – it's already defined in this notebook\n",
        "\n",
        "from stable_baselines3.common.callbacks import BaseCallback, CheckpointCallback\n",
        "\n",
        "# ---------- Custom callback to log burden + neural features ----------\n",
        "class DBSMetricsCallback(BaseCallback):\n",
        "    def __init__(self, verbose: int = 0):\n",
        "        super().__init__(verbose=verbose)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        infos = self.locals.get(\"infos\", None)\n",
        "        if not infos:\n",
        "            return True\n",
        "\n",
        "        info = infos[0] if isinstance(infos, (list, tuple)) else infos\n",
        "        if not isinstance(info, dict):\n",
        "            return True\n",
        "\n",
        "        # Level-2 metric\n",
        "        if \"burden\" in info and info[\"burden\"] is not None:\n",
        "            self.logger.record(\"custom/burden\", float(info[\"burden\"]))\n",
        "\n",
        "        # Neural features\n",
        "        feats = info.get(\"features\", {}) or {}\n",
        "        for k in [\"n_spikes\", \"rate_hz\", \"E_rate_hz\", \"I_rate_hz\", \"sync_E\", \"burst_E\", \"logEI\"]:\n",
        "            if k in feats and feats[k] is not None:\n",
        "                self.logger.record(f\"custom/{k}\", float(feats[k]))\n",
        "\n",
        "        # Stimulation parameters (optional)\n",
        "        stim = info.get(\"stim\", None)\n",
        "        if isinstance(stim, dict):\n",
        "            for k in [\"amp_mA\", \"freq_Hz\", \"pw_ms\", \"duty_cycle\"]:\n",
        "                if k in stim and stim[k] is not None:\n",
        "                    self.logger.record(f\"custom/stim_{k}\", float(stim[k]))\n",
        "\n",
        "        return True\n",
        "\n",
        "\n",
        "# ---------- Build environment ----------\n",
        "env = build_env(\n",
        "    seed=0,\n",
        "    episode_len=100,\n",
        "    forced_tissue_mode=\"BOUNDARY\",\n",
        "    freeze_case=True   # ⬅️ add this\n",
        ")\n",
        "\n",
        "# ---------- SAC configuration ----------\n",
        "cfg = SACConfig(\n",
        "    total_timesteps=5_000,\n",
        "    learning_rate=3e-4,\n",
        "    buffer_size=200_000,\n",
        "    batch_size=256,\n",
        "    gamma=0.99,\n",
        "    tau=0.005,\n",
        "    learning_starts=250,\n",
        "    train_freq=1,\n",
        "    gradient_steps=1,\n",
        "    seed=0,\n",
        "    log_dir=\"runs/sac_boundary\",\n",
        "    save_every_steps=50_000,\n",
        ")\n",
        "\n",
        "# ---------- Create agent ----------\n",
        "agent = SACAgent(env, cfg)\n",
        "\n",
        "# ---------- Train with callbacks ----------\n",
        "checkpoint_cb = CheckpointCallback(\n",
        "    save_freq=cfg.save_every_steps,\n",
        "    save_path=cfg.log_dir,\n",
        "    name_prefix=\"checkpoint\",\n",
        "    save_replay_buffer=True,\n",
        "    save_vecnormalize=False,\n",
        ")\n",
        "\n",
        "metrics_cb = DBSMetricsCallback()\n",
        "\n",
        "agent.model.learn(\n",
        "    total_timesteps=cfg.total_timesteps,\n",
        "    callback=[checkpoint_cb, metrics_cb],\n",
        ")\n",
        "\n",
        "# ---------- Save final model ----------\n",
        "final_model_path = f\"{cfg.log_dir}/final_model.zip\"\n",
        "agent.model.save(final_model_path)\n",
        "print(\"Saved model to:\", final_model_path)\n",
        "\n",
        "# ---------- Quick evaluation ----------\n",
        "print(\"Eval:\", agent.rollout(n_episodes=3, deterministic=True))\n"
      ],
      "metadata": {
        "id": "wck4r-lb5pGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs, info = env.reset(seed=0)\n",
        "print(\"reset info:\", info)\n",
        "\n",
        "action = env.action_space.sample()\n",
        "obs, r, terminated, truncated, info = env.step(action)\n",
        "\n",
        "print(\"reward:\", r, \"done:\", terminated or truncated)\n",
        "print(\"info keys:\", list(info.keys()))\n",
        "print(\"info['features']:\", info.get(\"features\", None))\n",
        "print(\"burden:\", info.get(\"burden\", None))\n",
        "print(\"burden:\", info[\"l2_state\"][\"burden\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "xHTl4-o6hr24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs\n"
      ],
      "metadata": {
        "id": "hsozfWICNjBa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
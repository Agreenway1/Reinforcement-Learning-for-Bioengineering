{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f776ucHlZvej"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Normal\n",
        "\n",
        "import collections\n",
        "import random\n",
        "import time\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3YmYFy9rBoQ"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cpu\")\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "092Mqjt3rE-f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class EpilepticNeuralMassJR:\n",
        "    \"\"\"\n",
        "    Jansen–Rit-style neural mass model with an explicit DBS input.\n",
        "\n",
        "    Populations:\n",
        "        - P: pyramidal cells\n",
        "        - E: excitatory interneurons\n",
        "        - I: inhibitory interneurons\n",
        "\n",
        "    State vector y = [y1, y2, y3, y4, y5, y6]\n",
        "        y1: P average membrane potential\n",
        "        y2: E average membrane potential\n",
        "        y3: I average membrane potential\n",
        "        y4: d/dt y1\n",
        "        y5: d/dt y2\n",
        "        y6: d/dt y3\n",
        "\n",
        "    Dynamics:\n",
        "        Second-order PSP operators for each population, driven by sigmoidal\n",
        "        firing from the others and external input p(t) + DBS(t).\n",
        "\n",
        "    DBS coupling:\n",
        "        - DBS current enters as an additive term to the pyramidal input\n",
        "          (you can change this if you prefer to target E or I).\n",
        "\n",
        "    All parameters are exposed so you can push the model into\n",
        "    more “epileptogenic” regimes if needed.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        A=3.25,      # mV, excitatory gain\n",
        "        B=22.0,      # mV, inhibitory gain\n",
        "        a=100.0,     # s^-1, excitatory inverse time constant\n",
        "        b=50.0,      # s^-1, inhibitory inverse time constant\n",
        "        C=135.0,     # average connectivity\n",
        "        e0=2.5,      # max firing rate (s^-1)\n",
        "        v0=6.0,      # sigmoidal threshold (mV)\n",
        "        r=0.56,      # sigmoid slope (mV^-1)\n",
        "        p_mean=120.0,  # baseline external input to P (s^-1)\n",
        "        p_std=30.0,    # noise on external input\n",
        "        epileptogenic_boost=1.3,  # scale on excitatory connectivity\n",
        "        rng=None,\n",
        "    ):\n",
        "        # --- store base connectivity so we can re-apply boost later (plasticity) ---\n",
        "        self._C_base = float(C)\n",
        "\n",
        "        # Default endpoint values for disease mapping (tune if you want)\n",
        "        self.p_mean_normal = 90.0\n",
        "        self.p_mean_ictal  = 130.0\n",
        "        self.boost_normal  = 1.0\n",
        "        self.boost_ictal   = 1.3\n",
        "\n",
        "        # initialise current parameters\n",
        "        self.p_mean = float(p_mean)\n",
        "        self.p_std  = float(p_std)\n",
        "\n",
        "        # set connectivity using the initial boost\n",
        "        self._set_connectivity(float(epileptogenic_boost))\n",
        "\n",
        "\n",
        "        self.A = A\n",
        "        self.B = B\n",
        "        self.a = a\n",
        "        self.b = b\n",
        "\n",
        "        self.e0 = e0\n",
        "        self.v0 = v0\n",
        "        self.r = r\n",
        "\n",
        "        self.p_mean = p_mean\n",
        "        self.p_std = p_std\n",
        "\n",
        "        self.rng = np.random.default_rng() if rng is None else rng\n",
        "\n",
        "                # --- Slow disease / excitability state --------------------------------\n",
        "        # disease_level in [0,1]: 0 = normal, 1 = strongly epileptic\n",
        "        self.disease_level = 0.0\n",
        "\n",
        "        # how fast the system tends to get worse (per RL step) if untreated\n",
        "        self.disease_drift = 0.01     # tune: 0.005–0.02\n",
        "\n",
        "        # how strongly seizure suppression pushes back toward normal\n",
        "        self.disease_control_gain = 0.1  # tune: 0.05–0.2\n",
        "\n",
        "        # JR parameter values for the two extremes.\n",
        "        # Replace \"p_drive\" with whatever your JR uses (e.g. p, I_ext, etc.).\n",
        "        self.jr_params_normal = {\"p_drive\": 90.0}\n",
        "        self.jr_params_ictal  = {\"p_drive\": 130.0}\n",
        "\n",
        "\n",
        "    def _set_connectivity(self, boost: float) -> None:\n",
        "        \"\"\"Reset connectivity constants from base C and a boost factor (no accumulation).\"\"\"\n",
        "        C = self._C_base\n",
        "        boost = float(boost)\n",
        "\n",
        "        self.C1 = C * boost\n",
        "        self.C2 = 0.8 * C * boost\n",
        "        self.C3 = 0.25 * C\n",
        "        self.C4 = 0.25 * C\n",
        "\n",
        "    def set_disease_level(self, d: float) -> None:\n",
        "        \"\"\"\n",
        "        d in [0,1]. 0 = healthy, 1 = epileptogenic.\n",
        "        Maps disease to background drive + excitatory connectivity boost.\n",
        "        \"\"\"\n",
        "        d = float(np.clip(d, 0.0, 1.0))\n",
        "\n",
        "        self.p_mean = (1.0 - d) * self.p_mean_normal + d * self.p_mean_ictal\n",
        "        boost = (1.0 - d) * self.boost_normal + d * self.boost_ictal\n",
        "        self._set_connectivity(boost)\n",
        "\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "    def _normalize_seizure_raw_safe(self, raw: float) -> float:\n",
        "        # allow reset/calibration to run before baseline/scale are set\n",
        "        if getattr(self, \"seizure_baseline\", None) is None or getattr(self, \"seizure_scale\", None) is None:\n",
        "            return 0.0\n",
        "\n",
        "        base = float(self.seizure_baseline)\n",
        "        s = max(float(self.seizure_scale), 1e-3)\n",
        "\n",
        "        z = (float(raw) - base) / s\n",
        "        z = max(0.0, z)\n",
        "        idx = z / (1.0 + z)\n",
        "        return float(np.clip(idx, 0.0, 1.0))\n",
        "\n",
        "\n",
        "    def S(self, v):\n",
        "        \"\"\"\n",
        "        Sigmoidal firing-rate function.\n",
        "        \"\"\"\n",
        "        return 2.0 * self.e0 / (1.0 + np.exp(self.r * (self.v0 - v)))\n",
        "\n",
        "    def _deriv(self, y, t, dbs_val):\n",
        "        \"\"\"\n",
        "        Compute time derivative dy/dt for state y at time t given DBS amplitude.\n",
        "        \"\"\"\n",
        "        y1, y2, y3, y4, y5, y6 = y\n",
        "\n",
        "        # External input p(t): noisy drive + can be modulated if needed\n",
        "        p_t = self.p_mean + self.p_std * self.rng.standard_normal()\n",
        "\n",
        "        # Firing rates\n",
        "        S_p = self.S(y2 - y3)          # pyramidal output driven by E and I\n",
        "        S_e = self.S(self.C1 * y1)     # excitatory input from pyramidal\n",
        "        S_i = self.S(self.C3 * y1)     # inhibitory input from pyramidal\n",
        "\n",
        "        # Add DBS as extra input to pyramidal (can interpret as current)\n",
        "        # DBS is added to the excitatory input term here:\n",
        "        # you can scale it or change how it couples.\n",
        "        I_dbs = dbs_val\n",
        "\n",
        "        # Differential equations (Jansen–Rit)\n",
        "        dy1_dt = y4\n",
        "        dy4_dt = self.A * self.a * (S_e + p_t + I_dbs) - 2.0 * self.a * y4 - (self.a ** 2) * y1\n",
        "\n",
        "        dy2_dt = y5\n",
        "        dy5_dt = self.A * self.a * (self.C2 * S_p) - 2.0 * self.a * y5 - (self.a ** 2) * y2\n",
        "\n",
        "        dy3_dt = y6\n",
        "        dy6_dt = self.B * self.b * (self.C4 * S_i) - 2.0 * self.b * y6 - (self.b ** 2) * y3\n",
        "\n",
        "        return np.array([dy1_dt, dy2_dt, dy3_dt, dy4_dt, dy5_dt, dy6_dt])\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "    # Map disease_level ∈ [0,1] into JR parameters\n",
        "    # ------------------------------------------------------------------\n",
        "    def _apply_jr_params_from_disease(self):\n",
        "        \"\"\"\n",
        "        Map self.disease_level in [0,1] to a JR background drive between\n",
        "        'normal' and 'ictal'.\n",
        "        \"\"\"\n",
        "        p_norm = self.jr_regimes[\"normal\"][\"p_drive\"]\n",
        "        p_ict  = self.jr_regimes[\"ictal\"][\"p_drive\"]\n",
        "\n",
        "        # linear interpolation: 0 -> normal, 1 -> ictal\n",
        "        p_current = (1.0 - self.disease_level) * p_norm + self.disease_level * p_ict\n",
        "\n",
        "        # write this into the actual JR model parameter:\n",
        "        self.jr.p_drive = p_current      # <<< or whatever param name you use\n",
        "\n",
        "\n",
        "\n",
        "    def simulate(\n",
        "        self,\n",
        "        T=10.0,\n",
        "        dt=0.0005,\n",
        "        dbs_fun=None,\n",
        "        y0=None,\n",
        "        record_downsample=10,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Simulate the neural mass for duration T with step dt.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        T : float\n",
        "            Total duration in seconds.\n",
        "        dt : float\n",
        "            Integration timestep in seconds.\n",
        "        dbs_fun : callable or None\n",
        "            Function u = dbs_fun(t) giving DBS drive at time t (in arbitrary units).\n",
        "            If None, DBS = 0 at all times.\n",
        "        y0 : array-like or None\n",
        "            Initial state. If None, start at zeros.\n",
        "        record_downsample : int\n",
        "            Store every Nth sample to reduce output size.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        t_rec : (N_rec,) array\n",
        "            Recorded time points.\n",
        "        y_rec : (N_rec, 6) array\n",
        "            State time series.\n",
        "        v_out : (N_rec,) array\n",
        "            “EEG-like” output: pyramidal potential y1.\n",
        "        \"\"\"\n",
        "        n_steps = int(T / dt)\n",
        "        if y0 is None:\n",
        "            y = np.zeros(6, dtype=float)\n",
        "        else:\n",
        "            y = np.array(y0, dtype=float)\n",
        "\n",
        "        if dbs_fun is None:\n",
        "            def dbs_fun(t):\n",
        "                return 0.0\n",
        "\n",
        "        # Preallocate output lists\n",
        "        t_list = []\n",
        "        y_list = []\n",
        "        v_list = []\n",
        "\n",
        "        for k in range(n_steps):\n",
        "            t = k * dt\n",
        "            u = float(dbs_fun(t))\n",
        "\n",
        "            # simple Euler–Maruyama integration\n",
        "            dy = self._deriv(y, t, u)\n",
        "            y = y + dt * dy\n",
        "\n",
        "            if k % record_downsample == 0:\n",
        "                t_list.append(t)\n",
        "                y_list.append(y.copy())\n",
        "                v_list.append(y[0])  # pyramidal potential\n",
        "\n",
        "        t_rec = np.asarray(t_list)\n",
        "        y_rec = np.vstack(y_list)\n",
        "        v_out = np.asarray(v_list)\n",
        "\n",
        "        return t_rec, y_rec, v_out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EpilepsyDBSCombinedEnv(gym.Env):\n",
        "    def __init__(\n",
        "        self,\n",
        "        jr_model=None,\n",
        "        pac_model=None,\n",
        "        step_T=0.1,\n",
        "        dt=0.001,\n",
        "        max_steps=100,\n",
        "        amp_min=0.0,\n",
        "        amp_max=5.0,\n",
        "        freq_min=10.0,\n",
        "        freq_max=200.0,\n",
        "        pw_min=60.0,\n",
        "        pw_max=450.0,\n",
        "        amp_delta_max=0.25,\n",
        "        freq_delta_max=5.0,\n",
        "        pw_delta_max=10.0,\n",
        "        w_seizure=3.0,\n",
        "        w_energy=0.2,\n",
        "        w_slew=0.005,\n",
        "        w_disease = 0.0, # just initially, change later\n",
        "        log_best_episodes=False,\n",
        "        n_best_episodes=10,\n",
        "        rng=None,\n",
        "        default_regime=\"normal\",   # <--- NEW: which regime to use by default\n",
        "        # --- seizure metric config (NEW) ---\n",
        "        seizure_metric=\"bandpower_ratio\",   # or \"line_length\"\n",
        "        seizure_band=(8.0, 30.0),           # adjust to your JR seizure oscillation\n",
        "        total_band=(1.0, 80.0),             # total band for normalization\n",
        "        seizure_norm=\"tanh\",                # \"tanh\" or \"logistic\"\n",
        "        seizure_scale=0.15,                 # will be auto-calibrated if you run calibrate()\n",
        "        seizure_target=0.2,                # optional: for shaping / logging\n",
        "\n",
        "\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.prev_seizure_index = None\n",
        "        self.w_delta_seizure = 0.5\n",
        "\n",
        "        self.seiz_mu = 0.0\n",
        "        self.seiz_var = 1.0\n",
        "        self.seiz_n = 0\n",
        "        self.seiz_eps = 1e-6\n",
        "        self.seiz_sigmoid_k = 2.0   # slope; 1–3 is typical\n",
        "        self.seiz_update_stats = True  # during training; maybe False in eval\n",
        "\n",
        "        # ---- Option B: latent burden dynamics ----\n",
        "        self.use_burden_state = True\n",
        "\n",
        "        # burden thresholds for regime labels\n",
        "        self.burden_thr_normal = 0.20\n",
        "        self.burden_thr_ictal  = 0.50\n",
        "\n",
        "        # burden dynamics parameters (tune later)\n",
        "        self.burden_drift_normal   = 0.002   # per step\n",
        "        self.burden_drift_preictal = 0.006\n",
        "        self.burden_drift_ictal    = 0.012\n",
        "\n",
        "        self.burden_relief_gain = 0.020      # how strongly DBS reduces burden\n",
        "        self.burden_noise_std   = 0.010      # stochasticity per step\n",
        "\n",
        "        self.disease_up_rate = 0.010    # increase when burden high\n",
        "        self.disease_down_rate = 0.002  # recovery when burden low\n",
        "        self.disease_floor = 0.0\n",
        "\n",
        "\n",
        "        # map stimulation params to \"effective control\"\n",
        "        self.stim_k_amp  = 1.0\n",
        "        self.stim_k_freq = 1.0\n",
        "        self.stim_k_pw   = 1.0\n",
        "\n",
        "        # optional: prevent unrealistic \"infinite DBS = instant cure\"\n",
        "        self.burden_relief_cap = 0.05        # max reduction per step\n",
        "\n",
        "        # store parameters\n",
        "        self.w_seizure = float(w_seizure)\n",
        "        self.w_energy = float(w_energy)\n",
        "        self.w_slew = float(w_slew)\n",
        "        self.w_disease = float(w_disease)   # <--- NEW\n",
        "\n",
        "        self.seizure_metric = seizure_metric\n",
        "        self.seizure_band = seizure_band\n",
        "        self.total_band = total_band\n",
        "        self.seizure_norm = seizure_norm\n",
        "        self.seizure_scale = float(seizure_scale)\n",
        "        self.seizure_target = float(seizure_target)\n",
        "\n",
        "        self.dt = float(dt)\n",
        "        self.step_T = float(step_T)\n",
        "        self.fs = 1.0 / self.dt\n",
        "\n",
        "        # ---- coupling of burden to physiology metric ----\n",
        "        self.burden_phys_gain = 0.030   # tune later\n",
        "        self.burden_phys_tau = 10.0\n",
        "        self._phys_ema = 0.0\n",
        "\n",
        "        self.phys_raw_lo = 0.70\n",
        "        self.phys_raw_hi = 1.10\n",
        "\n",
        "        self.w_seiz = 1.0\n",
        "        self.w_energy = 0.0\n",
        "        self.w_slew = 0.0\n",
        "        # optional: reward scaling\n",
        "        self.reward_scale = 1.0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # --- Seizure baseline (normal activity) -----------------------\n",
        "        self.seizure_baseline = None  # calibrated in reset()\n",
        "        self.baseline_margin = 0.02\n",
        "\n",
        "        self.jr = jr_model if jr_model is not None else EpilepticNeuralMassJR()\n",
        "\n",
        "                # --- disease / regime handling --------------------------------\n",
        "        # \"normal\", \"preictal\", \"ictal\"\n",
        "        self.default_regime = default_regime\n",
        "        self.disease_level = 0.0   # 0 = normal, 0.5 = preictal, 1 = ictal\n",
        "        # ---------------------------------------------------------------\n",
        "\n",
        "\n",
        "        self.step_T = float(step_T)\n",
        "        self.dt = float(dt)\n",
        "        self.steps_per_step = int(self.step_T / self.dt)\n",
        "        self.max_steps = int(max_steps)\n",
        "\n",
        "        # DBS ranges\n",
        "        self.amp_min = float(amp_min)\n",
        "        self.amp_max = float(amp_max)\n",
        "        self.freq_min = float(freq_min)\n",
        "        self.freq_max = float(freq_max)\n",
        "        self.pw_min = float(pw_min)\n",
        "        self.pw_max = float(pw_max)\n",
        "\n",
        "        self.amp_delta_max = float(amp_delta_max)\n",
        "        self.freq_delta_max = float(freq_delta_max)\n",
        "        self.pw_delta_max = float(pw_delta_max)\n",
        "\n",
        "        # logging\n",
        "        self.log_best_episodes = bool(log_best_episodes)\n",
        "        self.n_best_episodes = int(n_best_episodes)\n",
        "        self.best_episodes = []\n",
        "        self.current_episode_log = None\n",
        "        self.episode_reward = 0.0\n",
        "\n",
        "        self.rng = np.random.default_rng() if rng is None else rng\n",
        "\n",
        "        # internal state\n",
        "        self.t = 0.0\n",
        "        self.jr_state = None\n",
        "        self.pac_state = None\n",
        "        self.current_params = None\n",
        "        self.prev_params = None\n",
        "        self.step_count = 0\n",
        "\n",
        "                # -------------------------------\n",
        "        # Disease state & progression\n",
        "        # -------------------------------\n",
        "        self.default_regime = default_regime  # \"normal\", \"preictal\", or \"ictal\"\n",
        "        self.disease_level = 0.0             # scalar in [0, 1]\n",
        "\n",
        "        # how fast it drifts toward epilepsy if you do nothing (per step)\n",
        "        self.disease_drift = 0.01          # tune as you like\n",
        "\n",
        "        # how strongly seizure reduction pushes disease_level back down\n",
        "        self.disease_gain = 0.05              # weight for delta_seiz effect\n",
        "\n",
        "        # hard bounds\n",
        "        self.disease_min = 0.0\n",
        "        self.disease_max = 1.0\n",
        "\n",
        "\n",
        "        # reference scales\n",
        "        self._seizure_scale = 0.25\n",
        "        self._energy_ref = (self.amp_max ** 2) * self.freq_max * (self.pw_max / self.pw_max)\n",
        "\n",
        "        # --- NEW: JR regimes ---\n",
        "        # Replace 'p_drive' with the actual attribute / parameter name in your JR model.\n",
        "        self.jr_regimes = {\n",
        "            \"normal\":   {\"p_drive\": 80.0},   # low background input\n",
        "            \"preictal\": {\"p_drive\": 100.0},  # near bifurcation\n",
        "            \"ictal\":    {\"p_drive\": 130.0},  # clearly epileptic\n",
        "        }\n",
        "        if default_regime not in self.jr_regimes:\n",
        "            raise ValueError(f\"Unknown default_regime '{default_regime}'\")\n",
        "        self.current_regime = default_regime\n",
        "        # ------------------------\n",
        "\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.zeros(5, dtype=np.float32),\n",
        "            high=np.ones(5, dtype=np.float32),\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "\n",
        "        self.action_space = spaces.Box(\n",
        "            low=-1.0,\n",
        "            high=1.0,\n",
        "            shape=(3,),\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "    # Disease state / regime helpers\n",
        "    # ------------------------------------------------------------------\n",
        "    def _set_disease_from_regime(self, regime: str):\n",
        "        \"\"\"\n",
        "        Map a discrete regime label to a scalar disease_level in [0,1].\n",
        "\n",
        "        Currently:\n",
        "          normal   -> 0.0\n",
        "          preictal -> 0.5\n",
        "          ictal    -> 1.0\n",
        "        \"\"\"\n",
        "        if regime not in (\"normal\", \"preictal\", \"ictal\"):\n",
        "            raise ValueError(f\"Unknown regime '{regime}'. Use 'normal', 'preictal', or 'ictal'.\")\n",
        "\n",
        "        if regime == \"normal\":\n",
        "            self.disease_level = 0.0\n",
        "        elif regime == \"preictal\":\n",
        "            self.disease_level = 0.5\n",
        "        elif regime == \"ictal\":\n",
        "            self.disease_level = 1.0\n",
        "\n",
        "        self._apply_jr_params_from_disease()\n",
        "\n",
        "\n",
        "    def _update_seizure_stats(self, x: float):\n",
        "        self.seiz_n += 1\n",
        "        if self.seiz_n == 1:\n",
        "            self.seiz_mu = x\n",
        "            self.seiz_var = 1.0\n",
        "            return\n",
        "        delta = x - self.seiz_mu\n",
        "        self.seiz_mu += delta / self.seiz_n\n",
        "        delta2 = x - self.seiz_mu\n",
        "        # population variance estimate (good enough here)\n",
        "        self.seiz_var = ((self.seiz_n - 1) * self.seiz_var + delta * delta2) / self.seiz_n\n",
        "\n",
        "\n",
        "    def _seizure_severity_from_raw(self, raw: float) -> float:\n",
        "        if self.seiz_update_stats:\n",
        "            self._update_seizure_stats(raw)\n",
        "\n",
        "        sigma = float(np.sqrt(max(self.seiz_var, self.seiz_eps)))\n",
        "        z = (raw - float(self.seiz_mu)) / sigma\n",
        "\n",
        "        # sigmoid; stable\n",
        "        sev = 1.0 / (1.0 + np.exp(-self.seiz_sigmoid_k * z))\n",
        "        return float(np.clip(sev, 0.0, 1.0))\n",
        "\n",
        "\n",
        "\n",
        "    def _apply_jr_params_from_disease(self):\n",
        "        \"\"\"\n",
        "        Push disease_level into JR parameters (excitability / connectivity).\n",
        "        Requires EpilepticNeuralMassJR.set_disease_level().\n",
        "        \"\"\"\n",
        "        if self.jr is None:\n",
        "            return\n",
        "        if hasattr(self.jr, \"set_disease_level\"):\n",
        "            self.jr.set_disease_level(self.disease_level)\n",
        "            return\n",
        "\n",
        "\n",
        "    def _bandpower(self, freqs, psd, f_lo, f_hi):\n",
        "        idx = (freqs >= f_lo) & (freqs <= f_hi)\n",
        "        if not np.any(idx):\n",
        "            return 0.0\n",
        "        return float(np.trapz(psd[idx], freqs[idx]))\n",
        "\n",
        "    def _seizure_metric_bandpower_ratio(self, x: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Returns a scalar >= 0, where higher means more oscillatory power in seizure band.\n",
        "        \"\"\"\n",
        "        x = np.asarray(x, dtype=np.float64)\n",
        "        if x.size < 8:\n",
        "            return 0.0\n",
        "\n",
        "        # Demean + window to reduce leakage\n",
        "        x = x - np.mean(x)\n",
        "        n = x.size\n",
        "        w = np.hanning(n)\n",
        "        xw = x * w\n",
        "\n",
        "        # One-sided PSD estimate (periodogram)\n",
        "        X = np.fft.rfft(xw)\n",
        "        freqs = np.fft.rfftfreq(n, d=self.dt)\n",
        "\n",
        "        # Scale: not critical since we use a ratio; still keep it consistent\n",
        "        psd = (np.abs(X) ** 2) / (np.sum(w ** 2) * self.fs + 1e-12)\n",
        "\n",
        "        p_band = self._bandpower(freqs, psd, self.seizure_band[0], self.seizure_band[1])\n",
        "        p_total = self._bandpower(freqs, psd, self.total_band[0], self.total_band[1])\n",
        "\n",
        "        ratio = p_band / (p_total + 1e-12)  # 0..1-ish\n",
        "        return float(ratio)\n",
        "\n",
        "    def _seizure_metric_line_length(self, x: np.ndarray) -> float:\n",
        "        x = np.asarray(x, dtype=np.float64)\n",
        "        if x.size < 2:\n",
        "            return 0.0\n",
        "        dx = np.diff(x)\n",
        "        ll = np.sum(np.abs(dx)) / (x.size * self.dt + 1e-12)\n",
        "        return float(ll)\n",
        "\n",
        "    def _normalize_seizure_raw(self, raw: float) -> float:\n",
        "        if self.seizure_baseline is None or self.seizure_scale is None:\n",
        "            return 0.0\n",
        "\n",
        "        base = float(self.seizure_baseline)\n",
        "        s = max(float(self.seizure_scale), 1e-3)\n",
        "\n",
        "        z = (float(raw) - base) / s\n",
        "        z = max(0.0, z)\n",
        "        idx = z / (1.0 + z)\n",
        "        return float(np.clip(idx, 0.0, 1.0))\n",
        "\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Parameter handling\n",
        "    # ------------------------------------------------------------------\n",
        "    def _clip_params(self, amp, freq, pw):\n",
        "        amp_clipped = np.clip(amp, self.amp_min, self.amp_max)\n",
        "        freq_clipped = np.clip(freq, self.freq_min, self.freq_max)\n",
        "        pw_clipped = np.clip(pw, self.pw_min, self.pw_max)\n",
        "        return amp_clipped, freq_clipped, pw_clipped\n",
        "\n",
        "    def _update_params_from_action(self, action):\n",
        "        \"\"\"\n",
        "        Continuous action mapping for SAC.\n",
        "\n",
        "        action: np.array shape (3,), each component in [-1, 1]\n",
        "          action[0] controls amplitude change (mA)\n",
        "          action[1] controls frequency change (Hz)\n",
        "          action[2] controls pulse-width change (µs)\n",
        "\n",
        "        Per-step deltas are continuous:\n",
        "          d_amp  = action[0] * amp_delta_max\n",
        "          d_freq = action[1] * freq_delta_max\n",
        "          d_pw   = action[2] * pw_delta_max\n",
        "        \"\"\"\n",
        "        if self.current_params is None:\n",
        "            raise RuntimeError(\"Environment not reset. Call reset() first.\")\n",
        "\n",
        "        a = np.asarray(action, dtype=float).flatten()\n",
        "        if a.shape[0] != 3:\n",
        "            raise ValueError(\"Action must have shape (3,)\")\n",
        "\n",
        "        # current params\n",
        "        amp, freq, pw = self.current_params\n",
        "\n",
        "        # continuous deltas\n",
        "        d_amp  = float(a[0]) * float(self.amp_delta_max)\n",
        "        d_freq = float(a[1]) * float(self.freq_delta_max)\n",
        "        d_pw   = float(a[2]) * float(self.pw_delta_max)\n",
        "\n",
        "        # update\n",
        "        new_amp  = amp  + d_amp\n",
        "        new_freq = freq + d_freq\n",
        "        new_pw   = pw   + d_pw\n",
        "\n",
        "        # clip to device limits\n",
        "        new_amp, new_freq, new_pw = self._clip_params(new_amp, new_freq, new_pw)\n",
        "\n",
        "        return new_amp, new_freq, new_pw, d_amp, d_freq, d_pw\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # DBS waveform\n",
        "    # ------------------------------------------------------------------\n",
        "    def _make_dbs_fun(self, amp, freq, pw_us, duty=1.0, duty_period_s=1.0):\n",
        "        pw_s = float(pw_us) * 1e-6\n",
        "        f = float(freq)\n",
        "        amp = float(amp)\n",
        "\n",
        "        if amp == 0.0 or f <= 0.0 or pw_s <= 0.0:\n",
        "            return lambda t: 0.0\n",
        "\n",
        "        T = 1.0 / f\n",
        "\n",
        "        duty = float(np.clip(duty, 0.0, 1.0))\n",
        "        on_s = duty * float(duty_period_s)\n",
        "\n",
        "        def u(t):\n",
        "            t = float(t)\n",
        "            # duty gate\n",
        "            if duty < 1.0:\n",
        "                if (t % duty_period_s) > on_s:\n",
        "                    return 0.0\n",
        "            # pulse train\n",
        "            return amp if (t % T) <= pw_s else 0.0\n",
        "\n",
        "        return u\n",
        "\n",
        "\n",
        "    def _simulate_window(self, amp, freq, pw):\n",
        "        \"\"\"\n",
        "        Simulate one RL decision window.\n",
        "\n",
        "        Uses an effective (time-averaged) DBS drive so that pw_us < dt does not cause\n",
        "        pulses to be numerically missed. PAC is disabled (not computed).\n",
        "        \"\"\"\n",
        "        # ---- Effective DBS drive (average of pulse train) ----\n",
        "        # pw is in microseconds\n",
        "        amp = float(amp)\n",
        "        freq = float(freq)\n",
        "        pw_us = float(pw)\n",
        "\n",
        "        pw_s = pw_us * 1e-6\n",
        "        # Average of rectangular pulse train: amp * (pw/T) = amp * pw_s * freq\n",
        "        u_avg = amp * pw_s * freq\n",
        "        u_avg *= 50.0\n",
        "\n",
        "\n",
        "        # logging lists (PAC removed)\n",
        "        t_list, v_list, u_list = [], [], []      # downsampled, for logging/plots\n",
        "        v_metric = []                             # full-rate, for seizure metric\n",
        "\n",
        "        if self.jr_state is None:\n",
        "            self.jr_state = np.zeros(6, dtype=float)\n",
        "\n",
        "        MAX_STATE = 50.0      # hard clamp for all states\n",
        "        MAX_INPUT = 10.0      # clamp on DBS drive\n",
        "\n",
        "        for k in range(self.steps_per_step):\n",
        "            t = self.t + k * self.dt\n",
        "\n",
        "            # DBS drive (effective)\n",
        "            u_t = float(np.clip(u_avg, -MAX_INPUT, MAX_INPUT))\n",
        "\n",
        "            # JR update\n",
        "            dy = self.jr._deriv(self.jr_state, t, u_t)\n",
        "            self.jr_state = self.jr_state + self.dt * dy\n",
        "            self.jr_state = np.clip(self.jr_state, -MAX_STATE, MAX_STATE)\n",
        "\n",
        "            v = float(self.jr_state[0])\n",
        "            v_metric.append(v)\n",
        "\n",
        "\n",
        "            # downsample logging\n",
        "            if k % 10 == 0:\n",
        "                t_list.append(t)\n",
        "                v_list.append(v)\n",
        "                u_list.append(u_t)\n",
        "\n",
        "        self.t += self.step_T\n",
        "\n",
        "        t_window = np.asarray(t_list)\n",
        "        v_window = np.asarray(v_list)\n",
        "        u_window = np.asarray(u_list)\n",
        "        v_metric = np.asarray(v_metric, dtype=np.float64)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # ------------------------------\n",
        "        # Seizure metric (RAW + normalized index) computed on FULL-RATE signal\n",
        "        # ------------------------------\n",
        "        if not np.all(np.isfinite(v_metric)):\n",
        "            seizure_index = 1.0\n",
        "            energy_norm = 1.0\n",
        "            self._last_seizure_metric_raw = float(\"nan\")\n",
        "            return (\n",
        "                float(seiz_raw),          # <-- RAW FIRST\n",
        "                float(energy_norm),\n",
        "                t_window,\n",
        "                v_window,\n",
        "                u_window,\n",
        "            )\n",
        "\n",
        "\n",
        "        if self.seizure_metric == \"bandpower_ratio\":\n",
        "            seiz_raw = self._seizure_metric_bandpower_ratio(v_metric)\n",
        "        elif self.seizure_metric == \"line_length\":\n",
        "            seiz_raw = self._seizure_metric_line_length(v_metric)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown seizure_metric: {self.seizure_metric}\")\n",
        "\n",
        "        # keep raw metric for logging\n",
        "        self._last_seizure_metric_raw = float(seiz_raw)\n",
        "\n",
        "\n",
        "        # store for info/debug/calibration\n",
        "        self._last_seizure_metric_raw = float(seiz_raw)\n",
        "\n",
        "\n",
        "        # stimulation \"energy\" proxy (keep your original, but ensure types)\n",
        "        energy = (amp ** 2) * freq * (pw_us / max(self.pw_max, 1e-6))\n",
        "        energy_norm = float(np.clip(energy / max(self._energy_ref, 1e-6), 0.0, 1.0))\n",
        "\n",
        "        return (float(seiz_raw), float(energy_norm), t_window, v_window, u_window)\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Episode logging helpers\n",
        "    # ------------------------------------------------------------------\n",
        "    def _start_new_episode_log(self):\n",
        "        if not self.log_best_episodes:\n",
        "            self.current_episode_log = None\n",
        "            self.episode_reward = 0.0\n",
        "            return\n",
        "\n",
        "        self.current_episode_log = {\n",
        "            \"t\": [],\n",
        "            \"v\": [],\n",
        "            \"u\": [],\n",
        "            \"theta\": [],\n",
        "            \"amp_fast\": [],\n",
        "            \"seizure_index\": [],\n",
        "            \"pac_index\": [],\n",
        "            \"energy_norm\": [],\n",
        "            \"amp\": [],\n",
        "            \"freq\": [],\n",
        "            \"pw\": [],\n",
        "            \"rewards\": [],\n",
        "            \"total_reward\": 0.0,\n",
        "        }\n",
        "        self.episode_reward = 0.0\n",
        "\n",
        "    def _append_window_to_log(\n",
        "        self,\n",
        "        t_window,\n",
        "        v_window,\n",
        "        u_window,\n",
        "        theta_window,\n",
        "        amp_fast_window,\n",
        "        seizure_index,\n",
        "        pac_index,\n",
        "        energy_norm,\n",
        "        amp,\n",
        "        freq,\n",
        "        pw,\n",
        "        reward,\n",
        "    ):\n",
        "        if self.current_episode_log is None:\n",
        "            return\n",
        "\n",
        "        log = self.current_episode_log\n",
        "        log[\"t\"].append(t_window)\n",
        "        log[\"v\"].append(v_window)\n",
        "        log[\"u\"].append(u_window)\n",
        "        log[\"theta\"].append(theta_window)\n",
        "        log[\"amp_fast\"].append(amp_fast_window)\n",
        "\n",
        "        log[\"seizure_index\"].append(float(seizure_index))\n",
        "        log[\"pac_index\"].append(float(pac_index))\n",
        "        log[\"energy_norm\"].append(float(energy_norm))\n",
        "\n",
        "        log[\"amp\"].append(float(amp))\n",
        "        log[\"freq\"].append(float(freq))\n",
        "        log[\"pw\"].append(float(pw))\n",
        "\n",
        "        log[\"rewards\"].append(float(reward))\n",
        "\n",
        "    def _finalise_episode_log(self):\n",
        "        if self.current_episode_log is None or not self.log_best_episodes:\n",
        "            return\n",
        "\n",
        "        log = self.current_episode_log\n",
        "\n",
        "        # concatenate per-window time series\n",
        "        for key in [\"t\", \"v\", \"u\", \"theta\", \"amp_fast\"]:\n",
        "            if len(log[key]) > 0:\n",
        "                log[key] = np.concatenate(log[key])\n",
        "            else:\n",
        "                log[key] = np.array([], dtype=float)\n",
        "\n",
        "        # convert per-step scalars to arrays\n",
        "        for key in [\"seizure_index\", \"pac_index\", \"energy_norm\",\n",
        "                    \"amp\", \"freq\", \"pw\", \"rewards\"]:\n",
        "            log[key] = np.asarray(log[key], dtype=float)\n",
        "\n",
        "        log[\"total_reward\"] = float(self.episode_reward)\n",
        "\n",
        "        # insert into best episode list\n",
        "        self.best_episodes.append(log)\n",
        "        self.best_episodes.sort(key=lambda d: d[\"total_reward\"], reverse=True)\n",
        "        self.best_episodes = self.best_episodes[: self.n_best_episodes]\n",
        "\n",
        "        # clear current log\n",
        "        self.current_episode_log = None\n",
        "        self.episode_reward = 0.0\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Gymnasium API: reset / step\n",
        "    # ------------------------------------------------------------------\n",
        "    def _build_obs(self, seizure_index, params):\n",
        "        amp, freq, pw = params\n",
        "        amp_norm = (amp - self.amp_min) / (self.amp_max - self.amp_min)\n",
        "        freq_norm = (freq - self.freq_min) / (self.freq_max - self.freq_min)\n",
        "        pw_norm = (pw - self.pw_min) / (self.pw_max - self.pw_min)\n",
        "        return np.array(\n",
        "            [\n",
        "                seizure_index,\n",
        "                amp_norm,\n",
        "                freq_norm,\n",
        "                pw_norm,\n",
        "                float(self.disease_level),  # NEW: make it explicit & normalised\n",
        "            ],\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "\n",
        "    def _regime_from_burden(self, burden: float) -> str:\n",
        "        if burden < self.burden_thr_normal:\n",
        "            return \"normal\"\n",
        "        elif burden < self.burden_thr_ictal:\n",
        "            return \"preictal\"\n",
        "        else:\n",
        "            return \"ictal\"\n",
        "\n",
        "    def _stim_effect(self, amp: float, freq: float, pw: float) -> float:\n",
        "        \"\"\"\n",
        "        Map DBS params to a scalar control signal in [0,1] via a saturating nonlinearity.\n",
        "        \"\"\"\n",
        "        # Scale each param into ~[0,1] using action bounds you already have\n",
        "        amp_n  = (amp  - self.amp_min)  / max(self.amp_max  - self.amp_min, 1e-6)\n",
        "        freq_n = (freq - self.freq_min) / max(self.freq_max - self.freq_min, 1e-6)\n",
        "        pw_n   = (pw   - self.pw_min)   / max(self.pw_max   - self.pw_min, 1e-6)\n",
        "\n",
        "        amp_n  = float(np.clip(amp_n,  0.0, 1.0))\n",
        "        freq_n = float(np.clip(freq_n, 0.0, 1.0))\n",
        "        pw_n   = float(np.clip(pw_n,   0.0, 1.0))\n",
        "\n",
        "        # Weighted sum then sigmoid saturation\n",
        "        x = self.stim_k_amp * amp_n + self.stim_k_freq * freq_n + self.stim_k_pw * pw_n\n",
        "        # squash into (0,1)\n",
        "        eff = 1.0 / (1.0 + np.exp(-(x - 1.0) / 0.5))\n",
        "        return float(np.clip(eff, 0.0, 1.0))\n",
        "\n",
        "\n",
        "    def _update_burden(self, amp: float, freq: float, pw: float) -> dict:\n",
        "        \"\"\"\n",
        "        Update latent burden dynamics and return diagnostics.\n",
        "        \"\"\"\n",
        "        # Determine drift based on current regime (derived from current burden)\n",
        "        reg = self._regime_from_burden(self.burden)\n",
        "        if reg == \"normal\":\n",
        "            drift = self.burden_drift_normal\n",
        "        elif reg == \"preictal\":\n",
        "            drift = self.burden_drift_preictal\n",
        "        else:\n",
        "            drift = self.burden_drift_ictal\n",
        "\n",
        "        eff = self._stim_effect(amp, freq, pw)\n",
        "\n",
        "        # Use last window’s raw metric (set in _simulate_window) to couple physiology -> burden\n",
        "        raw = float(getattr(self, \"_last_seizure_metric_raw\", np.nan))\n",
        "        if np.isfinite(raw):\n",
        "            # map raw to [0,1]\n",
        "            phys = (raw - self.phys_raw_lo) / max(self.phys_raw_hi - self.phys_raw_lo, 1e-6)\n",
        "            phys = float(np.clip(phys, 0.0, 1.0))\n",
        "\n",
        "            # smooth it (EMA)\n",
        "            alpha = 1.0 / max(float(self.burden_phys_tau), 1.0)\n",
        "            self._phys_ema = (1.0 - alpha) * float(getattr(self, \"_phys_ema\", 0.0)) + alpha * phys\n",
        "\n",
        "            # coupling term (push burden upward when phys_ema high, downward when low)\n",
        "            # centered at 0.5 so it can go +/-.\n",
        "            phys_drive = self.burden_phys_gain * (self._phys_ema - 0.5)\n",
        "        else:\n",
        "            phys = float(\"nan\")\n",
        "            phys_drive = 0.0\n",
        "\n",
        "\n",
        "        relief = self.burden_relief_gain * eff\n",
        "        relief = float(min(relief, self.burden_relief_cap))\n",
        "\n",
        "        noise = float(self.np_random.normal(0.0, self.burden_noise_std))\n",
        "\n",
        "        b_next = self.burden + drift + phys_drive - relief + noise\n",
        "        b_next = float(np.clip(b_next, 0.0, 1.0))\n",
        "\n",
        "        diag = {\n",
        "            \"burden_prev\": float(self.burden),\n",
        "            \"burden_next\": float(b_next),\n",
        "            \"burden_drift\": float(drift),\n",
        "            \"burden_relief\": float(relief),\n",
        "            \"stim_eff\": float(eff),\n",
        "            \"burden_noise\": float(noise),\n",
        "            \"regime_prev\": reg,\n",
        "            \"regime_next\": self._regime_from_burden(b_next),\n",
        "            \"phys_raw\": raw,\n",
        "            \"phys_mapped\": phys,\n",
        "            \"phys_ema\": float(getattr(self, \"_phys_ema\", 0.0)),\n",
        "            \"phys_drive\": float(phys_drive),\n",
        "        }\n",
        "\n",
        "        self.burden = b_next\n",
        "        return diag\n",
        "\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        \"\"\"\n",
        "        Reset environment and start a new episode.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs : np.array, shape (5,)\n",
        "        info : dict\n",
        "        \"\"\"\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        self.t = 0.0\n",
        "        self.step_count = 0\n",
        "\n",
        "        # --- choose regime / disease state ----------------------------\n",
        "        if options is not None and \"regime\" in options:\n",
        "            regime = options[\"regime\"]\n",
        "        else:\n",
        "            regime = self.default_regime\n",
        "\n",
        "        self._set_disease_from_regime(regime)\n",
        "        # ---------------------------------------------------------------\n",
        "\n",
        "        # choose initial burden consistent with regime\n",
        "        if regime == \"normal\":\n",
        "            self.burden = float(np.clip(self.np_random.normal(0.12, 0.04), 0.0, 1.0))\n",
        "        elif regime == \"preictal\":\n",
        "            self.burden = float(np.clip(self.np_random.normal(0.33, 0.06), 0.0, 1.0))\n",
        "        else:  # ictal\n",
        "            self.burden = float(np.clip(self.np_random.normal(0.70, 0.08), 0.0, 1.0))\n",
        "\n",
        "\n",
        "        # reset underlying models\n",
        "        self.jr_state = np.zeros(6, dtype=float)\n",
        "        self.pac_state = np.array(\n",
        "            [0.0,\n",
        "            0.01 * self.rng.standard_normal(),\n",
        "            0.01 * self.rng.standard_normal()],\n",
        "            dtype=float,\n",
        "        )\n",
        "\n",
        "        # start from typical DBS settings\n",
        "        init_amp = 2.0     # mA\n",
        "        init_freq = 130.0  # Hz\n",
        "        init_pw = 120.0    # µs\n",
        "\n",
        "        init_amp, init_freq, init_pw = self._clip_params(init_amp, init_freq, init_pw)\n",
        "        self.current_params = (init_amp, init_freq, init_pw)\n",
        "        self.prev_params = self.current_params\n",
        "\n",
        "        # new episode log\n",
        "        self._start_new_episode_log()\n",
        "\n",
        "        # optional warm-up (no DBS) + baseline calibration\n",
        "        warmup_T = 1.0\n",
        "        warmup_steps = int(warmup_T / self.step_T)\n",
        "\n",
        "        if self.seizure_baseline is None:\n",
        "            # leave None; normalization will fallback conservatively\n",
        "            pass\n",
        "\n",
        "        # baseline = typical no-stim seizure index for THIS episode\n",
        "        # If user has externally calibrated a baseline, do not overwrite it\n",
        "        #if self.seizure_baseline is None:\n",
        "         #   self.seizure_baseline = float(np.mean(warm_seiz)) if len(warm_seiz) else 0.7\n",
        "\n",
        "\n",
        "        # ---------------------------------------------------------\n",
        "        # initial observation at current params\n",
        "        # ---------------------------------------------------------\n",
        "        seizure_index, energy_norm, t_w, v_w, u_w = self._simulate_window(*self.current_params)\n",
        "        pac_index = 0.0\n",
        "        theta_w = np.zeros_like(t_w, dtype=float)\n",
        "        amp_fast_w = np.zeros_like(t_w, dtype=float)\n",
        "\n",
        "        # PAC disabled: provide zero arrays for logging compatibility\n",
        "        theta_w = np.zeros_like(t_w, dtype=float)\n",
        "        amp_fast_w = np.zeros_like(t_w, dtype=float)\n",
        "        pac_index = 0.0\n",
        "\n",
        "        self.prev_seizure_index = float(seizure_index)\n",
        "\n",
        "        # log this initial window with zero reward\n",
        "        self._append_window_to_log(\n",
        "            t_w,\n",
        "            v_w,\n",
        "            u_w,\n",
        "            theta_w,\n",
        "            amp_fast_w,\n",
        "            seizure_index,\n",
        "            pac_index,\n",
        "            energy_norm,\n",
        "            amp=self.current_params[0],\n",
        "            freq=self.current_params[1],\n",
        "            pw=self.current_params[2],\n",
        "            reward=0.0,\n",
        "        )\n",
        "\n",
        "\n",
        "        obs = self._build_obs(seizure_index, self.current_params)\n",
        "        info = {\n",
        "            \"regime\": regime,\n",
        "            \"disease_level\": self.disease_level,\n",
        "            \"burden\": self.burden,\n",
        "            \"regime_labe;\": self._regime_from_burden(self.burden),\n",
        "        }\n",
        "        return obs, info\n",
        "\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "      \"\"\"\n",
        "      Single RL step.\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "      obs : np.array, shape (5,)\n",
        "           [seizure_index, amp_norm, freq_norm, pw_norm, disease_level]\n",
        "\n",
        "      reward : float\n",
        "      terminated : bool\n",
        "      truncated : bool\n",
        "      info : dict\n",
        "      \"\"\"\n",
        "      action = np.asarray(action, dtype=float).flatten()\n",
        "      if action.shape[0] != 3:\n",
        "          raise ValueError(\"Action must have shape (3,)\")\n",
        "\n",
        "      self.step_count += 1\n",
        "\n",
        "      # ---------------------------------------------------------\n",
        "      # 1) Update DBS parameters from action\n",
        "      # ---------------------------------------------------------\n",
        "      new_amp, new_freq, new_pw, d_amp, d_freq, d_pw = self._update_params_from_action(action)\n",
        "      self.prev_params = self.current_params\n",
        "      self.current_params = (new_amp, new_freq, new_pw)\n",
        "\n",
        "      burden_diag = {}\n",
        "      if getattr(self, \"use_burden_state\", False):\n",
        "          burden_diag = self._update_burden(new_amp, new_freq, new_pw)\n",
        "\n",
        "\n",
        "\n",
        "      # ---------------------------------------------------------\n",
        "      # 2) Simulate one window of JR + PAC dynamics\n",
        "      # ---------------------------------------------------------\n",
        "      # 2) Simulate one window of JR + PAC dynamics\n",
        "      raw_seiz, energy_norm, t_w, v_w, u_w = self._simulate_window(new_amp, new_freq, new_pw)\n",
        "\n",
        "      # ---- Option A: z-score + sigmoid mapping (INSERT HERE) ----\n",
        "      seizure_index = self._seizure_severity_from_raw(raw_seiz)\n",
        "\n",
        "      # PAC disabled: provide zero arrays for logging compatibility\n",
        "      theta_w = np.zeros_like(t_w, dtype=float)\n",
        "      amp_fast_w = np.zeros_like(t_w, dtype=float)\n",
        "      pac_index = 0.0\n",
        "\n",
        "      # ---------------------------------------------------------\n",
        "      # 3) Build observation (includes disease_level as last entry)\n",
        "      # ---------------------------------------------------------\n",
        "      obs = self._build_obs(seizure_index, self.current_params)\n",
        "\n",
        "      # ---------------------------------------------------------\n",
        "      # 4) Parameter slew penalty\n",
        "      # ---------------------------------------------------------\n",
        "      slew_amp = abs(d_amp) / max(self.amp_delta_max, 1e-6)\n",
        "      slew_freq = abs(d_freq) / max(self.freq_delta_max, 1e-6)\n",
        "      slew_pw = abs(d_pw) / max(self.pw_delta_max, 1e-6)\n",
        "      slew_penalty = (slew_amp + slew_freq + slew_pw) / 3.0\n",
        "\n",
        "      # ---------------------------------------------------------\n",
        "      # 5) Seizure change (delta_seiz > 0 means improvement)\n",
        "      # ---------------------------------------------------------\n",
        "      prev_seiz = self.prev_seizure_index\n",
        "      if prev_seiz is None:\n",
        "          delta_seiz = 0.0\n",
        "      else:\n",
        "          delta_seiz = max(0.0, prev_seiz - seizure_index)\n",
        "\n",
        "      # ---------------------------------------------------------\n",
        "      # 6) Disease dynamics (long-term plasticity)\n",
        "      #     - Disease increases if seizure_index stays above baseline\n",
        "      #     - Disease decreases if seizures improve\n",
        "      # ---------------------------------------------------------\n",
        "      # Use the same reference as your reward gating (target), not baseline\n",
        "\n",
        "\n",
        "      # Apply JR parameters based on updated disease_level\n",
        "      self._apply_jr_params_from_disease()\n",
        "\n",
        "      # now update prev for next step\n",
        "      self.prev_seizure_index = float(seizure_index)\n",
        "\n",
        "      # disease increases when seizures are high, decreases slowly when low\n",
        "      idx = float(seizure_index)  # burden-based seizure_index\n",
        "      target = float(getattr(self, \"seizure_target\", 0.2))\n",
        "\n",
        "      up = self.disease_up_rate * max(0.0, idx - target)\n",
        "      down = self.disease_down_rate * max(0.0, target - idx)\n",
        "\n",
        "      self.disease_level = float(np.clip(\n",
        "          self.disease_level + up - down,\n",
        "          self.disease_floor,\n",
        "          1.0\n",
        "))\n",
        "\n",
        "      # ---------------------------------------------------------\n",
        "      # 7) Reward components\n",
        "      #     - Primary: suppress seizures\n",
        "      #     - Secondary: energy, slew, disease\n",
        "      # ---------------------------------------------------------\n",
        "      target = float(getattr(self, \"seizure_target\", 0.05))\n",
        "\n",
        "      # seizure_index is ALREADY returned by _simulate_window()\n",
        "      seiz_cost = float(seizure_index)  # dense, always informative\n",
        "\n",
        "      cost = (\n",
        "          self.w_seiz   * seiz_cost +\n",
        "          self.w_energy * float(energy_norm) +\n",
        "          self.w_slew   * float(slew_penalty) +\n",
        "          self.w_disease * float(self.disease_level)\n",
        "      )\n",
        "      reward = -cost + self.w_delta_seizure * float(delta_seiz)\n",
        "\n",
        "\n",
        "\n",
        "      # ---------------------------------------------------------\n",
        "      # 8) Logging\n",
        "      # ---------------------------------------------------------\n",
        "      self.episode_reward += reward\n",
        "      self._append_window_to_log(\n",
        "          t_w,\n",
        "          v_w,\n",
        "          u_w,\n",
        "          theta_w,\n",
        "          amp_fast_w,\n",
        "          seizure_index,\n",
        "          pac_index,      # <-- must be present (0.0 if PAC disabled)\n",
        "          energy_norm,\n",
        "          new_amp,\n",
        "          new_freq,\n",
        "          new_pw,\n",
        "          reward,         # <-- must be last\n",
        "      )\n",
        "\n",
        "\n",
        "      # ---------------------------------------------------------\n",
        "      # 9) Termination / truncation\n",
        "      # ---------------------------------------------------------\n",
        "      terminated = False\n",
        "      truncated = self.step_count >= self.max_steps\n",
        "\n",
        "      if truncated or terminated:\n",
        "          self._finalise_episode_log()\n",
        "\n",
        "      # Add these just before building info\n",
        "      base = float(self.seizure_baseline) if self.seizure_baseline is not None else np.nan\n",
        "      sc   = float(self.seizure_scale) if self.seizure_scale is not None else np.nan\n",
        "      raw  = float(getattr(self, \"_last_seizure_metric_raw\", np.nan))\n",
        "      z    = (raw - base) / sc if np.isfinite(raw) and np.isfinite(base) and np.isfinite(sc) and sc > 0 else np.nan\n",
        "      target = float(getattr(self, \"seizure_target\", 0.05))\n",
        "\n",
        "\n",
        "      # ---------------------------------------------------------\n",
        "      # 10) info dict (no assignments inside the literal)\n",
        "      # ---------------------------------------------------------\n",
        "      info = {\n",
        "          \"seizure_index\": float(seizure_index),\n",
        "          \"seizure_metric_raw\": float(getattr(self, \"_last_seizure_metric_raw\", np.nan)),\n",
        "          \"seizure_error_above_baseline\": float(seiz_error),\n",
        "          \"seizure_target\": target,\n",
        "          \"seizure_baseline\": base,\n",
        "          \"seizure_scale\": sc,\n",
        "          \"burden\": self.burden,\n",
        "          \"regime_label\": self._regime_from_burden(self.burden),\n",
        "          \"seizure_z\": float(z),\n",
        "          \"pac_index\": float(pac_index),\n",
        "          \"energy_norm\": float(energy_norm),\n",
        "          \"amp\": float(new_amp),\n",
        "          \"freq\": float(new_freq),\n",
        "          \"pw\": float(new_pw),\n",
        "          \"slew_penalty\": float(slew_penalty),\n",
        "          \"disease_level\": float(self.disease_level),\n",
        "          \"reward\": float(reward),\n",
        "          \"cost_components\": {\n",
        "              \"seizure\": float(self.w_seiz * seiz_cost),\n",
        "              \"energy\": float(self.w_energy * energy_norm),\n",
        "              \"slew\": float(self.w_slew * slew_penalty),\n",
        "              \"disease\": float(self.w_disease * self.disease_level),\n",
        "              \"delta_seiz_bonus\": float(self.w_delta_seizure * delta_seiz),\n",
        "          },\n",
        "      }\n",
        "\n",
        "      return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def calibrate_seizure_scale(self, n_windows: int = 300, seed: int = 0, regime: str = \"normal\"):\n",
        "        # Ensure we are in the requested regime\n",
        "        self.reset(seed=seed, options={\"regime\": regime})\n",
        "\n",
        "        raw_vals = []\n",
        "        zero_action = np.array([0.0, 0.0, 0.0], dtype=np.float32)\n",
        "\n",
        "        for _ in range(n_windows):\n",
        "            _, _, terminated, truncated, info = self.step(zero_action)\n",
        "            raw_vals.append(float(info[\"seizure_metric_raw\"]))\n",
        "            if terminated or truncated:\n",
        "                self.reset(seed=seed, options={\"regime\": regime})\n",
        "\n",
        "        raw = np.asarray(raw_vals, dtype=float)\n",
        "        raw = raw[np.isfinite(raw)]\n",
        "        if raw.size < 10:\n",
        "            raise RuntimeError(f\"Not enough finite raw seizure metric samples: {raw.size}\")\n",
        "\n",
        "        p50 = float(np.percentile(raw, 50))\n",
        "        p95 = float(np.percentile(raw, 95))\n",
        "        eps = 1e-3\n",
        "\n",
        "        self.seizure_baseline = p50\n",
        "        self.seizure_scale = float(max(p95 - p50, eps))\n",
        "\n",
        "        return {\n",
        "            \"regime\": regime,\n",
        "            \"n_windows\": int(raw.size),\n",
        "            \"raw_p50\": p50,\n",
        "            \"raw_p95\": p95,\n",
        "            \"seizure_baseline_set_to\": float(self.seizure_baseline),\n",
        "            \"seizure_scale_set_to\": float(self.seizure_scale),\n",
        "        }\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Convenience\n",
        "    # ------------------------------------------------------------------\n",
        "    def get_best_episodes(self):\n",
        "        \"\"\"\n",
        "        Return a shallow copy of the list of best episodes.\n",
        "        \"\"\"\n",
        "        return list(self.best_episodes)\n"
      ],
      "metadata": {
        "id": "LAb3xC69DXcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsS90eB4rJ2i"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, hidden_sizes=(256, 256), activation=nn.ReLU):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        last = in_dim\n",
        "        for h in hidden_sizes:\n",
        "            layers.append(nn.Linear(last, h))\n",
        "            layers.append(activation())\n",
        "            last = h\n",
        "        layers.append(nn.Linear(last, out_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        self.prev_seizure_index = None\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoDQDMhDrL9b"
      },
      "outputs": [],
      "source": [
        "class GaussianPolicy(nn.Module):\n",
        "    def __init__(self, obs_dim, act_dim, act_low, act_high, hidden_sizes=(256, 256), log_std_min=-20, log_std_max=2):\n",
        "        super().__init__()\n",
        "        self.base = MLP(obs_dim, 2 * act_dim, hidden_sizes)\n",
        "        self.log_std_min = log_std_min\n",
        "        self.log_std_max = log_std_max\n",
        "        self.register_buffer(\"act_low\", torch.tensor(act_low, dtype=torch.float32))\n",
        "        self.register_buffer(\"act_high\", torch.tensor(act_high, dtype=torch.float32))\n",
        "\n",
        "    def forward(self, obs):\n",
        "        mu_logstd = self.base(obs)\n",
        "        mu, log_std = torch.chunk(mu_logstd, 2, dim=-1)\n",
        "        log_std = torch.clamp(log_std, self.log_std_min, self.log_std_max)\n",
        "        std = log_std.exp()\n",
        "        dist = Normal(mu, std)\n",
        "        return dist\n",
        "\n",
        "    def sample(self, obs):\n",
        "        dist = self.forward(obs)\n",
        "        x_t = dist.rsample()\n",
        "        log_prob = dist.log_prob(x_t).sum(-1, keepdim=True)\n",
        "        # squash via tanh\n",
        "        y_t = torch.tanh(x_t)\n",
        "        # correction term\n",
        "        log_prob -= torch.sum(torch.log(1 - y_t.pow(2) + 1e-6), dim=-1, keepdim=True)\n",
        "        # rescale to action bounds\n",
        "        act_mid = (self.act_high + self.act_low) / 2.0\n",
        "        act_half = (self.act_high - self.act_low) / 2.0\n",
        "        action = act_mid + act_half * y_t\n",
        "        return action, log_prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv6MUZSvrOHL"
      },
      "outputs": [],
      "source": [
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, obs_dim, act_dim, hidden_sizes=(256, 256)):\n",
        "        super().__init__()\n",
        "        self.q = MLP(obs_dim + act_dim, 1, hidden_sizes)\n",
        "\n",
        "    def forward(self, obs, act):\n",
        "        x = torch.cat([obs, act], dim=-1)\n",
        "        return self.q(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNLkHb9FrQOe"
      },
      "outputs": [],
      "source": [
        "Transition = collections.namedtuple(\"Transition\", [\"obs\", \"act\", \"rew\", \"next_obs\", \"done\"])\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity, obs_dim, act_dim):\n",
        "        self.capacity = capacity\n",
        "        self.obs_buf = np.zeros((capacity, obs_dim), dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros((capacity, obs_dim), dtype=np.float32)\n",
        "        self.act_buf = np.zeros((capacity, act_dim), dtype=np.float32)\n",
        "        self.rew_buf = np.zeros((capacity, 1), dtype=np.float32)\n",
        "        self.done_buf = np.zeros((capacity, 1), dtype=np.float32)\n",
        "        self.ptr = 0\n",
        "        self.size = 0\n",
        "\n",
        "    def add(self, obs, act, rew, next_obs, done):\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.act_buf[self.ptr] = act\n",
        "        self.rew_buf[self.ptr] = rew\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.done_buf[self.ptr] = done\n",
        "\n",
        "        self.ptr = (self.ptr + 1) % self.capacity\n",
        "        self.size = min(self.size + 1, self.capacity)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        idxs = np.random.randint(0, self.size, size=batch_size)\n",
        "        return (\n",
        "            torch.tensor(self.obs_buf[idxs], dtype=torch.float32, device=DEVICE),\n",
        "            torch.tensor(self.act_buf[idxs], dtype=torch.float32, device=DEVICE),\n",
        "            torch.tensor(self.rew_buf[idxs], dtype=torch.float32, device=DEVICE),\n",
        "            torch.tensor(self.next_obs_buf[idxs], dtype=torch.float32, device=DEVICE),\n",
        "            torch.tensor(self.done_buf[idxs], dtype=torch.float32, device=DEVICE),\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69ebnQuvrSQS"
      },
      "outputs": [],
      "source": [
        "class SACAgent:\n",
        "    def __init__(self, obs_dim, act_dim, act_low, act_high,\n",
        "                 gamma=0.99, tau=0.005, alpha=0.2,\n",
        "                 actor_lr=1e-4 , critic_lr=3e-4, target_entropy=None):\n",
        "        self.gamma = gamma\n",
        "        self.tau = tau\n",
        "\n",
        "        self.actor = GaussianPolicy(obs_dim, act_dim, act_low, act_high).to(DEVICE)\n",
        "        self.q1 = QNetwork(obs_dim, act_dim).to(DEVICE)\n",
        "        self.q2 = QNetwork(obs_dim, act_dim).to(DEVICE)\n",
        "        self.q1_target = QNetwork(obs_dim, act_dim).to(DEVICE)\n",
        "        self.q2_target = QNetwork(obs_dim, act_dim).to(DEVICE)\n",
        "        self.q1_target.load_state_dict(self.q1.state_dict())\n",
        "        self.q2_target.load_state_dict(self.q2.state_dict())\n",
        "\n",
        "        self.actor_opt = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
        "        self.q1_opt = optim.Adam(self.q1.parameters(), lr=critic_lr)\n",
        "        self.q2_opt = optim.Adam(self.q2.parameters(), lr=critic_lr)\n",
        "\n",
        "        self.log_alpha = torch.tensor(np.log(alpha), device=DEVICE, requires_grad=True)\n",
        "        self.alpha_opt = optim.Adam([self.log_alpha], lr=actor_lr)\n",
        "        self.target_entropy = target_entropy if target_entropy is not None else -act_dim\n",
        "\n",
        "        self.critic_losses = []\n",
        "        self.actor_losses = []\n",
        "        self.alpha_hist = []\n",
        "        self.entropy_hist = []\n",
        "\n",
        "\n",
        "    @property\n",
        "    def alpha(self):\n",
        "        return self.log_alpha.exp()\n",
        "\n",
        "    def select_action(self, obs, eval_mode=False):\n",
        "        obs_t = torch.tensor(obs, dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
        "        if eval_mode:\n",
        "            dist = self.actor(obs_t)\n",
        "            mu = dist.mean\n",
        "            y_t = torch.tanh(mu)\n",
        "            act_mid = (self.actor.act_high + self.actor.act_low) / 2.0\n",
        "            act_half = (self.actor.act_high - self.actor.act_low) / 2.0\n",
        "            action = act_mid + act_half * y_t\n",
        "            return action.detach().cpu().numpy()[0]\n",
        "        else:\n",
        "            action, _ = self.actor.sample(obs_t)\n",
        "            return action.detach().cpu().numpy()[0]\n",
        "\n",
        "    def update(self, replay_buffer, batch_size):\n",
        "        obs, act, rew, next_obs, done = replay_buffer.sample(batch_size)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            next_action, next_log_prob = self.actor.sample(next_obs)\n",
        "            q1_next = self.q1_target(next_obs, next_action)\n",
        "            q2_next = self.q2_target(next_obs, next_action)\n",
        "            q_next = torch.min(q1_next, q2_next) - self.alpha * next_log_prob\n",
        "            target_q = rew + (1 - done) * self.gamma * q_next\n",
        "\n",
        "        # Q1, Q2 losses\n",
        "        q1_pred = self.q1(obs, act)\n",
        "        q2_pred = self.q2(obs, act)\n",
        "        q1_loss = ((q1_pred - target_q)**2).mean()\n",
        "        q2_loss = ((q2_pred - target_q)**2).mean()\n",
        "\n",
        "        self.q1_opt.zero_grad()\n",
        "        q1_loss.backward()\n",
        "        self.q1_opt.step()\n",
        "\n",
        "        self.q2_opt.zero_grad()\n",
        "        q2_loss.backward()\n",
        "        self.q2_opt.step()\n",
        "\n",
        "        # Actor + alpha\n",
        "        new_actions, log_prob = self.actor.sample(obs)\n",
        "        q1_new = self.q1(obs, new_actions)\n",
        "        q2_new = self.q2(obs, new_actions)\n",
        "        q_new = torch.min(q1_new, q2_new)\n",
        "\n",
        "        actor_loss = (self.alpha * log_prob - q_new).mean()\n",
        "\n",
        "        self.actor_opt.zero_grad()\n",
        "        actor_loss.backward()\n",
        "        self.actor_opt.step()\n",
        "\n",
        "        alpha_loss = -(self.log_alpha * (log_prob + self.target_entropy).detach()).mean()\n",
        "        self.alpha_opt.zero_grad()\n",
        "        alpha_loss.backward()\n",
        "        self.alpha_opt.step()\n",
        "\n",
        "        # After computing q1_loss, q2_loss, actor_loss, alpha_loss, log_prob etc.\n",
        "        self.critic_losses.append(float((q1_loss + q2_loss).item()))\n",
        "        self.actor_losses.append(float(actor_loss.item()))\n",
        "        self.alpha_hist.append(float(self.alpha.item()))\n",
        "\n",
        "        # policy entropy estimate: -E[log pi(a|s)]\n",
        "        self.entropy_hist.append(float((-log_prob).mean().item()))\n",
        "\n",
        "\n",
        "        # Soft target updates\n",
        "        with torch.no_grad():\n",
        "            for param, target_param in zip(self.q1.parameters(), self.q1_target.parameters()):\n",
        "                target_param.data.mul_(1 - self.tau)\n",
        "                target_param.data.add_(self.tau * param.data)\n",
        "            for param, target_param in zip(self.q2.parameters(), self.q2_target.parameters()):\n",
        "                target_param.data.mul_(1 - self.tau)\n",
        "                target_param.data.add_(self.tau * param.data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import welch\n",
        "\n",
        "def compute_psd(signal, fs, nperseg=None):\n",
        "    freqs, psd = welch(\n",
        "        signal,\n",
        "        fs=fs,\n",
        "        nperseg=nperseg or min(1024, len(signal)),\n",
        "        scaling=\"density\"\n",
        "    )\n",
        "    return freqs, psd\n",
        "\n",
        "\n",
        "def collect_regime_psds(\n",
        "    env,\n",
        "    regime,\n",
        "    n_windows=50,\n",
        "    fs=1000.0,\n",
        "    action=None\n",
        "):\n",
        "    psds = []\n",
        "    freqs_ref = None\n",
        "\n",
        "    env.reset(options={\"regime\": regime})\n",
        "\n",
        "    for _ in range(n_windows):\n",
        "        obs, reward, terminated, truncated, info = env.step(\n",
        "            action if action is not None else np.zeros(env.action_space.shape)\n",
        "        )\n",
        "\n",
        "        # EXPECTED: info[\"lfp\"]\n",
        "        lfp = info.get(\"lfp\", None)\n",
        "        if lfp is None:\n",
        "            raise RuntimeError(\"LFP not found in info; adjust extraction.\")\n",
        "\n",
        "        freqs, psd = compute_psd(lfp, fs)\n",
        "        freqs_ref = freqs if freqs_ref is None else freqs_ref\n",
        "        psds.append(psd)\n",
        "\n",
        "        if terminated or truncated:\n",
        "            env.reset(options={\"regime\": regime})\n",
        "\n",
        "    return freqs_ref, np.vstack(psds)\n"
      ],
      "metadata": {
        "id": "-Qs3AcZBOpsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env2.reset(options={\"regime\": \"normal\"})\n",
        "obs, reward, terminated, truncated, info = env2.step(\n",
        "    np.zeros(env2.action_space.shape)\n",
        ")\n",
        "\n",
        "print(\"info keys:\", info.keys())\n",
        "print(\"obs type:\", type(obs))\n",
        "if isinstance(obs, dict):\n",
        "    print(\"obs keys:\", obs.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ6HjFA4PpMe",
        "outputId": "949125e9-25ad-4fac-a9b1-cc50159df335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "info keys: dict_keys(['seizure_index', 'seizure_metric_raw', 'seizure_error_above_baseline', 'seizure_target', 'seizure_baseline', 'seizure_scale', 'burden', 'regime_label', 'seizure_z', 'pac_index', 'energy_norm', 'amp', 'freq', 'pw', 'slew_penalty', 'disease_level', 'reward', 'cost_components'])\n",
            "obs type: <class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4191453066.py:230: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(psd[idx], freqs[idx]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "print(inspect.getsource(EpilepsyDBSCombinedEnv._normalize_seizure_raw))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM3cq_uGbOzL",
        "outputId": "6fdc6a23-4726-42c0-f4b6-4f728df5005c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    def _normalize_seizure_raw(self, raw: float) -> float:\n",
            "        if self.seizure_baseline is None or self.seizure_scale is None:\n",
            "            return 0.0\n",
            "\n",
            "        base = float(self.seizure_baseline)\n",
            "        s = max(float(self.seizure_scale), 1e-3)\n",
            "\n",
            "        z = (float(raw) - base) / s\n",
            "        z = max(0.0, z)\n",
            "        idx = z / (1.0 + z)\n",
            "        return float(np.clip(idx, 0.0, 1.0))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVnWwGkQrUSn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "872a6b2d-c590-451e-9aff-af6a48c07ec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2802254465.py:271: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(psd[idx], freqs[idx]))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'seiz_error' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3579800649.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_band\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrate_seizure_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_windows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"normal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2802254465.py\u001b[0m in \u001b[0;36mcalibrate_seizure_scale\u001b[0;34m(self, n_windows, seed, regime)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_windows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m             \u001b[0mraw_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seizure_metric_raw\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2802254465.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    962\u001b[0m           \u001b[0;34m\"seizure_index\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseizure_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m           \u001b[0;34m\"seizure_metric_raw\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_last_seizure_metric_raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m           \u001b[0;34m\"seizure_error_above_baseline\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseiz_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m           \u001b[0;34m\"seizure_target\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;34m\"seizure_baseline\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seiz_error' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1) Create env\n",
        "env = EpilepsyDBSCombinedEnv()\n",
        "\n",
        "episode_summaries = []\n",
        "\n",
        "\n",
        "# Seizure metric config\n",
        "env.seizure_metric = \"bandpower_ratio\"   # or \"line_length\"\n",
        "env.seizure_band = (8.0, 30.0)           # only used if bandpower_ratio\n",
        "env.total_band = (1.0, 80.0)\n",
        "\n",
        "cal = env.calibrate_seizure_scale(n_windows=500, regime=\"normal\", seed=0)\n",
        "print(cal)\n",
        "\n",
        "# 2) Get dimensions from Gymnasium spaces\n",
        "obs_dim = env.observation_space.shape[0]\n",
        "act_dim = env.action_space.shape[0]\n",
        "act_low = env.action_space.low\n",
        "act_high = env.action_space.high\n",
        "\n",
        "# 3) Create SAC agent\n",
        "agent = SACAgent(obs_dim, act_dim, act_low, act_high)\n",
        "\n",
        "# 4) Create replay buffer\n",
        "buffer_capacity = 100_000\n",
        "replay_buffer = ReplayBuffer(buffer_capacity, obs_dim, act_dim)\n",
        "\n",
        "# 5) Training hyperparameters\n",
        "num_episodes = 400\n",
        "max_steps_per_episode = env.max_steps\n",
        "batch_size = 128\n",
        "warmup_steps = 5000\n",
        "\n",
        "episode_returns = []\n",
        "global_step = 0\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    # Choose regime per episode\n",
        "\n",
        "    if episode < 30:\n",
        "        env.w_seiz, env.w_energy, env.w_slew = 1.0, 0.0, 0.0\n",
        "    elif episode < 70:\n",
        "        env.w_seiz, env.w_energy, env.w_slew = 1.0, 0.1, 0.05\n",
        "    else:\n",
        "        env.w_seiz, env.w_energy, env.w_slew = 1.0, 0.3, 0.1\n",
        "    regime = \"ictal\"\n",
        "\n",
        "    obs, info = env.reset(options={\"regime\": regime})\n",
        "    done = False\n",
        "    ep_return = 0.0\n",
        "    steps = 0\n",
        "\n",
        "    # ----- accumulators for printed diagnostics -----\n",
        "    seizure_cost_sum = 0.0\n",
        "    pac_err_sum = 0.0  # stays 0 unless you add it\n",
        "    energy_cost_sum = 0.0\n",
        "    slew_cost_sum = 0.0\n",
        "\n",
        "    amp_sum = 0.0\n",
        "    freq_sum = 0.0\n",
        "    pw_sum = 0.0\n",
        "\n",
        "    # NEW: seizure index diagnostics (raw index, not cost)\n",
        "    seiz_idx_sum = 0.0\n",
        "    seiz_idx_max = 0.0\n",
        "\n",
        "    while (not done) and (steps < max_steps_per_episode):\n",
        "        # 1) Action selection\n",
        "        if global_step < warmup_steps:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = agent.select_action(obs)\n",
        "\n",
        "        # 2) Step environment\n",
        "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
        "        done = bool(terminated or truncated)\n",
        "\n",
        "        # 3) Replay buffer guard + add\n",
        "        if (\n",
        "            np.all(np.isfinite(obs)) and\n",
        "            np.all(np.isfinite(action)) and\n",
        "            np.isfinite(reward) and\n",
        "            np.all(np.isfinite(next_obs))\n",
        "        ):\n",
        "            replay_buffer.add(\n",
        "                obs,\n",
        "                action,\n",
        "                np.array([reward], dtype=np.float32),\n",
        "                next_obs,\n",
        "                np.array([float(done)], dtype=np.float32),\n",
        "            )\n",
        "\n",
        "            if (global_step >= warmup_steps) and (replay_buffer.size >= batch_size):\n",
        "                agent.update(replay_buffer, batch_size)\n",
        "        else:\n",
        "            print(f\"[Warning] Non-finite transition at step {steps}, terminating episode.\")\n",
        "            done = True\n",
        "\n",
        "        # 4) Accumulate metrics (per step)\n",
        "        # Cost components in your env are already weighted\n",
        "        seizure_cost_sum += float(info[\"cost_components\"][\"seizure\"])\n",
        "        energy_cost_sum += float(info[\"cost_components\"][\"energy\"])\n",
        "        slew_cost_sum += float(info[\"cost_components\"][\"slew\"])\n",
        "        # pac_err_sum += float(info.get(\"pac_error\", 0.0))  # only if you ever add it\n",
        "\n",
        "        amp_sum += float(info[\"amp\"])\n",
        "        freq_sum += float(info[\"freq\"])\n",
        "        pw_sum += float(info[\"pw\"])\n",
        "\n",
        "        seiz_idx = float(info[\"seizure_index\"])\n",
        "        seiz_idx_sum += seiz_idx\n",
        "        if seiz_idx > seiz_idx_max:\n",
        "            seiz_idx_max = seiz_idx\n",
        "\n",
        "        # 5) Bookkeeping\n",
        "        obs = next_obs\n",
        "        ep_return += float(reward)\n",
        "        steps += 1\n",
        "        global_step += 1\n",
        "\n",
        "    # ----- episode averages -----\n",
        "    if steps > 0:\n",
        "        avg_seizure_cost = seizure_cost_sum / steps\n",
        "        avg_pac_err = pac_err_sum / steps\n",
        "        avg_energy_cost = energy_cost_sum / steps\n",
        "        avg_slew_cost = slew_cost_sum / steps\n",
        "\n",
        "        avg_amp = amp_sum / steps\n",
        "        avg_freq = freq_sum / steps\n",
        "        avg_pw = pw_sum / steps\n",
        "\n",
        "        mean_seiz_idx = seiz_idx_sum / steps\n",
        "        max_seiz_idx = seiz_idx_max\n",
        "    else:\n",
        "        avg_seizure_cost = avg_pac_err = avg_energy_cost = avg_slew_cost = 0.0\n",
        "        avg_amp = avg_freq = avg_pw = 0.0\n",
        "        mean_seiz_idx = max_seiz_idx = 0.0\n",
        "\n",
        "    # SECTION 5: If ictal episodes still show ~0 seizure penalty AND index is below target, scale is likely too large.\n",
        "    if (regime == \"ictal\") and (steps > 0):\n",
        "        target = float(getattr(env, \"seizure_target\", 0.05))\n",
        "        if (avg_seizure_cost < 1e-6) and (max_seiz_idx < target + 1e-3):\n",
        "            env.seizure_scale = max(env.seizure_scale * 0.25, 1e-12)\n",
        "            print(f\"[Adjust] ictal seizure penalty ~0; reducing env.seizure_scale to {env.seizure_scale:.3e}\")\n",
        "\n",
        "    episode_returns.append(ep_return)\n",
        "\n",
        "    episode_summaries.append({\n",
        "    \"episode\": episode + 1,\n",
        "    \"regime\": regime,\n",
        "    \"return\": float(ep_return),\n",
        "    \"steps\": int(steps),\n",
        "    \"avg_seizure_cost\": float(avg_seizure_cost),\n",
        "    \"avg_energy_cost\": float(avg_energy_cost),\n",
        "    \"avg_slew_cost\": float(avg_slew_cost),\n",
        "    \"mean_seiz_idx\": float(mean_seiz_idx),\n",
        "    \"max_seiz_idx\": float(max_seiz_idx),\n",
        "    \"avg_amp\": float(avg_amp),\n",
        "    \"avg_freq\": float(avg_freq),\n",
        "    \"avg_pw\": float(avg_pw),\n",
        "})\n",
        "\n",
        "\n",
        "    # ----- prints -----\n",
        "    print(f\"\\nEpisode {episode+1}/{num_episodes}  (regime={regime})\")\n",
        "    print(f\"Return: {ep_return:.3f} over {steps} steps\\n\")\n",
        "\n",
        "    print(\"=== Average Cost Components (weighted) ===\")\n",
        "    print(f\"  Seizure term         : {avg_seizure_cost:.4f}\")\n",
        "    print(f\"  PAC error term       : {avg_pac_err:.4f}\")\n",
        "    print(f\"  Energy term          : {avg_energy_cost:.4f}\")\n",
        "    print(f\"  Slew term            : {avg_slew_cost:.4f}\")\n",
        "\n",
        "    print(\"\\n=== Seizure Index Diagnostics (raw index) ===\")\n",
        "    print(f\"  Mean seizure_index   : {mean_seiz_idx:.4f}\")\n",
        "    print(f\"  Max seizure_index    : {max_seiz_idx:.4f}\")\n",
        "    print(f\"  seizure_target       : {float(getattr(env, 'seizure_target', 0.05)):.4f}\")\n",
        "\n",
        "    print(\"\\n=== Average DBS Parameters ===\")\n",
        "    print(f\"  Mean amplitude (mA)  : {avg_amp:.3f}\")\n",
        "    print(f\"  Mean frequency (Hz)  : {avg_freq:.3f}\")\n",
        "    print(f\"  Mean pulse width (µs): {avg_pw:.3f}\")\n",
        "    print(\"\\n\" + \"-\"*60 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = EpilepsyDBSCombinedEnv()\n",
        "env.seizure_metric = \"bandpower_ratio\"\n",
        "env.seizure_band = (8.0, 30.0)\n",
        "env.total_band = (1.0, 80.0)\n",
        "\n",
        "# 1) Reset into the regime you want calibrated\n",
        "env.reset(seed=0, options={\"regime\": \"normal\"})\n",
        "\n",
        "# 2) Calibrate WITHOUT regime kwarg\n",
        "cal = env.calibrate_seizure_scale(n_windows=50, seed=0)\n",
        "print(\"cal:\", cal)\n",
        "\n",
        "a0 = np.array([0.0, 0.0, 0.0], dtype=np.float32)\n",
        "\n",
        "raws = []\n",
        "for _ in range(20):\n",
        "    obs, r, term, trunc, info = env.step(a0)\n",
        "    raws.append(info[\"seizure_metric_raw\"])\n",
        "\n",
        "print(\"raw min/max:\", float(np.min(raws)), float(np.max(raws)))\n",
        "\n"
      ],
      "metadata": {
        "id": "APQ4dvYb3jGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"seizure_metric:\", getattr(env, \"seizure_metric\", None))\n",
        "print(\"seizure_baseline:\", getattr(env, \"seizure_baseline\", None))\n",
        "print(\"seizure_scale:\", getattr(env, \"seizure_scale\", None))\n",
        "\n",
        "def debug_norm_once(regime=\"normal\", steps=10):\n",
        "    obs, info = env.reset(options={\"regime\": regime})\n",
        "    for i in range(steps):\n",
        "        obs, r, term, trunc, info = env.step(np.zeros(3, dtype=np.float32))\n",
        "        raw = info.get(\"seizure_metric_raw\", None)\n",
        "        idx = info.get(\"seizure_index\", None)\n",
        "        print(f\"{regime:8s} step {i:02d}: raw={raw:.6f}  idx={idx:.6f}\")\n",
        "        if term or trunc:\n",
        "            obs, info = env.reset(options={\"regime\": regime})\n",
        "\n",
        "debug_norm_once(\"normal\", steps=10)\n",
        "debug_norm_once(\"ictal\", steps=10)\n"
      ],
      "metadata": {
        "id": "_BC1wyog_I59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cal = env.calibrate_seizure_scale(n_windows=300, regime=\"normal\", seed=0)\n",
        "print(\"CAL:\", cal)\n",
        "print(\"baseline:\", getattr(env, \"seizure_baseline\", None))\n",
        "print(\"scale   :\", getattr(env, \"seizure_scale\", None))\n",
        "\n",
        "# quick probe of raw range under the same regime, zero action\n",
        "obs, info = env.reset(seed=0, options={\"regime\": \"normal\"})\n",
        "raws, idxs = [], []\n",
        "for _ in range(50):\n",
        "    obs, r, term, trunc, info = env.step(np.zeros(3, dtype=np.float32))\n",
        "    raws.append(info[\"seizure_metric_raw\"])\n",
        "    idxs.append(info[\"seizure_index\"])\n",
        "    if term or trunc:\n",
        "        obs, info = env.reset(seed=0, options={\"regime\": \"normal\"})\n",
        "\n",
        "print(\"raw min/mean/max:\", float(np.min(raws)), float(np.mean(raws)), float(np.max(raws)))\n",
        "print(\"idx min/mean/max:\", float(np.min(idxs)), float(np.mean(idxs)), float(np.max(idxs)))\n"
      ],
      "metadata": {
        "id": "TktjWdZSCgXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def run_diagnostic_episode(env, regime=\"normal\", n_steps=150, action=None, seed=0, capture_step=10):\n",
        "    \"\"\"\n",
        "    Runs one episode worth of steps under a given regime and returns logged arrays.\n",
        "    action: if None -> zero action; else callable(step)->action or constant np.array(3,)\n",
        "    capture_step: which step to capture a window trace from (v_window/u_window)\n",
        "    \"\"\"\n",
        "    obs, info = env.reset(seed=seed, options={\"regime\": regime})\n",
        "\n",
        "    raws = []\n",
        "    idxs = []\n",
        "    rews = []\n",
        "    amps = []\n",
        "    freqs = []\n",
        "    pws = []\n",
        "\n",
        "    # capture window traces (if available)\n",
        "    cap = {\"t\": None, \"v\": None, \"u\": None, \"step\": None}\n",
        "\n",
        "    for t in range(n_steps):\n",
        "        if action is None:\n",
        "            a = np.zeros(3, dtype=np.float32)\n",
        "        elif callable(action):\n",
        "            a = np.asarray(action(t), dtype=np.float32)\n",
        "        else:\n",
        "            a = np.asarray(action, dtype=np.float32)\n",
        "\n",
        "        obs, reward, terminated, truncated, info = env.step(a)\n",
        "\n",
        "        raws.append(float(info.get(\"seizure_metric_raw\", np.nan)))\n",
        "        idxs.append(float(info.get(\"seizure_index\", np.nan)))\n",
        "        rews.append(float(reward))\n",
        "\n",
        "        # pull stim params if you store them\n",
        "        # (adapt keys if your env uses different names)\n",
        "        stim = info.get(\"stim_params\", None)\n",
        "        if stim is None:\n",
        "            # fallback: if you store current_params on env\n",
        "            if hasattr(env, \"current_params\") and env.current_params is not None:\n",
        "                amp, freq, pw = env.current_params\n",
        "            else:\n",
        "                amp, freq, pw = (np.nan, np.nan, np.nan)\n",
        "        else:\n",
        "            amp = stim.get(\"amp_mA\", np.nan)\n",
        "            freq = stim.get(\"freq_Hz\", np.nan)\n",
        "            pw = stim.get(\"pw_us\", stim.get(\"pw_ms\", np.nan))  # support either\n",
        "\n",
        "        amps.append(float(amp))\n",
        "        freqs.append(float(freq))\n",
        "        pws.append(float(pw))\n",
        "\n",
        "        # try to capture an example window trace\n",
        "        if t == capture_step:\n",
        "            # Your env already has t_window/v_window/u_window inside _simulate_window.\n",
        "            # If you store them (recommended), pull them here.\n",
        "            if \"t_window\" in info and \"v_window\" in info and \"u_window\" in info:\n",
        "                cap[\"t\"] = np.asarray(info[\"t_window\"])\n",
        "                cap[\"v\"] = np.asarray(info[\"v_window\"])\n",
        "                cap[\"u\"] = np.asarray(info[\"u_window\"])\n",
        "                cap[\"step\"] = t\n",
        "            else:\n",
        "                # If not in info, attempt to fetch from env fields if you stored them\n",
        "                for k_t, k_v, k_u in [(\"_last_t_window\", \"_last_v_window\", \"_last_u_window\"),\n",
        "                                      (\"_t_window\", \"_v_window\", \"_u_window\")]:\n",
        "                    if hasattr(env, k_t) and hasattr(env, k_v) and hasattr(env, k_u):\n",
        "                        cap[\"t\"] = np.asarray(getattr(env, k_t))\n",
        "                        cap[\"v\"] = np.asarray(getattr(env, k_v))\n",
        "                        cap[\"u\"] = np.asarray(getattr(env, k_u))\n",
        "                        cap[\"step\"] = t\n",
        "                        break\n",
        "\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    return {\n",
        "        \"regime\": regime,\n",
        "        \"raw\": np.asarray(raws),\n",
        "        \"idx\": np.asarray(idxs),\n",
        "        \"rew\": np.asarray(rews),\n",
        "        \"amp\": np.asarray(amps),\n",
        "        \"freq\": np.asarray(freqs),\n",
        "        \"pw\": np.asarray(pws),\n",
        "        \"cap\": cap,\n",
        "    }\n",
        "\n",
        "\n",
        "def plot_diagnostics(result, show_hist=True, psd=True):\n",
        "    regime = result[\"regime\"]\n",
        "    raw = result[\"raw\"]\n",
        "    idx = result[\"idx\"]\n",
        "    amp = result[\"amp\"]\n",
        "    freq = result[\"freq\"]\n",
        "    pw = result[\"pw\"]\n",
        "    cap = result[\"cap\"]\n",
        "\n",
        "    steps = np.arange(len(raw))\n",
        "\n",
        "    # 1) raw seizure metric\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(steps, raw)\n",
        "    plt.title(f\"{regime}: raw seizure metric\")\n",
        "    plt.xlabel(\"step\")\n",
        "    plt.ylabel(\"raw\")\n",
        "    plt.show()\n",
        "\n",
        "    # 2) seizure index\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(steps, idx)\n",
        "    plt.title(f\"{regime}: seizure_index\")\n",
        "    plt.xlabel(\"step\")\n",
        "    plt.ylabel(\"index\")\n",
        "    plt.show()\n",
        "\n",
        "    # 3) DBS params\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(steps, amp, label=\"amp (mA)\")\n",
        "    plt.plot(steps, freq, label=\"freq (Hz)\")\n",
        "    plt.plot(steps, pw, label=\"pw (us or ms)\")\n",
        "    plt.title(f\"{regime}: stimulation parameters\")\n",
        "    plt.xlabel(\"step\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # 4) example window traces\n",
        "    if cap[\"t\"] is not None and cap[\"v\"] is not None:\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(cap[\"t\"], cap[\"v\"], label=\"v(t)\")\n",
        "        if cap[\"u\"] is not None:\n",
        "            plt.plot(cap[\"t\"], cap[\"u\"], label=\"u(t)\")\n",
        "        plt.title(f\"{regime}: example window trace (step {cap['step']})\")\n",
        "        plt.xlabel(\"time (s or internal units)\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        # 5) PSD (optional)\n",
        "        if psd:\n",
        "            x = np.asarray(cap[\"v\"], dtype=float)\n",
        "            x = x - np.mean(x)\n",
        "            if x.size >= 32:\n",
        "                # estimate fs from time axis if possible\n",
        "                t = np.asarray(cap[\"t\"], dtype=float)\n",
        "                if np.all(np.diff(t) > 0):\n",
        "                    dt = float(np.median(np.diff(t)))\n",
        "                    fs = 1.0 / dt\n",
        "                else:\n",
        "                    fs = 1000.0  # fallback\n",
        "\n",
        "                from scipy.signal import welch\n",
        "                f, Pxx = welch(x, fs=fs, nperseg=min(256, x.size))\n",
        "                plt.figure(figsize=(10, 4))\n",
        "                plt.semilogy(f, Pxx)\n",
        "                plt.title(f\"{regime}: PSD of v(t) (step {cap['step']})\")\n",
        "                plt.xlabel(\"Hz\")\n",
        "                plt.ylabel(\"PSD\")\n",
        "                plt.xlim(0, 80)\n",
        "                plt.show()\n",
        "\n",
        "    # 6) histograms\n",
        "    if show_hist:\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.hist(raw[np.isfinite(raw)], bins=30)\n",
        "        plt.title(f\"{regime}: raw metric histogram\")\n",
        "        plt.xlabel(\"raw\")\n",
        "        plt.ylabel(\"count\")\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.hist(idx[np.isfinite(idx)], bins=30)\n",
        "        plt.title(f\"{regime}: index histogram\")\n",
        "        plt.xlabel(\"index\")\n",
        "        plt.ylabel(\"count\")\n",
        "        plt.show()\n",
        "\n",
        "    # Print summary stats\n",
        "    print(f\"== {regime} summary ==\")\n",
        "    print(\"raw  min/mean/max:\", float(np.nanmin(raw)), float(np.nanmean(raw)), float(np.nanmax(raw)))\n",
        "    print(\"idx  min/mean/max:\", float(np.nanmin(idx)), float(np.nanmean(idx)), float(np.nanmax(idx)))\n",
        "    print(\"amp  min/mean/max:\", float(np.nanmin(amp)), float(np.nanmean(amp)), float(np.nanmax(amp)))\n",
        "    print(\"freq min/mean/max:\", float(np.nanmin(freq)), float(np.nanmean(freq)), float(np.nanmax(freq)))\n",
        "    print(\"pw   min/mean/max:\", float(np.nanmin(pw)), float(np.nanmean(pw)), float(np.nanmax(pw)))\n",
        "\n",
        "\n",
        "# ---- Usage ----\n",
        "# 1) Calibrate\n",
        "cal = env.calibrate_seizure_scale(n_windows=300, regime=\"normal\", seed=0)\n",
        "print(\"Calibration:\", cal)\n",
        "\n",
        "# 2) Reset after calibration\n",
        "env.reset(seed=0, options={\"regime\": \"normal\"})\n",
        "\n",
        "# 3) Diagnostics per regime\n",
        "for reg in [\"normal\", \"preictal\", \"ictal\"]:\n",
        "    res = run_diagnostic_episode(env, regime=reg, n_steps=150, action=None, seed=0, capture_step=10)\n",
        "    plot_diagnostics(res, show_hist=True, psd=True)\n"
      ],
      "metadata": {
        "id": "JVscZoCRHFOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check: seizure_index under no stim in different regimes\n",
        "def mean_idx(regime, n=200):\n",
        "    env.reset(options={\"regime\": regime})\n",
        "    xs = []\n",
        "    for _ in range(n):\n",
        "        _, _, term, trunc, info = env.step(np.zeros(3, dtype=np.float32))\n",
        "        xs.append(info[\"seizure_index\"])\n",
        "        if term or trunc:\n",
        "            env.reset(options={\"regime\": regime})\n",
        "    return float(np.mean(xs)), float(np.std(xs))\n",
        "\n",
        "print(\"normal :\", mean_idx(\"normal\"))\n",
        "print(\"preictal:\", mean_idx(\"preictal\"))\n",
        "print(\"ictal  :\", mean_idx(\"ictal\"))\n"
      ],
      "metadata": {
        "id": "Mp6plzgTj3qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(episode_returns, label=\"Episode return\")\n",
        "# optional: moving average\n",
        "window = 10\n",
        "if len(episode_returns) >= window:\n",
        "    ma = np.convolve(episode_returns,\n",
        "                     np.ones(window)/window,\n",
        "                     mode=\"valid\")\n",
        "    plt.plot(range(window-1, len(episode_returns)),\n",
        "             ma, linestyle=\"--\", label=f\"{window}-ep moving avg\")\n",
        "\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Return\")\n",
        "plt.title(\"DBS RL training: episode returns\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o_FohQgoC6ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs, info = env.reset(options={\"regime\": \"ictal\"})  # start ictal\n",
        "seiz_traj = []\n",
        "dis_traj = []\n",
        "\n",
        "done = False\n",
        "while not done:\n",
        "    action = np.zeros(3, dtype=float)  # or your trained policy(obs)\n",
        "    obs, reward, terminated, truncated, info = env.step(action)\n",
        "    seiz_traj.append(info[\"seizure_index\"])\n",
        "    dis_traj.append(info[\"disease_level\"])\n",
        "    done = terminated or truncated\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(seiz_traj, label=\"seizure_index\")\n",
        "plt.plot(dis_traj, label=\"disease_level\")\n",
        "plt.axhline(env.seizure_baseline, linestyle=\"--\", label=\"baseline\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"RL step\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.title(\"Seizure and disease dynamics in one episode\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1HkBDlfKNJ3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start from an epileptic regime\n",
        "obs, info = env.reset(options={\"regime\": \"ictal\"})\n",
        "\n",
        "seiz_list = []\n",
        "disease_list = []\n",
        "reward_list = []\n",
        "time_list = []\n",
        "\n",
        "for step in range(env.max_steps):\n",
        "    # Use the SAC agent's learned policy\n",
        "    action = agent.select_action(obs)\n",
        "\n",
        "    obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "    seiz_list.append(info[\"seizure_index\"])\n",
        "    disease_list.append(info[\"disease_level\"])\n",
        "    reward_list.append(reward)\n",
        "    time_list.append(step * env.step_T)\n",
        "\n",
        "    if terminated or truncated:\n",
        "        break\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(8, 8), sharex=True)\n",
        "\n",
        "axes[0].plot(time_list, seiz_list)\n",
        "axes[0].set_ylabel(\"Seizure index\")\n",
        "\n",
        "axes[1].plot(time_list, disease_list)\n",
        "axes[1].set_ylabel(\"Disease level\")\n",
        "\n",
        "axes[2].plot(time_list, reward_list)\n",
        "axes[2].set_ylabel(\"Reward\")\n",
        "axes[2].set_xlabel(\"Time (s)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TYfoNOg4C_E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = EpilepsyDBSCombinedEnv(\n",
        "    default_regime=\"ictal\",\n",
        "    log_best_episodes=True,   # <--- crucial\n",
        "    n_best_episodes=1\n",
        ")\n",
        "\n",
        "obs, info = env.reset(options={\"regime\": \"ictal\"})\n",
        "\n",
        "done = False\n",
        "while not done:\n",
        "    # for now, just keep DBS parameters fixed:\n",
        "    action = np.zeros(3, dtype=float)\n",
        "    obs, reward, terminated, truncated, info = env.step(action)\n",
        "    done = terminated or truncated\n",
        "\n",
        "episodes = env.get_best_episodes()\n",
        "episode = episodes[0]   # only one\n"
      ],
      "metadata": {
        "id": "azps8SvxPXVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "t = episode[\"t\"]       # shape (N_samples,)\n",
        "v = episode[\"v\"]       # JR output\n",
        "u = episode[\"u\"]       # DBS drive signal\n",
        "\n",
        "fig, (ax_stim, ax_seiz) = plt.subplots(\n",
        "    2, 1, figsize=(10, 6), sharex=True,\n",
        "    gridspec_kw={\"height_ratios\": [1, 2]}\n",
        ")\n",
        "\n",
        "# Top: stimulation signal (continuous DBS drive)\n",
        "u_env = np.convolve(np.abs(u), np.ones(200)/200, mode=\"same\")\n",
        "ax_stim.plot(t, u_env)\n",
        "ax_stim.set_ylabel(\"DBS |u(t)| envelope\")\n",
        "ax_stim.set_title(\"DBS stimulation\")\n",
        "\n",
        "# Bottom: 'seizure activity' – here using JR voltage\n",
        "ax_seiz.plot(t, v)\n",
        "ax_seiz.set_xlabel(\"Time (s)\")\n",
        "ax_seiz.set_ylabel(\"JR output v(t)\")\n",
        "ax_seiz.set_title(\"Network activity\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YDip0DGEPavj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seiz_idx = episode[\"seizure_index\"]   # shape (num_steps,)\n",
        "rewards  = episode[\"rewards\"]         # shape (num_steps,)\n",
        "\n",
        "# Disease level isn't in the episode log yet; we read it during the episode.\n",
        "# For now, do a fresh run with explicit logging outside the env:\n",
        "env2 = EpilepsyDBSCombinedEnv(default_regime=\"ictal\")\n",
        "obs, info = env2.reset(options={\"regime\": \"ictal\"})\n",
        "\n",
        "seiz_traj = []\n",
        "dis_traj  = []\n",
        "rew_traj  = []\n",
        "t_steps   = []\n",
        "\n",
        "done = False\n",
        "step_idx = 0\n",
        "while not done:\n",
        "    action = np.zeros(3, dtype=float)\n",
        "    obs, reward, terminated, truncated, info = env2.step(action)\n",
        "\n",
        "    seiz_traj.append(info[\"seizure_index\"])\n",
        "    dis_traj.append(info[\"disease_level\"])\n",
        "    rew_traj.append(info[\"reward\"])\n",
        "    t_steps.append(step_idx * env2.step_T)\n",
        "\n",
        "    step_idx += 1\n",
        "    done = terminated or truncated\n",
        "\n",
        "seiz_traj = np.array(seiz_traj)\n",
        "dis_traj  = np.array(dis_traj)\n",
        "rew_traj  = np.array(rew_traj)\n",
        "t_steps   = np.array(t_steps)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
        "\n",
        "ax1.plot(t_steps, seiz_traj, label=\"seizure_index\")\n",
        "ax1.plot(t_steps, dis_traj, label=\"disease_level\")\n",
        "ax1.axhline(getattr(env2, \"seizure_baseline\", 0.7),\n",
        "            linestyle=\"--\", label=\"baseline\")\n",
        "ax1.set_ylabel(\"Value\")\n",
        "ax1.set_title(\"RL-level seizure & disease dynamics\")\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(t_steps, rew_traj)\n",
        "ax2.set_xlabel(\"Time (s)\")\n",
        "ax2.set_ylabel(\"Reward\")\n",
        "ax2.set_title(\"Reward per step\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lFBeb54sPdbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best = env.get_best_episodes()\n",
        "\n",
        "# Save each best episode as a separate .npz file\n",
        "import numpy as np\n",
        "\n",
        "for i, ep in enumerate(best):\n",
        "    np.savez_compressed(\n",
        "        f\"best_episode_{i}.npz\",\n",
        "        t=ep[\"t\"],\n",
        "        v=ep[\"v\"],\n",
        "        u=ep[\"u\"],\n",
        "        theta=ep[\"theta\"],\n",
        "        amp_fast=ep[\"amp_fast\"],\n",
        "        seizure_index=ep[\"seizure_index\"],\n",
        "        pac_index=ep[\"pac_index\"],\n",
        "        energy_norm=ep[\"energy_norm\"],\n",
        "        amp=ep[\"amp\"],\n",
        "        freq=ep[\"freq\"],\n",
        "        pw=ep[\"pw\"],\n",
        "        rewards=ep[\"rewards\"],\n",
        "        total_reward=ep[\"total_reward\"],\n",
        "    )\n"
      ],
      "metadata": {
        "id": "4kBpvBOSE8h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_fixed_dbs(\n",
        "    env,\n",
        "    regime=\"ictal\",\n",
        "    amp=5.0,\n",
        "    freq=145.0,\n",
        "    pw=90.0,\n",
        "    n_steps=200,\n",
        "):\n",
        "    \"\"\"\n",
        "    Run an episode in `regime` with *fixed* DBS parameters and return\n",
        "    time series and total reward.\n",
        "    \"\"\"\n",
        "    obs, info = env.reset(options={\"regime\": regime})\n",
        "\n",
        "    # Override current params and previous params to the desired fixed DBS\n",
        "    amp, freq, pw = env._clip_params(amp, freq, pw)\n",
        "    env.current_params = (amp, freq, pw)\n",
        "    env.prev_params = env.current_params\n",
        "\n",
        "    rewards = []\n",
        "    seizure_ts = []\n",
        "    disease_ts = []\n",
        "    pac_ts = []\n",
        "    energy_ts = []\n",
        "\n",
        "    for _ in range(n_steps):\n",
        "        # zero action = keep params unchanged\n",
        "        action = np.zeros(3, dtype=float)\n",
        "        obs, reward, terminated, truncated, info_step = env.step(action)\n",
        "\n",
        "        rewards.append(reward)\n",
        "        seizure_ts.append(info_step[\"seizure_index\"])\n",
        "        pac_ts.append(info_step[\"pac_index\"])\n",
        "        energy_ts.append(info_step[\"energy_norm\"])\n",
        "        disease_ts.append(env.disease_level)\n",
        "\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    return {\n",
        "        \"rewards\": np.array(rewards, dtype=float),\n",
        "        \"seizure\": np.array(seizure_ts, dtype=float),\n",
        "        \"pac\": np.array(pac_ts, dtype=float),\n",
        "        \"energy\": np.array(energy_ts, dtype=float),\n",
        "        \"disease\": np.array(disease_ts, dtype=float),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "5YC9vbaWZMz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_sets = {\n",
        "    \"SANTE_like_high\":  {\"amp\": 5.0, \"freq\": 145.0, \"pw\": 90.0},\n",
        "    \"SANTE_like_low\":   {\"amp\": 2.5, \"freq\": 145.0, \"pw\": 90.0},\n",
        "    \"init_130Hz\":       {\"amp\": 2.0, \"freq\": 130.0, \"pw\": 120.0},\n",
        "    \"no_stim\":          {\"amp\": 0.0, \"freq\": 130.0, \"pw\": 120.0},\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, p in param_sets.items():\n",
        "    out = evaluate_fixed_dbs(\n",
        "        env,\n",
        "        regime=\"ictal\",     # start in ictal state\n",
        "        amp=p[\"amp\"],\n",
        "        freq=p[\"freq\"],\n",
        "        pw=p[\"pw\"],\n",
        "        n_steps=env.max_steps,\n",
        "    )\n",
        "    results[name] = out\n",
        "    total_R = out[\"rewards\"].sum()\n",
        "    mean_R = out[\"rewards\"].mean()\n",
        "    print(f\"{name}: total reward = {total_R:.3f}, mean reward/step = {mean_R:.3f}\")\n"
      ],
      "metadata": {
        "id": "7SaRbDhEZM8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "best = env.get_best_episodes()[-1]   # last run\n",
        "t = best[\"t\"]\n",
        "v = best[\"v\"]\n",
        "u = best[\"u\"]\n",
        "seiz = best[\"seizure_index\"]         # per-step values – you can upsample in time if you want\n",
        "rewards = best[\"rewards\"]\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, sharex=True, figsize=(10, 8))\n",
        "\n",
        "axes[0].plot(t, u)\n",
        "axes[0].set_ylabel(\"DBS drive u(t)\")\n",
        "axes[0].set_title(\"DBS waveform\")\n",
        "\n",
        "axes[1].plot(t, v)\n",
        "axes[1].set_ylabel(\"JR output v(t)\")\n",
        "\n",
        "# Optionally interpolate seizure_index to same time grid as t\n",
        "axes[2].step(range(len(seiz)), seiz, where=\"post\")\n",
        "axes[2].set_ylabel(\"Seizure index\")\n",
        "axes[2].set_xlabel(\"Step or time\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5eYtWtH5ZSZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_seiz(env, regime, n=200):\n",
        "    try:\n",
        "        env.reset(regime=regime)\n",
        "    except TypeError:\n",
        "        env.default_regime = regime\n",
        "        env.reset()\n",
        "\n",
        "    zs = []\n",
        "    for _ in range(n):\n",
        "        _, _, term, trunc, info = env.step(np.array([0.,0.,0.], dtype=np.float32))\n",
        "        zs.append(info[\"seizure_index\"])\n",
        "        if term or trunc:\n",
        "            try:\n",
        "                env.reset(regime=regime)\n",
        "            except TypeError:\n",
        "                env.default_regime = regime\n",
        "                env.reset()\n",
        "    return float(np.mean(zs)), float(np.std(zs))\n",
        "\n",
        "print(\"normal :\", mean_seiz(env, \"normal\"))\n",
        "print(\"preictal:\", mean_seiz(env, \"preictal\"))\n",
        "print(\"ictal  :\", mean_seiz(env, \"ictal\"))\n"
      ],
      "metadata": {
        "id": "HF10ScGBfv2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "rows = []\n",
        "for name, out in results.items():\n",
        "    rows.append({\n",
        "        \"policy\": name,\n",
        "        \"mean_reward\": out[\"rewards\"].mean(),\n",
        "        \"total_reward\": out[\"rewards\"].sum(),\n",
        "        \"mean_seiz\": out[\"seizure\"].mean(),\n",
        "        \"final_disease\": out[\"disease\"][-1],\n",
        "        \"mean_energy\": out[\"energy\"].mean(),\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "qMP-TlA2ZUr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def _get_policy_action(policy, obs, deterministic=True):\n",
        "    \"\"\"\n",
        "    Tries common policy interfaces.\n",
        "    - If you have an SAC agent, rename `policy` accordingly or wrap it.\n",
        "    \"\"\"\n",
        "    # 1) Stable-baselines3 style: policy.predict(obs, deterministic=True)\n",
        "    if hasattr(policy, \"predict\"):\n",
        "        a, _ = policy.predict(obs, deterministic=deterministic)\n",
        "        return np.asarray(a, dtype=float).reshape(-1)\n",
        "\n",
        "    # 2) Common custom: policy.act(obs, deterministic=True) or policy.select_action(obs, deterministic=True)\n",
        "    for name in [\"act\", \"select_action\", \"get_action\"]:\n",
        "        if hasattr(policy, name):\n",
        "            fn = getattr(policy, name)\n",
        "            try:\n",
        "                a = fn(obs, deterministic=deterministic)\n",
        "            except TypeError:\n",
        "                a = fn(obs)\n",
        "            return np.asarray(a, dtype=float).reshape(-1)\n",
        "\n",
        "    raise AttributeError(\"Could not infer how to get actions from `policy`. Provide a wrapper with a .predict() or .act().\")\n",
        "\n",
        "\n",
        "def eval_policy(env, policy=None, regime=\"normal\", n_episodes=5, max_steps=100, deterministic=True, kind=\"learned\"):\n",
        "    rows = []\n",
        "    for ep in range(n_episodes):\n",
        "        obs, info = env.reset(options={\"regime\": regime})\n",
        "        ep_ret = 0.0\n",
        "        seiz = []\n",
        "        energy = []\n",
        "        slew = []\n",
        "        disease = []\n",
        "        for t in range(max_steps):\n",
        "            if kind == \"no_action\":\n",
        "                action = np.zeros(3, dtype=float)\n",
        "            elif kind == \"random_action\":\n",
        "                action = np.random.uniform(-1.0, 1.0, size=(3,))\n",
        "            else:\n",
        "                action = _get_policy_action(policy, obs, deterministic=deterministic)\n",
        "\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "            ep_ret += float(reward)\n",
        "\n",
        "            seiz.append(float(info.get(\"seizure_index\", np.nan)))\n",
        "            energy.append(float(info.get(\"energy_norm\", np.nan)))\n",
        "            slew.append(float(info.get(\"slew_penalty\", np.nan)))\n",
        "            disease.append(float(info.get(\"disease_level\", np.nan)))\n",
        "\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "\n",
        "        rows.append({\n",
        "            \"regime\": regime,\n",
        "            \"policy\": kind if kind != \"learned\" else \"learned\",\n",
        "            \"episode_return\": ep_ret,\n",
        "            \"mean_seizure\": float(np.nanmean(seiz)),\n",
        "            \"mean_energy\": float(np.nanmean(energy)),\n",
        "            \"mean_slew\": float(np.nanmean(slew)),\n",
        "            \"final_disease\": float(disease[-1]) if len(disease) else np.nan,\n",
        "            \"steps\": len(seiz),\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ---- Run evaluation ----\n",
        "# Set `policy` to your trained SAC policy/agent object.\n",
        "# Example:\n",
        "# policy = agent\n",
        "policy = None  # <-- CHANGE THIS to your trained SAC agent/policy\n",
        "\n",
        "regimes = [\"normal\", \"preictal\", \"ictal\"]\n",
        "all_rows = []\n",
        "\n",
        "for r in regimes:\n",
        "    all_rows.append(eval_policy(env, policy=None, regime=r, n_episodes=5, max_steps=env.max_steps, kind=\"no_action\"))\n",
        "    all_rows.append(eval_policy(env, policy=None, regime=r, n_episodes=5, max_steps=env.max_steps, kind=\"random_action\"))\n",
        "    if policy is not None:\n",
        "        all_rows.append(eval_policy(env, policy=policy, regime=r, n_episodes=5, max_steps=env.max_steps, kind=\"learned\", deterministic=True))\n",
        "\n",
        "df_eval = pd.concat(all_rows, ignore_index=True)\n",
        "summary = df_eval.groupby([\"regime\", \"policy\"]).agg(\n",
        "    mean_return=(\"episode_return\", \"mean\"),\n",
        "    std_return=(\"episode_return\", \"std\"),\n",
        "    mean_seizure=(\"mean_seizure\", \"mean\"),\n",
        "    mean_energy=(\"mean_energy\", \"mean\"),\n",
        "    mean_slew=(\"mean_slew\", \"mean\"),\n",
        "    final_disease=(\"final_disease\", \"mean\"),\n",
        "    mean_steps=(\"steps\", \"mean\"),\n",
        ").reset_index()\n",
        "\n",
        "summary\n"
      ],
      "metadata": {
        "id": "1m5rNv-oK0EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.DataFrame(episode_summaries)\n",
        "\n",
        "# choose a regime to rank within (ictal is most meaningful)\n",
        "df_ictal = df[df[\"regime\"] == \"ictal\"].copy()\n",
        "\n",
        "# best episodes by return\n",
        "top = df_ictal.sort_values(\"return\", ascending=False).head(10)\n",
        "\n",
        "print(top[[\"episode\",\"return\",\"mean_seiz_idx\",\"avg_amp\",\"avg_freq\",\"avg_pw\"]])\n",
        "\n",
        "# Scatter plots of param sets for top episodes\n",
        "plt.figure()\n",
        "plt.scatter(top[\"avg_amp\"], top[\"avg_freq\"])\n",
        "plt.xlabel(\"Mean amplitude (mA)\")\n",
        "plt.ylabel(\"Mean frequency (Hz)\")\n",
        "plt.title(\"Top-10 ictal episodes: mean amp vs mean freq\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(top[\"avg_amp\"], top[\"avg_pw\"])\n",
        "plt.xlabel(\"Mean amplitude (mA)\")\n",
        "plt.ylabel(\"Mean pulse width (us)\")\n",
        "plt.title(\"Top-10 ictal episodes: mean amp vs mean pw\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(top[\"avg_freq\"], top[\"avg_pw\"])\n",
        "plt.xlabel(\"Mean frequency (Hz)\")\n",
        "plt.ylabel(\"Mean pulse width (us)\")\n",
        "plt.title(\"Top-10 ictal episodes: mean freq vs mean pw\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wUZRhldctOLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Episode return curve\n",
        "plt.figure()\n",
        "plt.plot(episode_returns)\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Return\")\n",
        "plt.title(\"Episode returns\")\n",
        "plt.show()\n",
        "\n",
        "# SAC internal curves (if available)\n",
        "def safe_plot(arr, title, ylabel):\n",
        "    if arr is None or len(arr) == 0:\n",
        "        print(f\"[Missing] {title} not logged\")\n",
        "        return\n",
        "    plt.figure()\n",
        "    plt.plot(arr)\n",
        "    plt.xlabel(\"Update step\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "safe_plot(getattr(agent, \"critic_losses\", None), \"Critic loss\", \"loss\")\n",
        "safe_plot(getattr(agent, \"actor_losses\", None), \"Actor loss\", \"loss\")\n",
        "safe_plot(getattr(agent, \"alpha_hist\", None), \"Alpha (temperature)\", \"alpha\")\n",
        "safe_plot(getattr(agent, \"entropy_hist\", None), \"Policy entropy estimate\", \"entropy\")\n"
      ],
      "metadata": {
        "id": "RSwjaxv6tsj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASELINES = {\n",
        "    \"SANTE_low\":  {\"amp\": 1.0, \"freq\": 145.0, \"pw\": 90.0},\n",
        "    \"SANTE_high\": {\"amp\": 3.0, \"freq\": 145.0, \"pw\": 90.0},\n",
        "    \"standard_130Hz\": {\"amp\": 2.0, \"freq\": 130.0, \"pw\": 90.0},\n",
        "    \"low_freq\": {\"amp\": 2.0, \"freq\": 50.0, \"pw\": 90.0},\n",
        "}\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def rollout_fixed(env, params, regime=\"ictal\", seed=0):\n",
        "    obs, info = env.reset(seed=seed, options={\"regime\": regime})\n",
        "    env.current_params = (params[\"amp\"], params[\"freq\"], params[\"pw\"])\n",
        "    env.prev_params = env.current_params\n",
        "\n",
        "    rets = 0.0\n",
        "    seiz = []\n",
        "    energy = []\n",
        "    slew = []\n",
        "\n",
        "    for t in range(env.max_steps):\n",
        "        # action is ignored if you directly set current_params; so instead\n",
        "        # you should implement a helper env.step_params(...) or map params -> action\n",
        "        # If your env uses actions only, do params->action mapping here.\n",
        "        # For now, assume you have a function env.params_to_action(...)\n",
        "        a = env.params_to_action(params[\"amp\"], params[\"freq\"], params[\"pw\"])\n",
        "        obs, r, term, trunc, info = env.step(a)\n",
        "        rets += float(r)\n",
        "        seiz.append(float(info[\"seizure_index\"]))\n",
        "        energy.append(float(info[\"cost_components\"][\"energy\"]))\n",
        "        slew.append(float(info[\"cost_components\"][\"slew\"]))\n",
        "        if term or trunc:\n",
        "            break\n",
        "\n",
        "    return {\n",
        "        \"return\": rets,\n",
        "        \"mean_seizure_index\": float(np.mean(seiz)),\n",
        "        \"max_seizure_index\": float(np.max(seiz)),\n",
        "        \"mean_energy_cost\": float(np.mean(energy)),\n",
        "        \"mean_slew_cost\": float(np.mean(slew)),\n",
        "        \"steps\": len(seiz),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "LUaGiJFZtxfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "for name, p in BASELINES.items():\n",
        "    out = rollout_fixed(env, p, regime=\"ictal\", seed=0)\n",
        "    out.update({\"policy\": name})\n",
        "    rows.append(out)\n",
        "\n",
        "df_base = pd.DataFrame(rows)\n",
        "print(df_base.sort_values(\"return\", ascending=False))\n"
      ],
      "metadata": {
        "id": "VEtuXqI2t1g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.seizure_metric = \"line_length\"  # use this if bandpower seems unstable at 100 ms\n",
        "print(env.calibrate_seizure_scale(n_windows=300, regime=\"normal\", seed=0))\n",
        "\n",
        "def mean_index(regime, n=100):\n",
        "    env.reset(regime=regime)\n",
        "    idxs = []\n",
        "    for _ in range(n):\n",
        "        obs, r, done, info = env.step(np.array([0.0, 0.0, 0.0], dtype=np.float32))\n",
        "        idxs.append(info[\"seizure_index\"])\n",
        "        if done:\n",
        "            env.reset(regime=regime)\n",
        "    return float(np.mean(idxs)), float(np.std(idxs))\n",
        "\n",
        "print(\"normal mean/std:\", mean_index(\"normal\"))\n",
        "print(\"ictal  mean/std:\", mean_index(\"ictal\"))\n",
        "print(\"preictal mean/std:\", mean_index(\"preictal\"))\n"
      ],
      "metadata": {
        "id": "IXUdh5SreWiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def _maybe_get(obj, names):\n",
        "    for n in names:\n",
        "        if hasattr(obj, n):\n",
        "            return getattr(obj, n)\n",
        "    return None\n",
        "\n",
        "# Replace `agent` with your SAC agent variable if it exists in your notebook.\n",
        "agent = sac_agent  # or whatever your instance variable is called\n",
        "\n",
        "if agent is None:\n",
        "    print(\"Set `agent = <your SAC agent>` for this cell.\")\n",
        "else:\n",
        "    # Common history field names\n",
        "    critic_hist = _maybe_get(agent, [\"critic_losses\", \"q_losses\", \"critic_loss_hist\", \"loss_q_hist\"])\n",
        "    actor_hist  = _maybe_get(agent, [\"actor_losses\", \"actor_loss_hist\", \"loss_pi_hist\"])\n",
        "    alpha_hist  = _maybe_get(agent, [\"alpha_hist\", \"temperature_hist\", \"log_alpha_hist\"])\n",
        "    ent_hist    = _maybe_get(agent, [\"entropy_hist\", \"policy_entropy_hist\"])\n",
        "\n",
        "    found_any = any(x is not None for x in [critic_hist, actor_hist, alpha_hist, ent_hist])\n",
        "\n",
        "    if not found_any:\n",
        "        print(\n",
        "            \"I could not find stored loss/alpha/entropy histories on `agent`.\\n\\n\"\n",
        "            \"To log learning, you need to append scalars during each SAC update, e.g.:\\n\"\n",
        "            \"  self.critic_losses.append(float(q_loss))\\n\"\n",
        "            \"  self.actor_losses.append(float(pi_loss))\\n\"\n",
        "            \"  self.alpha_hist.append(float(alpha))   # if autotuning\\n\"\n",
        "            \"  self.entropy_hist.append(float(entropy))\\n\\n\"\n",
        "            \"Where to add:\\n\"\n",
        "            \"- right after critic backward/step\\n\"\n",
        "            \"- right after actor backward/step\\n\"\n",
        "            \"- right after alpha update (if any)\\n\"\n",
        "        )\n",
        "    else:\n",
        "        # Plot whatever exists\n",
        "        plt.figure()\n",
        "        if critic_hist is not None:\n",
        "            plt.plot(np.asarray(critic_hist, dtype=float))\n",
        "            plt.title(\"Critic loss history\")\n",
        "            plt.xlabel(\"Update\")\n",
        "            plt.ylabel(\"Loss\")\n",
        "            plt.show()\n",
        "\n",
        "        plt.figure()\n",
        "        if actor_hist is not None:\n",
        "            plt.plot(np.asarray(actor_hist, dtype=float))\n",
        "            plt.title(\"Actor loss history\")\n",
        "            plt.xlabel(\"Update\")\n",
        "            plt.ylabel(\"Loss\")\n",
        "            plt.show()\n",
        "\n",
        "        if alpha_hist is not None:\n",
        "            plt.figure()\n",
        "            plt.plot(np.asarray(alpha_hist, dtype=float))\n",
        "            plt.title(\"Alpha / temperature history\")\n",
        "            plt.xlabel(\"Update\")\n",
        "            plt.ylabel(\"Alpha\")\n",
        "            plt.show()\n",
        "\n",
        "        if ent_hist is not None:\n",
        "            plt.figure()\n",
        "            plt.plot(np.asarray(ent_hist, dtype=float))\n",
        "            plt.title(\"Policy entropy history\")\n",
        "            plt.xlabel(\"Update\")\n",
        "            plt.ylabel(\"Entropy\")\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "id": "6AMwJ7nOK2II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Set your trained policy/agent object here\n",
        "policy = SACAgent  # <-- set to your trained SAC policy/agent\n",
        "\n",
        "def collect_actions(env, policy, regime=\"normal\", max_steps=100, deterministic=True):\n",
        "    obs, info = env.reset(options={\"regime\": regime})\n",
        "    acts = []\n",
        "    infos = []\n",
        "    for _ in range(max_steps):\n",
        "        a = _get_policy_action(policy, obs, deterministic=deterministic)\n",
        "        obs, reward, terminated, truncated, info = env.step(a)\n",
        "        acts.append(a)\n",
        "        infos.append(info)\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "    return np.asarray(acts, dtype=float), infos\n",
        "\n",
        "def summarize_actions(actions):\n",
        "    # proportions relative to your quantisation thresholds\n",
        "    thr = 1.0/3.0\n",
        "    cols = []\n",
        "    for i in range(actions.shape[1]):\n",
        "        x = actions[:, i]\n",
        "        cols.append({\n",
        "            \"dim\": i,\n",
        "            \"mean\": float(np.mean(x)),\n",
        "            \"std\": float(np.std(x)),\n",
        "            \"p_neg\": float(np.mean(x < -thr)),\n",
        "            \"p_zero\": float(np.mean((x >= -thr) & (x <= thr))),\n",
        "            \"p_pos\": float(np.mean(x > thr)),\n",
        "        })\n",
        "    return pd.DataFrame(cols)\n",
        "\n",
        "if policy is None:\n",
        "    print(\"Set `policy = <your trained SAC policy/agent>` first.\")\n",
        "else:\n",
        "    for r in [\"normal\", \"preictal\", \"ictal\"]:\n",
        "        acts, infos = collect_actions(env, policy, regime=r, max_steps=env.max_steps, deterministic=True)\n",
        "        print(f\"\\nRegime: {r}, steps: {len(acts)}\")\n",
        "        display(summarize_actions(acts))\n"
      ],
      "metadata": {
        "id": "RlYzLvaOK4dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def run_fixed_policy(env, action_vec, regime=\"ictal\", n_steps=100, label=\"policy\"):\n",
        "    obs, info = env.reset(options={\"regime\": regime})\n",
        "    seiz, energy, amp, freq, pw = [], [], [], [], []\n",
        "    for _ in range(n_steps):\n",
        "        obs, reward, terminated, truncated, info = env.step(np.array(action_vec, dtype=float))\n",
        "        seiz.append(float(info[\"seizure_index\"]))\n",
        "        energy.append(float(info[\"energy_norm\"]))\n",
        "        amp.append(float(info[\"amp\"]))\n",
        "        freq.append(float(info[\"freq\"]))\n",
        "        pw.append(float(info[\"pw\"]))\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "    return {\n",
        "        \"label\": label,\n",
        "        \"seizure\": np.asarray(seiz),\n",
        "        \"energy\": np.asarray(energy),\n",
        "        \"amp\": np.asarray(amp),\n",
        "        \"freq\": np.asarray(freq),\n",
        "        \"pw\": np.asarray(pw),\n",
        "    }\n",
        "\n",
        "regime = \"ictal\"\n",
        "N = env.max_steps\n",
        "\n",
        "runs = [\n",
        "    run_fixed_policy(env, [0, 0, 0], regime=regime, n_steps=N, label=\"no_change\"),\n",
        "    run_fixed_policy(env, [+1, +1, +1], regime=regime, n_steps=N, label=\"always_increase\"),\n",
        "    run_fixed_policy(env, [-1, -1, -1], regime=regime, n_steps=N, label=\"always_decrease\"),\n",
        "]\n",
        "\n",
        "plt.figure()\n",
        "for r in runs:\n",
        "    plt.plot(r[\"seizure\"], label=r[\"label\"])\n",
        "plt.title(f\"Seizure index under fixed policies ({regime})\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Seizure index\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "for r in runs:\n",
        "    plt.plot(r[\"energy\"], label=r[\"label\"])\n",
        "plt.title(f\"Energy norm under fixed policies ({regime})\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Energy norm\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "for r in runs:\n",
        "    plt.plot(r[\"amp\"], label=r[\"label\"])\n",
        "plt.title(f\"Amp (mA) under fixed policies ({regime})\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"mA\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "for r in runs:\n",
        "    plt.plot(r[\"freq\"], label=r[\"label\"])\n",
        "plt.title(f\"Freq (Hz) under fixed policies ({regime})\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Hz\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "for r in runs:\n",
        "    plt.plot(r[\"pw\"], label=r[\"label\"])\n",
        "plt.title(f\"PW (us) under fixed policies ({regime})\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"us\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5HT4gFN8K7OB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}